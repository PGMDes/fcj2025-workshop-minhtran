[{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Trần Huỳnh Bảo Minh\nSố điện thoại: 078 222 4 999\nEmail: baominhbrthcs@gmail.com\nTrường: Đại học FPT TP.HCM\nNgành: Trí tuệ nhân tạo\nLớp: SE193028\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Bắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Bắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Bắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/3-blogstranslated/3.4-blog4/","title":"Blog 4","tags":[],"description":"","content":"Bắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/3-blogstranslated/3.5-blog5/","title":"Blog 5","tags":[],"description":"","content":"Bắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/3-blogstranslated/3.6-blog6/","title":"Blog 6","tags":[],"description":"","content":"Bắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/","title":"Chuẩn bị tài nguyên","tags":[],"description":"","content":"Để chuẩn bị cho phần này của workshop, bạn sẽ cần phải:\nTriển khai CloudFormation stack Sửa đổi bảng định tuyến VPC. Các thành phần này hoạt động cùng nhau để mô phỏng DNS forwarding và name resolution.\nTriển khai CloudFormation stack Mẫu CloudFormation sẽ tạo các dịch vụ bổ sung để hỗ trợ mô phỏng môi trường truyền thống:\nMột Route 53 Private Hosted Zone lưu trữ các bản ghi Bí danh (Alias records) cho điểm cuối PrivateLink S3 Một Route 53 Inbound Resolver endpoint cho phép \u0026ldquo;VPC Cloud\u0026rdquo; giải quyết các yêu cầu resolve DNS gửi đến Private Hosted Zone Một Route 53 Outbound Resolver endpoint cho phép \u0026ldquo;VPC On-prem\u0026rdquo; chuyển tiếp các yêu cầu DNS cho S3 sang \u0026ldquo;VPC Cloud\u0026rdquo; Click link sau để mở AWS CloudFormation console. Mẫu yêu cầu sẽ được tải sẵn vào menu. Chấp nhận tất cả mặc định và nhấp vào Tạo stack. Có thể mất vài phút để triển khai stack hoàn tất. Bạn có thể tiếp tục với bước tiếp theo mà không cần đợi quá trình triển khai kết thúc.\nCập nhật bảng định tuyến private on-premise Workshop này sử dụng StrongSwan VPN chạy trên EC2 instance để mô phỏng khả năng kết nối giữa trung tâm dữ liệu truyền thống và môi trường cloud AWS. Hầu hết các thành phần bắt buộc đều được cung cấp trước khi bạn bắt đầu. Để hoàn tất cấu hình VPN, bạn sẽ sửa đổi bảng định tuyến \u0026ldquo;VPC on-prem\u0026rdquo; để hướng lưu lượng đến cloud đi qua StrongSwan VPN instance.\nMở Amazon EC2 console\nChọn instance tên infra-vpngw-test. Từ Details tab, copy Instance ID và paste vào text editor của bạn để sử dụng ở những bước tiếp theo\nĐi đến VPC menu bằng cách gõ \u0026ldquo;VPC\u0026rdquo; vào Search box\nClick vào Route Tables, chọn RT Private On-prem route table, chọn Routes tab, và click Edit Routes.\nClick Add route. Destination: CIDR block của Cloud VPC Target: ID của infra-vpngw-test instance (bạn đã lưu lại ở bước trên) Click Save changes "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Bài thu hoạch “Vòng đời phát triển theo hướng AI: Tái định hình kỹ thuật phần mềm” Mục Đích Của Sự Kiện Hiểu rõ cách AI có thể tự động hóa và tối ưu hóa từng giai đoạn trong vòng đời phát triển phần mềm (Software Development Lifecycle – SDLC). Nắm bắt được triết lý AI hỗ trợ con người thay vì thay thế con người trong quá trình xây dựng ứng dụng. Trực tiếp quan sát cách Amazon Q và các công cụ AI khác hỗ trợ lập trình viên từ giai đoạn khởi tạo ý tưởng, viết mã, đến triển khai hạ tầng (IaC – Infrastructure as Code). Nhận thức được xu hướng “AI-first development” – nơi AI trở thành một phần tự nhiên của quy trình phát triển phần mềm tương lai. Danh Sách Diễn Giả Toan Huynh My Nguyen Nội Dung Nổi Bật Thử thách khi lập trình với AI Phần mở đầu trình bày những hạn chế và thách thức khi đưa AI vào lập trình:\nAI chưa thể xử lý các project có logic phức tạp, đòi hỏi hiểu biết sâu về ngữ cảnh nghiệp vụ. Lập trình viên khó kiểm soát chi tiết trong mã sinh ra nếu không mô tả rõ ràng mục tiêu và phạm vi. Chất lượng code phụ thuộc nhiều vào prompt và context mà người dùng cung cấp. Đây chính là lý do AI-DLC ra đời: tạo ra một quy trình có cấu trúc, giúp AI và con người phối hợp hiệu quả hơn.\nAI in Development – How AI is Changing Software Phần này phân tích cách AI đang thay đổi ngành phần mềm:\nAI hỗ trợ sinh code, tạo tài liệu kỹ thuật, thiết kế API, và kiểm thử tự động. Developer chuyển vai trò từ “code writer” sang “AI orchestrator” — người điều phối, định hướng và đánh giá đầu ra. Các công cụ như Amazon Q, GitHub Copilot, ChatGPT for Developers trở thành công cụ trung tâm trong workflow của team dev hiện đại. 🔹 Giới thiệu về AI-DLC là gì AI-Driven Development Lifecycle (AI-DLC) là phương pháp tiếp cận phát triển phần mềm có sự đồng hành của AI, nơi mỗi bước được thiết kế để cung cấp cho AI ngữ cảnh và mục tiêu cụ thể nhằm tạo ra kết quả chính xác hơn.\n🟧 Inception\nBuild Context on Existing Codes – AI được “nuôi” bằng mã nguồn hiện tại để hiểu cấu trúc dự án. Elaborate Intent with User Stories – Developer mô tả yêu cầu thông qua user story, làm rõ mục tiêu. Plan with Units of Work – Phân tách công việc thành các đơn vị nhỏ để AI có thể thực thi và sinh code từng phần. 🟦 Construction\nDomain Model (Component Model) – Xây dựng mô hình miền hoặc sơ đồ kiến trúc logic. Generate Code \u0026amp; Test – AI sinh code và test tự động dựa trên thông tin đã lên kế hoạch. Add Architectural Components – Bổ sung các thành phần kiến trúc như API, data layer, logging, security. Deploy with IaC \u0026amp; Tests – Tự động triển khai hệ thống với Infrastructure as Code và test tích hợp. 🔁 Mỗi bước đều cung cấp thêm “rich context” cho bước kế tiếp, giúp AI hiểu sâu hơn về hệ thống và sinh ra kết quả ngày càng chính xác.\nCORE CONCEPTS – Ba nguyên lý cốt lõi Context Awareness – AI cần có ngữ cảnh rõ ràng về mã, yêu cầu và domain để hoạt động hiệu quả. Collaborative Generation – Con người và AI hợp tác: AI sinh code, con người định hướng và kiểm duyệt. Continuous Refinement – Quy trình lặp lại liên tục để tinh chỉnh đầu ra và cải thiện chất lượng. Mob Elaboration Mob Elaboration là phương pháp mở rộng yêu cầu (intent elaboration) theo hình thức cộng tác nhóm:\nNhiều thành viên cùng nhau mô tả yêu cầu, đặt câu hỏi, và bổ sung thông tin cho AI. Giúp AI hiểu sâu hơn về nghiệp vụ, mục tiêu và logic phức tạp của dự án. Cách tiếp cận này giúp giảm rủi ro hiểu sai yêu cầu, đặc biệt trong các team lớn hoặc đa miền. 5-Stage Sequential Process của AI-DLC AI-DLC được thực hiện qua 5 giai đoạn:\nInception – Hiểu yêu cầu, phân tích hệ thống. Construction – Tạo mô hình miền và cấu trúc ban đầu. Generation – Sinh mã tự động. Testing – Tự động hóa kiểm thử đơn vị và tích hợp. Deployment – Triển khai ứng dụng với IaC và CI/CD pipelines. Mỗi vòng lặp giúp AI học thêm và cải thiện chất lượng đầu ra.\nDemo 1 – Trải nghiệm trực quan AI DLC với Amazon Q Buổi demo minh họa cách áp dụng AI-DLC trong thực tế thông qua một dự án nhỏ:\nBắt đầu từ ý tưởng đơn giản → chuyển thành user story mô tả yêu cầu nghiệp vụ. AI hỗ trợ phân chia công việc (Units of Work) và lập kế hoạch chi tiết cho từng module. Người tham dự có thể điều khiển AI thông qua câu hỏi, checkbox và điều kiện logic, giúp AI hiểu rõ phạm vi công việc. AI tiếp tục sinh code, viết test, tạo cấu trúc dự án và triển khai thử nghiệm tự động. Demo thể hiện rõ cách AI và con người phối hợp nhịp nhàng: AI làm việc lặp đi lặp lại, con người định hướng và ra quyết định chiến lược. Giới Thiệu Về Kiro Triết Lý Của Kiro\nPhần tiếp theo của workshop giới thiệu Kiro, một môi trường phát triển thông minh được thiết kế xoay quanh triết lý “AI-native development” – nơi AI là một phần cốt lõi, không phải chỉ là công cụ hỗ trợ.\nTriết lý của Kiro tập trung vào ba yếu tố chính:\nTích hợp sâu với quy trình phát triển – AI không chỉ hỗ trợ viết code, mà còn tham gia lập kế hoạch, quản lý context, và phân tích tác động thay đổi. Hiểu ngữ cảnh dự án toàn diện – Kiro duy trì trạng thái hiểu biết liên tục về cấu trúc hệ thống, cho phép AI tương tác với toàn bộ project thay vì từng file riêng lẻ. Kiểm soát \u0026amp; cộng tác thông minh – Lập trình viên có thể hướng dẫn AI thông qua contextual commands, giúp đảm bảo rằng mỗi thay đổi đều có mục đích rõ ràng và nhất quán với hệ thống. Cấu Trúc Project Trong Kiro\nKhác với các text editor truyền thống như VSCode hay JetBrains, Kiro không chỉ là môi trường viết mã — nó là AI workspace có nhận thức cấu trúc.\nCấu trúc project trong Kiro bao gồm:\nContext Layer – Lưu trữ ngữ cảnh, domain model, và quan hệ giữa các module. Task Layer – Quản lý các đơn vị công việc (Units of Work) được AI theo dõi và hoàn thành dần. AI Agent Layer – Mỗi tác vụ (code, test, refactor, deploy) có agent riêng đảm nhận, tạo ra mô hình phát triển đa agent – hợp tác – song song. Human-in-the-Loop Control – Lập trình viên có thể can thiệp ở mọi bước: xác nhận, sửa đổi hoặc từ chối đầu ra của AI. Điều này giúp Kiro không chỉ là công cụ sinh code mà trở thành một hệ sinh thái phát triển hợp tác giữa người và AI.\nDemo 2: Kiro – Áp Dụng AI-DLC Trong phần trình diễn, diễn giả minh họa cách Kiro vận hành AI-DLC một cách liền mạch:\nNgười dùng nhập một yêu cầu nghiệp vụ cơ bản, ví dụ “xây dựng hệ thống quản lý sự kiện”. Kiro tự động phân tích intent, tạo domain model và chia nhỏ thành các user story. AI trong Kiro sinh ra các module, component và test case tương ứng. Developer có thể tương tác qua bảng kiểm (checkbox-based task control) để xác nhận từng phần việc. Cuối cùng, Kiro triển khai hệ thống hoàn chỉnh với IaC và kiểm thử tự động. Buổi demo cho thấy AI-DLC không chỉ là lý thuyết, mà có thể được triển khai thực tế ngay trong môi trường Kiro — nơi AI, con người, và quy trình phát triển hòa quyện thành một hệ thống thống nhất.\nTrải nghiệm trong event Tham gia buổi workshop “AI DLC x Kiro: Reinventing Developer Experience with AI” là một trải nghiệm vô cùng bổ ích, giúp tôi hiểu rõ hơn về cách AI được tích hợp sâu vào môi trường phát triển phần mềm và cách mà triết lý thiết kế của Kiro mang lại hướng tiếp cận mới cho developer.\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đã chia sẻ về AI DLC – một nền tảng hỗ trợ phát triển phần mềm dựa trên AI, giúp tự động hóa nhiều quy trình trong SDLC. Ngoài ra, phần giới thiệu về Kiro Editor mang lại cái nhìn sâu sắc về cách xây dựng một text editor theo hướng AI-native thay vì chỉ “thêm plugin AI” vào môi trường cũ. Tôi đặc biệt ấn tượng với triết lý của Kiro: tối giản, hiệu năng cao, tập trung vào trải nghiệm người dùng và khả năng mở rộng theo module. Trải nghiệm kỹ thuật thực tế Buổi demo minh họa cách sử dụng AI DLC kết hợp với Kiro để tạo, chỉnh sửa và tối ưu mã nguồn một cách thông minh. Tôi được chứng kiến một project nhỏ được khởi tạo và quản lý ngay trong Kiro, với khả năng AI tự động đề xuất refactor, viết test case và phân tích logic code. So với các text editor phổ biến như VSCode hay Sublime, Kiro thể hiện sự khác biệt nhờ kiến trúc AI-first và plugin architecture nhẹ, cho phép tích hợp AI mà không làm giảm hiệu suất. Ứng dụng công cụ hiện đại Việc trải nghiệm AI DLC trên Kiro giúp tôi hiểu rõ hơn về khả năng tự động hóa quy trình phát triển, đặc biệt là ở các bước như code generation, documentation và debugging. Tôi nhận ra tiềm năng của việc xây dựng công cụ học tập và làm việc cá nhân có khả năng gợi ý thông minh, giúp rút ngắn thời gian phát triển và nâng cao chất lượng sản phẩm. Các khái niệm về modular design của Kiro cũng gợi ý cho tôi hướng đi trong việc thiết kế hệ thống linh hoạt, dễ mở rộng và dễ bảo trì. Kết nối và trao đổi Workshop tạo cơ hội để tôi giao lưu với các developer, nhà nghiên cứu AI và product designer, từ đó hiểu thêm về xu hướng AI-augmented development. Qua các cuộc thảo luận, tôi học được nhiều về cách AI có thể đóng vai trò cộng tác viên sáng tạo, giúp developer tập trung hơn vào logic và tư duy hệ thống thay vì những thao tác lặp lại. Bài học rút ra AI DLC kết hợp Kiro là ví dụ điển hình cho thế hệ công cụ phát triển mới — AI-first IDE, nơi AI không chỉ hỗ trợ mà còn đồng hành cùng lập trình viên trong mọi giai đoạn phát triển. Triết lý “less is more” của Kiro nhấn mạnh rằng sự tối giản và hiệu suất có thể tạo ra trải nghiệm mạnh mẽ hơn bất kỳ hệ thống phức tạp nào. Tôi học được rằng việc áp dụng AI hiệu quả không chỉ nằm ở công nghệ, mà còn ở cách tích hợp và triết lý thiết kế, điều này có thể được mang vào các dự án học tập hoặc phát triển phần mềm thực tế của tôi. Một số hình ảnh khi tham gia sự kiện "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"Bài thu hoạch “WORKSHOP KHOA HỌC DỮ LIỆU TRÊN AWS” Mục Đích Của Sự Kiện Chia sẻ các dịch vụ AI trên AWS Hướng dẫn triển khai mô hình AI thông qua Amazon SageMaker Chia sẻ cách deploy mô hình AI và truy cập thông qua API Danh Sách Diễn Giả Văn Hoàng Kha - Cloud Solutions Architec AWS User Group Leader Bạch Doãn Vương - Cloud Develops Engineer AWS Community Builder Nội Dung Nổi Bật Giới thiệu \u0026amp; Tầm quan trọng của Cloud trong Data Science Trình bày vai trò của điện toán đám mây (Cloud Computing) trong việc hỗ trợ xử lý dữ liệu, huấn luyện và triển khai mô hình AI quy mô lớn.\nSo sánh Cloud vs. On-premise:\nCloud: khả năng mở rộng linh hoạt, triển khai nhanh, tiết kiệm chi phí vận hành, dễ dàng tích hợp. On-premise: tốn kém chi phí đầu tư ban đầu, khó mở rộng, bảo trì phức tạp. Cloud (đặc biệt là AWS) mang lại nền tảng mạnh mẽ cho Data Science pipeline — từ thu thập, lưu trữ, xử lý dữ liệu, huấn luyện, cho đến triển khai mô hình AI.\nCác Layer AI Trên AWS AWS chia hệ sinh thái AI thành 3 tầng (layers), giúp người dùng lựa chọn mức độ quản lý phù hợp với năng lực và mục tiêu của mình:\n1. AI Services (Fully Managed Layer)\nDành cho người dùng muốn ứng dụng AI mà không cần kiến thức chuyên sâu về Machine Learning.\nCác dịch vụ AI sẵn có, đã được huấn luyện bởi AWS.\nNgười dùng chỉ cần gọi API là có thể sử dụng ngay trong ứng dụng.\nVí dụ:\nAmazon Comprehend: Phân tích ngôn ngữ tự nhiên (NLP) Amazon Translate: Dịch máy học đa ngôn ngữ Amazon Textract: Trích xuất dữ liệu từ tài liệu, hóa đơn Amazon Rekognition: Nhận diện hình ảnh và video Amazon Polly: Chuyển văn bản thành giọng nói Amazon Bedrock: Truy cập các mô hình nền tảng (Foundation Models) như Claude, Titan, Mistral\u0026hellip; 👉 Lợi ích: Triển khai nhanh, không cần huấn luyện mô hình, chi phí linh hoạt theo nhu cầu sử dụng.\n2. ML Services (Semi-managed Layer)\nDành cho Data Scientist, ML Engineer muốn xây dựng, huấn luyện và triển khai mô hình ML một cách tùy chỉnh hơn.\nAmazon SageMaker là trung tâm của tầng này: cung cấp bộ công cụ đầy đủ để build – train – deploy mô hình Machine Learning.\nCác tính năng nổi bật:\nData Wrangler: Làm sạch và xử lý dữ liệu trực quan. Feature Store: Quản lý đặc trưng (features) dùng cho nhiều mô hình. AutoML (SageMaker Autopilot): Tự động huấn luyện mô hình. Model Registry \u0026amp; Monitoring: Theo dõi và quản lý mô hình sau khi deploy. 👉 Lợi ích: Toàn quyền kiểm soát pipeline ML, có thể tùy chỉnh thuật toán, môi trường huấn luyện, và quy trình triển khai.\n3. AI Infrastructure (Self-managed Layer)\nDành cho tổ chức hoặc chuyên gia muốn tự quản lý toàn bộ hạ tầng AI/ML để tối ưu chi phí hoặc hiệu năng.\nNgười dùng có thể xây dựng môi trường huấn luyện bằng cách kết hợp các dịch vụ hạ tầng cơ bản của AWS:\nAmazon EC2 / EC2 GPU Instances (P5, G6, Inferentia): Huấn luyện mô hình tùy chỉnh quy mô lớn. Amazon EKS / ECS: Chạy các workload ML trong container hoặc Kubernetes. AWS Lambda: Xử lý dữ liệu hoặc inference nhỏ gọn, serverless. Amazon S3 / EFS: Lưu trữ dữ liệu và mô hình. 👉 Lợi ích: Linh hoạt tối đa, kiểm soát toàn bộ quá trình huấn luyện, nhưng yêu cầu kiến thức kỹ thuật cao hơn.\nCác Dịch Vụ AI Phổ Biến Của AWS Hỗ Trợ Sinh Viên Trong Quá Trình Train Model 1. Amazon SageMaker\nMôi trường phát triển tích hợp (SageMaker Studio) cho toàn bộ quy trình ML:\nChuẩn bị dữ liệu Huấn luyện mô hình Theo dõi kết quả Triển khai endpoint phục vụ API inference Hỗ trợ AutoML, GPU training, model monitoring và CI/CD cho mô hình AI.\n2. Amazon Comprehend\nDịch vụ NLP giúp phân tích, hiểu và phân loại ngôn ngữ tự nhiên.\nChức năng chính:\nPhân tích cảm xúc (Sentiment Analysis) Nhận dạng thực thể (Entity Recognition) Phân loại văn bản (Text Classification) Gắn nhãn dữ liệu tự động Phát hiện ngôn ngữ Trường hợp sử dụng thực tế:\nXử lý tài liệu thông minh Phân tích mail hàng loạt để phát hiện phản hồi tích cực/tiêu cực Phân tích cảm xúc và tâm lý khách hàng Hỗ trợ trung tâm liên lạc (Contact Center Analytics) Xác thực và trích xuất thông tin cá nhân 3. Amazon Translate\nDịch vụ dịch máy học (Neural Machine Translation).\nHỗ trợ hơn 75 ngôn ngữ với độ chính xác cao và dễ tích hợp.\nỨng dụng:\nLàm website đa ngôn ngữ Dịch nội dung tự động trong ứng dụng Hỗ trợ chatbot và phân tích dữ liệu đa ngôn ngữ 4. Amazon Textract\nTự động trích xuất văn bản và dữ liệu có cấu trúc từ hình ảnh, tài liệu, hoặc biểu mẫu. Ứng dụng trong các quy trình như: số hóa hồ sơ, xử lý hóa đơn, tự động nhập dữ liệu vào hệ thống. Tổng Quan Data Science Pipeline Trên AWS Thu thập \u0026amp; lưu trữ dữ liệu: Amazon S3, AWS Data Exchange Tiền xử lý dữ liệu: AWS Glue, Lambda, Athena Huấn luyện mô hình: SageMaker (train, tune, evaluate) Triển khai mô hình: SageMaker Endpoint / Lambda + API Gateway Giám sát \u0026amp; tối ưu: CloudWatch, Model Monitor Demo 1: Thiết kế Workflow AI Training bằng Giao Diện Kéo - Thả (No-Code/Low-Code) Mục tiêu: Giới thiệu cách xây dựng quy trình huấn luyện mô hình AI mà không cần viết nhiều code.\nCông cụ sử dụng: Amazon SageMaker Studio / SageMaker Canvas\nNội dung trình diễn:\nChuẩn bị dataset và tải lên Amazon S3.\nDùng giao diện kéo-thả của SageMaker để:\nChọn nguồn dữ liệu, thuật toán huấn luyện và tham số. Thiết kế toàn bộ pipeline gồm bước làm sạch dữ liệu, training, validation và deployment. Quan sát trực quan tiến trình training và kết quả mô hình (accuracy, confusion matrix, metrics, v.v.).\nThông điệp chính: Sinh viên, nhà phát triển có thể nhanh chóng tạo workflow AI mà không cần viết code phức tạp — giúp rút ngắn thời gian nghiên cứu và thử nghiệm mô hình.\nDemo 2: Triển khai AI Service và Truy Cập Qua API/Website Mục tiêu: Giới thiệu cách deploy mô hình AI để người dùng có thể truy cập và sử dụng thực tế.\nCông cụ sử dụng: Amazon SageMaker Endpoint, API Gateway, và Lambda.\nNội dung trình diễn:\nDeploy mô hình AI đã huấn luyện lên SageMaker Endpoint. Tích hợp endpoint với API Gateway để tạo REST API công khai. Tạo đường dẫn web hoặc API URL để người dùng có thể gửi yêu cầu (ví dụ: nhập câu văn để phân tích cảm xúc hoặc dịch ngôn ngữ). Minh họa cách hiển thị kết quả trực quan (UI demo hoặc Postman/API test). Thông điệp chính: Cho thấy cách AWS hỗ trợ triển khai mô hình AI từ giai đoạn nghiên cứu đến ứng dụng thực tế — dễ dàng chia sẻ, mở rộng, và thương mại hóa.\nThảo Luận: Hiệu Năng \u0026amp; Chi Phí (Cloud vs. On-premise) Tiêu chí Cloud (AWS) On-premise Khả năng mở rộng Dễ dàng mở rộng tài nguyên theo nhu cầu Giới hạn phần cứng cố định Chi phí Trả theo mức sử dụng (Pay-as-you-go) Chi phí đầu tư ban đầu cao Triển khai Tự động, nhanh chóng Thủ công, tốn thời gian Bảo trì AWS quản lý Người dùng tự chịu trách nhiệm Thích hợp cho sinh viên ✅ Có Free Tier, dễ học và thử nghiệm ❌ Khó tiếp cận, tốn kém Kết Luận AWS cung cấp hệ sinh thái AI toàn diện từ tầng hạ tầng đến tầng ứng dụng, phù hợp với mọi đối tượng — từ sinh viên mới học AI đến doanh nghiệp triển khai quy mô lớn. Trải nghiệm trong event Tham gia workshop “AI Services on AWS for Data Science” là một trải nghiệm rất bổ ích, giúp tôi hiểu rõ hơn về vai trò của Cloud trong Data Science và cách AWS hỗ trợ huấn luyện, triển khai, và truy cập mô hình AI.\nHọc hỏi từ các diễn giả có chuyên môn cao Diễn giả giới thiệu tầm quan trọng của Cloud trong xử lý dữ liệu và huấn luyện mô hình. Hiểu rõ 3 layer AI trên AWS: AI-managed services, ML services (SageMaker), và AI frameworks. Trải nghiệm kỹ thuật thực tế Demo 1: Thiết kế workflow AI bằng cách kéo thả trong SageMaker Canvas để train model mà không cần code. Demo 2: Triển khai mô hình AI thành service có thể truy cập qua API hoặc liên kết thực tế. Ứng dụng công cụ hiện đại Tìm hiểu các dịch vụ AI nổi bật: Amazon Comprehend, Translate, và Textract. Hiểu cách các dịch vụ này hỗ trợ NLP, dịch tự động, và trích xuất dữ liệu thông minh trong nhiều ngữ cảnh. Kết nối và trao đổi Giao lưu với chuyên gia và sinh viên cùng quan tâm đến AI \u0026amp; Cloud. Trao đổi về chi phí, hiệu năng (Cloud vs On-premise) và cách tối ưu sử dụng SageMaker. Bài học rút ra Cloud là nền tảng trọng yếu trong quy trình Data Science hiện đại. AWS cung cấp đầy đủ công cụ cho mọi cấp độ AI — từ không code đến tự triển khai. Hiểu rõ hơn cách đưa mô hình AI vào sản phẩm thực tế qua các dịch vụ AWS. Một số hình ảnh khi tham gia sự kiện "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.1-workshop-overview/","title":"Giới thiệu","tags":[],"description":"","content":"Giới thiệu về VPC Endpoint Điểm cuối VPC (endpoint) là thiết bị ảo. Chúng là các thành phần VPC có thể mở rộng theo chiều ngang, dự phòng và có tính sẵn sàng cao. Chúng cho phép giao tiếp giữa tài nguyên điện toán của bạn và dịch vụ AWS mà không gây ra rủi ro về tính sẵn sàng. Tài nguyên điện toán đang chạy trong VPC có thể truy cập Amazon S3 bằng cách sử dụng điểm cuối Gateway. Interface Endpoint PrivateLink có thể được sử dụng bởi tài nguyên chạy trong VPC hoặc tại TTDL. Tổng quan về workshop Trong workshop này, bạn sẽ sử dụng hai VPC.\n\u0026ldquo;VPC Cloud\u0026rdquo; dành cho các tài nguyên cloud như Gateway endpoint và EC2 instance để kiểm tra. \u0026ldquo;VPC On-Prem\u0026rdquo; mô phỏng môi trường truyền thống như nhà máy hoặc trung tâm dữ liệu của công ty. Một EC2 Instance chạy phần mềm StrongSwan VPN đã được triển khai trong \u0026ldquo;VPC On-prem\u0026rdquo; và được cấu hình tự động để thiết lập đường hầm VPN Site-to-Site với AWS Transit Gateway. VPN này mô phỏng kết nối từ một vị trí tại TTDL (on-prem) với AWS cloud. Để giảm thiểu chi phí, chỉ một phiên bản VPN được cung cấp để hỗ trợ workshop này. Khi lập kế hoạch kết nối VPN cho production workloads của bạn, AWS khuyên bạn nên sử dụng nhiều thiết bị VPN để có tính sẵn sàng cao. "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Trong trang này bạn sẽ cần giới thiệu worklog của bạn như thế nào? Bạn hoàn thành chương trình trong vòng bao nhiêu tuần? Bạn đã làm gì trong các tuần đó?\nThông thường và cũng là tiêu chuẩn, một worklog được thực hiện trong khoảng 3 tháng (trong suốt thời gian thực tập) với nội dung các tuần như sau:\nTuần 1: Làm quen với các nền tảng AWS, Mạng VPC, Bảo mật và Thực hành Labs\nTuần 2: Thực hành AWS EC2, Auto Scaling, CloudWatch, Backup, S3, FSx, Storage Gateway\nTuần 3: Dịch vụ Bảo mật \u0026amp; Cơ sở dữ liệu trên AWS (IAM, Cognito, KMS, RDS, Aurora, Redshift, ElastiCache)\nTuần 4: Làm công việc C\u0026hellip;\nTuần 5: Làm công việc D\u0026hellip;\nTuần 6: Làm công việc E\u0026hellip;\nTuần 7: Làm công việc G\u0026hellip;\nTuần 8: Làm công việc H\u0026hellip;\nTuần 9: Làm công việc I\u0026hellip;\nTuần 10: Làm công việc L\u0026hellip;\nTuần 11: Làm công việc M\u0026hellip;\nTuần 12: Làm công việc N\u0026hellip;\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/","title":"Tạo một Gateway Endpoint","tags":[],"description":"","content":" Mở Amazon VPC console Trong thanh điều hướng, chọn Endpoints, click Create Endpoint: Bạn sẽ thấy 6 điểm cuối VPC hiện có hỗ trợ AWS Systems Manager (SSM). Các điểm cuối này được Mẫu CloudFormation triển khai tự động cho workshop này.\nTrong Create endpoint console: Đặt tên cho endpoint: s3-gwe Trong service category, chọn aws services Trong Services, gõ \u0026ldquo;s3\u0026rdquo; trong hộp tìm kiếm và chọn dịch vụ với loại gateway Đối với VPC, chọn VPC Cloud từ drop-down menu. Đối với Route tables, chọn bảng định tuyến mà đã liên kết với 2 subnets (lưu ý: đây không phải là bảng định tuyến chính cho VPC mà là bảng định tuyến thứ hai do CloudFormation tạo). Đối với Policy, để tùy chọn mặc định là Full access để cho phép toàn quyền truy cập vào dịch vụ. Bạn sẽ triển khai VPC endpoint policy trong phần sau để chứng minh việc hạn chế quyền truy cập vào S3 bucket dựa trên các policies. Không thêm tag vào VPC endpoint. Click Create endpoint, click x sau khi nhận được thông báo tạo thành công. "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Mục tiêu Tuần 1: Hiểu các kiến thức cơ bản về điện toán đám mây và hạ tầng toàn cầu của AWS. Học cách quản lý dịch vụ AWS thông qua Management Console, CLI và SDK. Tìm hiểu bảo mật, IAM và quản lý chi phí AWS thông qua các bài thực hành. Xây dựng nền tảng kiến thức về mạng VPC và kết nối (Subnet, Route Table, IGW, NAT, Peering, Transit Gateway). Thực hành trực tiếp trên AWS với các bài Lab để củng cố lý thuyết bằng kỹ năng thực tế. Nhiệm vụ trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Đọc và ghi chú lại các quy định, nội quy của đơn vị thực tập\n- Học Module 01:\n+ Điện toán đám mây: Khái niệm, lợi ích\n+ Tổng quan AWS:\n+ Điểm khác biệt của AWS, triết lý định giá, nguyên tắc lãnh đạo\n+ Hành trình lên đám mây\n+ Hạ tầng AWS: Data center, AZ, Region, Edge Locations\n+ Quản lý dịch vụ AWS:\n+ AWS Management Console\n+ AWS CLI\n+ AWS SDK\n- Thực hành:\n+ Lab 01: Tạo tài khoản AWS, bật MFA, tạo IAM User/Group, Access Keys\n+ Lab 07: Tạo các loại ngân sách khác nhau\n+ Lab 09: Sử dụng AWS Support Plans và mở case hỗ trợ\n- Nghiên cứu:\n+ AWS Well-Architected Framework 08/09/2025 08/09/2025 2 - Tổng quan mạng: Tầm quan trọng trong kiến trúc AWS Cloud\n+ Amazon VPC: Khái niệm, khác biệt với Private Cloud truyền thống, triển khai Multi-AZ\n+ VPC CIDR: IPv4 (bắt buộc), IPv6 (tùy chọn), giới hạn 5 VPC mỗi Region\n+ Subnet: Public vs Private, các địa chỉ IP dự trữ\n+ Route Table: Route mặc định, route tùy chỉnh, định tuyến Public Subnet\n+ Elastic Network Interface (ENI), Elastic IP Address\n+ VPC Endpoint: Interface Endpoint, Gateway Endpoint (S3, DynamoDB)\n+ Internet Gateway: Yêu cầu để có Internet access (public IP + route)\n+ NAT Gateway: Internet outbound từ private subnet 09/09/2025 09/09/2025 3 Bảo mật VPC:\n+ Security Group (stateful, chỉ có allow rules, gắn vào ENI)\n+ Network ACL (stateless, inbound/outbound rules, gắn vào Subnet)\n+ VPC Flow Logs (theo dõi traffic, phát hiện request bị từ chối, lưu CloudWatch/S3)\n+ Kết nối Multi-VPC:\n+ VPC Peering: Kết nối 1:1, không hỗ trợ transitive routing, CIDR không trùng lặp\n+ Transit Gateway: Mô hình hub-and-spoke, đơn giản hóa định tuyến, cần TGW Attachment mỗi AZ\n+ Kết nối Hybrid:\n+ VPN Site-to-Site: Virtual Private Gateway (AWS) \u0026amp; Customer Gateway (On-premises)\n+ VPN Client-to-Site: chi phí cao, thường dùng giải pháp bên thứ 3\n+ Direct Connect: Kết nối chuyên dụng/hosted, độ trễ ổn định (20–30ms), nhà cung cấp VN (Viettel, FPT)\n+ Elastic Load Balancing (ELB):\n+ Khái niệm: health check, sticky session, access log (lưu S3)\n+ Các loại:\n- Application Load Balancer (Layer 7, HTTP/HTTPS, path-based routing)\n- Network Load Balancer (Layer 4, TCP/TLS, static IP, hiệu năng cao)\n- Classic Load Balancer (Layer 4 \u0026amp; 7, cũ)\n- Gateway Load Balancer (Layer 3, điều hướng traffic appliance) 10/09/2025 10/09/2025 4 - Ôn tập:\n- Hệ thống lại kiến thức từ Ngày 2 \u0026amp; Ngày 3: VPC, Subnet, Route Table, Internet Gateway, NAT Gateway, Security Group, Network ACL, VPC Peering, Transit Gateway, VPN, Direct Connect, Elastic Load Balancing.\n+ Lab:\n- Lab 1:\n+ Tạo VPC, Subnet, Internet Gateway, Route Table, Security Group.\n+ Bật VPC Flow Logs.\n+ Khởi chạy EC2 instance và test kết nối SSH.\n+ Tạo NAT Gateway cho Private Subnet có Internet outbound.\n+ Sử dụng Reachability Analyzer để kiểm tra kết nối mạng.\n+ Quản lý EC2 bằng AWS Systems Manager Session Manager.\n+ Bật CloudWatch Monitoring \u0026amp; Alerting để giám sát EC2.\n- Lab 2:\n+ Lặp lại các bước để củng cố kiến thức và kỹ năng thực hành. 11/09/2025 11/09/2025 5 - Thực hành trên AWS:\n+ Lab 02-02: Session Manager (chuẩn bị, kết nối EC2, quản lý session logs, port forwarding)\n+ Lab 02-03: VPC Peering (chuẩn bị, cập nhật Network ACL, tạo kết nối peering, cấu hình route table, bật cross-peer DNS)\n+ Lab 02-04: Transit Gateway (thiết lập hạ tầng, tạo TGW, TGW attachments, tạo TGW route table, thêm gateway, kiểm tra kết quả)\n+ Lab 02-05: Hybrid DNS (thiết lập, tạo outbound endpoint, tạo Route 53 resolver rule, tạo inbound endpoint) 12/09/2025 12/09/2025 Thành tựu Tuần 1: Nắm vững kiến thức nền tảng về AWS và Điện toán đám mây\nHiểu khái niệm, lợi ích của cloud computing và hành trình chuyển đổi lên cloud. Nắm vững hạ tầng AWS: Region, AZ, Edge Location, Data Center. Thực hành công cụ quản lý AWS\nSử dụng thành thạo AWS Management Console, AWS CLI, AWS SDK. Tạo và quản lý IAM Users/Groups, kích hoạt MFA, cấu hình Access Keys. Quản lý chi phí và hỗ trợ AWS\nTạo và quản lý các loại Budget khác nhau. Tìm hiểu các gói Support Plans và thực hành mở case hỗ trợ. Kiến thức Networking \u0026amp; Security trên AWS\nXây dựng và cấu hình VPC, Subnet, Route Table, Internet Gateway, NAT Gateway. Triển khai Security Group, Network ACL, VPC Flow Logs. So sánh VPC Peering và Transit Gateway, tìm hiểu kết nối Hybrid (VPN, Direct Connect). Quản lý hệ thống trên AWS\nQuản lý EC2 bằng Session Manager thay vì SSH. Thực hành Port Forwarding và quản lý Session Logs. Bật giám sát bằng CloudWatch Monitoring \u0026amp; Alerts. Giải pháp nâng cao\nCấu hình VPC Peering và Transit Gateway để kết nối nhiều VPC. Thiết lập Hybrid DNS với Route 53 Resolver (Inbound/Outbound Endpoints). Thực hành với Elastic Load Balancer (ALB, NLB, CLB, GWLB). 👉 Kết quả: Sau Tuần 1, tôi đã xây dựng nền tảng vững chắc về AWS cơ bản và các khái niệm mạng ở mức trung cấp, đồng thời hoàn thành nhiều bài Lab trực tiếp trên AWS để rèn luyện kỹ năng thực hành.\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu tuần 2: Học và thực hành dịch vụ Compute của AWS (EC2, AMI, EBS, Auto Scaling, ELB). Nắm vững kỹ năng giám sát và sao lưu với CloudWatch và AWS Backup. Tìm hiểu dịch vụ lưu trữ: S3, Storage Gateway, FSx. Thực hành triển khai, mở rộng và host website tĩnh. Các công việc cần triển khai trong tuần này: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 Lý thuyết (Module 03 – Máy ảo Compute trên AWS)\n- Tìm hiểu Amazon EC2: khái niệm, kiến trúc, loại instance, hypervisor Nitro.\n- Các thành phần liên quan: AMI, Backup, Snapshot, Key Pair.\n- Hiểu cách sử dụng Elastic Block Store (EBS) và Instance Store.\n- Tìm hiểu User Data \u0026amp; Meta Data cho tự động hóa EC2.\n- EC2 Auto Scaling và các mô hình giá: On-demand, Reserved, Saving Plans, Spot.\n- Tổng quan về Amazon Lightsail, Amazon EFS, Amazon FSx, AWS Application Migration Service (MGN).\nThực hành (Lab 04 – Amazon EC2)\n- Khởi chạy và làm quen với các tính năng cơ bản của EC2.\n- Cấu hình Linux VPC và Windows VPC với Security Groups.\n- Kết nối tới EC2:\n• Windows qua RDP (3389) dùng Key Pair.\n• Linux qua SSH bằng MobaXterm và PuTTY.\n- Thực hiện các thao tác:\n• Thay đổi loại instance.\n• Tạo snapshot EBS.\n• Tạo AMI tùy chỉnh và khởi chạy instance từ AMI.\n• Truy cập EC2 không cần Key Pair bằng AWS Systems Manager (SSM).\n- Triển khai ứng dụng Node.js CRUD User Management trên cả Amazon Linux và Windows EC2. 14/09/2025 15/09/2025 2 Lab 06: EC2 Auto Scaling và Elastic Load Balancing\n- Triển khai ứng dụng bằng Auto Scaling Group để tăng khả năng mở rộng.\n- Sử dụng Elastic Load Balancer để phân phối tải ứng dụng.\n- Chuẩn bị hạ tầng mạng, khởi chạy EC2 và cấu hình RDS.\n- Tạo AMI và Launch Template cho triển khai đồng nhất.\n- Cấu hình Auto Scaling Group kết hợp Load Balancer đảm bảo HA \u0026amp; tiết kiệm chi phí.\nLab 08: Amazon CloudWatch\n- Khám phá CloudWatch để giám sát môi trường AWS, hybrid và on-premises.\n- Thu thập, phân tích log và metrics hiệu năng.\n- Cấu hình CloudFormation để tạo môi trường CloudWatch.\n- Thực hành Metrics: biểu đồ, phép tính, gán nhãn dữ liệu.\n- Thực hành Logs: thu thập tập trung, chính sách lưu giữ, phát hiện bất thường.\n- Thiết lập Alarms để giám sát và kích hoạt hành động.\n- Xây dựng Dashboards hiển thị real-time tình trạng hệ thống.\nLab 13: AWS Backup\n- Học AWS Backup để tạo kế hoạch sao lưu tự động cho EBS, RDS, DynamoDB, EFS.\n- Triển khai hạ tầng với CloudFormation và tạo S3 bucket lưu trữ.\n- Thiết kế Backup Plan dựa trên RTO và RPO.\n- Cấu hình thông báo qua SNS về trạng thái backup, khôi phục và lỗi. 16/09/2025 16/09/2025 3 Lý thuyết: Dịch vụ lưu trữ AWS (Amazon S3)\n- S3 là dịch vụ lưu trữ đối tượng:\n• Đối tượng bất biến, cập nhật phải re-upload.\n• Phù hợp dữ liệu WORM (Write Once Read Many).\n• Lưu trữ không giới hạn, 1 object ≤ 5TB.\n• Độ bền 99.999999999%, khả dụng 99.99%.\n• Mặc định replicate dữ liệu trên 3 AZ trong 1 Region.\n• Hỗ trợ multipart upload và trigger event.\n- Truy cập S3:\n• Giao thức REST API (PUT, GET).\n• URL object: https://bucket.s3.amazonaws.com/key\n- Access Point: hostname riêng cho từng app/user.\n- Storage Class: Standard, Standard-IA, Intelligent-Tiering, One Zone-IA, Glacier/Deep Archive.\n- Quản lý vòng đời object bằng Lifecycle Policy.\n- S3 Static Website \u0026amp; CORS: host web tĩnh, hỗ trợ cross-origin.\n- Access Control: ACL và Bucket Policy.\n- Endpoint \u0026amp; Versioning: truy cập nội bộ VPC, versioning chống xóa/ghi đè.\n- Object Key \u0026amp; Performance: partitioning, random prefix để tối ưu.\n- Glacier: lưu trữ chi phí thấp, truy xuất Expedited/Standard/Bulk, rẻ hơn S3 Standard 20 lần. 17/09/2025 17/09/2025 4 Lab 24: AWS Storage Gateway (File Gateway)\n- Chuẩn bị hạ tầng:\n• Tạo S3 Bucket backend.\n• Khởi chạy EC2 làm Storage Gateway.\n- Cấu hình Storage Gateway:\n• Tạo Gateway và File Share.\n• Mount File Share vào máy local.\n- Ghi chú:\n• Thực tế triển khai Appliance on-premises.\n• Hỗ trợ VMware, Hyper-V, KVM, Appliance vật lý. 18/09/2025 18/09/2025 5 Lab 25: Amazon FSx for Windows File Server\n- Tìm hiểu kiến trúc FSx:\n• File Servers (Windows File Server qua SMB).\n• Storage (lưu trên Amazon S3).\n• Networking (ENIs trong VPC).\n• Data Replication (tự động nhân bản đa AZ).\n• Quản lý và giám sát bởi AWS.\n- Triển khai FSx để cung cấp dịch vụ lưu trữ file dùng chung.\n- Học tích hợp với Windows Server, quản lý và truy cập dữ liệu.\nLab 57: Amazon S3 \u0026amp; Static Website Hosting\n- Ôn lại khái niệm S3: Bucket, Object (≤ 5TB).\n- Chuẩn bị hạ tầng:\n• Tạo bucket, cấu hình ACL và Public Access.\n• Upload và tổ chức object.\n- Cấu hình Static Website Hosting:\n• Bật hosting, khai báo index/error document.\n• Kiểm thử endpoint DNS.\n- Quản lý truy cập \u0026amp; bảo mật:\n• Điều chỉnh Block Public Access.\n• Gán ACL cho object.\n- Tăng tốc website bằng CloudFront:\n• Tạo Distribution liên kết bucket.\n• Cấu hình OAI, test endpoint CloudFront.\n- Tính năng bổ sung:\n• Bật Versioning phục hồi dữ liệu.\n• Thực hành di chuyển object giữa folder/bucket. 19/09/2025 19/09/2025 Kết quả đạt được tuần 2: Tính toán \u0026amp; Triển khai\nHiểu rõ kiến thức về Amazon EC2, kiến trúc và các thành phần liên quan (AMI, Snapshot, Key Pair, EBS). Triển khai và quản lý thành công EC2 cho cả Linux và Windows. Thực hành triển khai ứng dụng thực tế Node.js CRUD trên EC2. Nắm được các kỹ thuật tự động hóa với User Data, Meta Data, AWS Systems Manager. Khả năng mở rộng \u0026amp; Tính sẵn sàng cao\nTriển khai EC2 Auto Scaling Group để tự động điều chỉnh năng lực theo nhu cầu. Cấu hình Elastic Load Balancer (ELB) để phân phối lưu lượng. Tích hợp Auto Scaling với Load Balancer nhằm đảm bảo high availability và tối ưu chi phí. Giám sát \u0026amp; Quan sát hệ thống\nSử dụng Amazon CloudWatch để giám sát hạ tầng và ứng dụng. Tạo metrics, dashboards, alarms để theo dõi tình trạng hệ thống theo thời gian thực. Quản lý log tập trung với CloudWatch Logs, thiết lập chính sách lưu trữ và phát hiện bất thường. Thực hành thiết lập giám sát tự động qua CloudFormation. Bảo vệ \u0026amp; Sao lưu dữ liệu\nThiết kế AWS Backup Plans cho nhiều dịch vụ (EBS, RDS, DynamoDB, EFS). Áp dụng các mục tiêu RTO/RPO trong chiến lược khôi phục dữ liệu. Cấu hình SNS notifications để nhận thông báo trạng thái sao lưu và phục hồi. Lưu trữ \u0026amp; Quản lý dữ liệu\nHiểu rõ Amazon S3 là dịch vụ lưu trữ đối tượng với lifecycle policies và storage classes. Thực hành các tính năng: versioning, ACL, Bucket Policy, CORS. Cấu hình S3 Static Website Hosting và kiểm tra truy cập công khai. Tích hợp với CloudFront để tăng tốc độ phân phối nội dung và bảo mật bằng OAI. Tìm hiểu Amazon FSx for Windows File Server: kiến trúc, tích hợp Windows, và dịch vụ lưu trữ file được quản lý hoàn toàn. "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":"Mục tiêu tuần 3: Hiểu triết lý bảo mật AWS (“Security is Job Zero”) và Mô hình Trách nhiệm chia sẻ. Thành thạo các dịch vụ Quản lý danh tính \u0026amp; truy cập: IAM Users, Groups, Roles, Policies, Permission Boundaries, Organizations, Identity Center, Cognito. Ứng dụng AWS KMS để mã hóa dữ liệu, tích hợp CloudTrail và phân tích logs bằng Athena. Nắm vững các dịch vụ cơ sở dữ liệu AWS: RDS, Aurora, Redshift, ElastiCache và các khái niệm cơ bản SQL, NoSQL, OLTP, OLAP. Triển khai Amazon RDS với Multi-AZ, subnet groups, backup/restore để đảm bảo tính sẵn sàng và khả năng phục hồi. Các công việc cần triển khai trong tuần này: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 Module 05: Dịch vụ bảo mật trên AWS\n- Tìm hiểu triết lý bảo mật của AWS\n- Hiểu nguyên tắc “Security is Job Zero” — bảo mật là ưu tiên hàng đầu trong các dịch vụ AWS.\n- Mô hình chia sẻ trách nhiệm\n- AWS bảo mật hạ tầng, lưu trữ, tính toán và các dịch vụ được quản lý.\n- Khách hàng chịu trách nhiệm về cấu hình, mã hóa, xác thực, hệ điều hành, mạng và bảo mật cấp dữ liệu.\n- Nhận ra sự khác biệt về mức độ trách nhiệm tùy theo loại dịch vụ (hạ tầng, quản lý, toàn phần).\n- Quản lý danh tính và truy cập (IAM)\n- Tìm hiểu về rủi ro tài khoản Root và các thực hành tốt (hạn chế sử dụng, MFA, tách lưu trữ thông tin truy cập).\n- Hiểu các khái niệm IAM: Người dùng, Nhóm, Vai trò, Chính sách.\n- Phân biệt chính sách dựa trên danh tính và tài nguyên.\n- Khám phá IAM Role với thông tin truy cập tạm thời qua AWS STS (assume-role).\n- Amazon Cognito\n- User Pool: xác thực và đăng nhập cho ứng dụng.\n- Identity Pool: cung cấp quyền truy cập tài nguyên AWS sau khi xác thực.\n- Tích hợp xác thực với các nhà cung cấp xã hội (Google, Facebook, v.v.).\n- AWS Organizations\n- Quản lý nhiều tài khoản tập trung.\n- Tạo Đơn vị Tổ chức (OU), hợp nhất hóa đơn và Chính sách Kiểm soát Dịch vụ (SCPs).\n- AWS Identity Center\n- Quản lý truy cập tập trung trên các tài khoản AWS và ứng dụng bên ngoài.\n- Các bước: Nhóm người dùng → Tạo bộ quyền → Gán quyền truy cập.\n- AWS Key Management Service (KMS)\n- Dịch vụ tạo và quản lý khóa mã hóa.\n- Khóa do khách hàng quản lý (CMK) dùng để tạo khóa dữ liệu mã hóa/giải mã bên ngoài KMS.\n- AWS Security Hub\n- Dịch vụ kiểm tra bảo mật liên tục tuân thủ thực hành tốt và tiêu chuẩn AWS.\n- Cung cấp điểm số bảo mật và xác định tài nguyên/tài khoản cấu hình sai. 22/09/2025 22/09/2025 2 Lab 02: Kiến thức cơ bản về AWS IAM\n- Tìm hiểu nền tảng IAM: Người dùng, Nhóm, Vai trò, Chính sách.\n- Khám phá các thực hành tốt với nguyên tắc quyền tối thiểu.\n- Hiểu các phương thức xác thực IAM: mật khẩu, khóa truy cập, thông tin truy cập tạm thời qua AWS STS.\n- Thực hành tạo và quản lý Người dùng và Nhóm IAM.\nLab 44: Vai trò \u0026amp; Điều kiện IAM\n- Ôn lại luồng yêu cầu IAM: chủ thể, hành động, tài nguyên, dữ liệu môi trường.\n- Thực hành quá trình xác thực và nhận vai trò bằng sts:AssumeRole.\n- Tạo Nhóm IAM với các chính sách: AmazonEC2FullAccess, AmazonRDSFullAccess, DatabaseAdministrator.\n- Tạo nhiều Người dùng IAM: EC2-admin-user, RDS-admin-user, Group-user, và No-permission-user.\n- Cấu hình Vai trò IAM với Điều kiện:\n- Giới hạn quyền truy cập vai trò theo địa chỉ IP.\n- Áp dụng điều kiện thời gian tăng cường bảo mật.\nLab 48: Vai trò IAM cho ứng dụng\n- So sánh sử dụng Access Keys và IAM Role trên EC2:\n- Nhấn mạnh rủi ro bảo mật khi mã hóa cứng Access Keys trong ứng dụng.\n- Chỉ ra cách IAM Role loại bỏ rủi ro bằng cách tự động cấp quyền tạm thời.\n- Triển khai EC2 instance với IAM Role, cho phép truy cập an toàn đến S3 mà không cần quản lý Access Keys. 23/09/2025 23/09/2025 3 Lab 18: Liên kết danh tính với Amazon Cognito\n- Tìm hiểu về liên kết danh tính với Amazon Cognito.\n- Cấu hình User Pool và Identity Pool hỗ trợ xác thực từ nhiều nguồn (Google, Facebook, SAML).\n- Thực hành tạo ứng dụng khách, tích hợp và xác thực người dùng.\nLab 27: Vai trò IAM\n- Hiểu khái niệm Vai trò IAM và sự khác biệt với Người dùng IAM.\n- Gán Vai trò cho EC2 để truy cập tài nguyên AWS mà không cần mã hóa thông tin truy cập.\n- Thực hiện nguyên tắc quyền tối thiểu với Vai trò IAM.\nLab 28: Nhóm và Chính sách IAM\n- Tạo Nhóm IAM và thêm nhiều Người dùng vào nhóm.\n- Gắn chính sách cho Nhóm để quản lý quyền tập trung.\n- Thực hành viết và áp dụng chính sách IAM bằng JSON.\nLab 30: Giới hạn quyền IAM\n- Tìm hiểu về Giới hạn quyền để giới hạn quyền tối đa cho Người dùng/Nhóm.\n- Tạo chính sách giới hạn quyền truy cập EC2 đầy đủ cho một vùng duy nhất.\n- Gán cả chính sách dựa trên danh tính và giới hạn quyền cho Người dùng, quan sát hiệu quả quyền kết hợp.\nLab 33: Mã hóa dữ liệu lưu trữ với AWS KMS\n- Tìm hiểu về AWS KMS: sử dụng khóa đối xứng \u0026amp; bất đối xứng.\n- Tạo CMK, cấu hình chính sách khóa, tích hợp CloudTrail để giám sát.\n- Thực hành mã hóa dữ liệu trong S3 bằng KMS.\n- Sử dụng CloudTrail để ghi lại mọi hoạt động liên quan đến khóa.\n- Truy vấn log với Amazon Athena để phân tích quyền truy cập và kiểm tra tuân thủ. 24/09/2025 24/09/2025 4 Lý thuyết: Dịch vụ cơ sở dữ liệu AWS\n- Ôn lại các khái niệm cơ bản về cơ sở dữ liệu:\n- Khóa chính, khóa ngoại, đánh chỉ mục, phân vùng, kế hoạch thực thi, log, bộ đệm.\n- Phân biệt RDBMS (SQL) và cơ sở dữ liệu NoSQL.\n- Hiểu sự khác biệt OLTP (xử lý giao dịch) và OLAP (xử lý phân tích).\n- Amazon RDS (Dịch vụ cơ sở dữ liệu quan hệ):\n- Tìm hiểu các tính năng quản lý: tự động sao lưu, bản sao đọc, chuyển đổi dự phòng Multi-AZ, mã hóa, tự động mở rộng.\n- Hiểu rằng RDS dựa trên EC2 nhưng do AWS quản lý toàn bộ.\n- Amazon Aurora:\n- RDBMS hiệu năng cao, tối ưu cho AWS, tương thích MySQL và PostgreSQL.\n- Tính năng: Backtrack, Cloning, Global Database, kiến trúc Multi-Master.\n- Amazon Redshift:\n- Giải pháp kho dữ liệu tối ưu cho OLAP và phân tích dữ liệu lớn.\n- Sử dụng lưu trữ dạng cột, kiến trúc MPP, node trưởng/nút tính toán.\n- Tối ưu hóa chi phí: Transient Cluster, Redshift Spectrum (truy vấn dữ liệu trên S3).\n- Amazon ElastiCache:\n- Dịch vụ bộ nhớ đệm quản lý (Redis, Memcached).\n- Tăng hiệu năng ứng dụng bằng cách giảm tải truy vấn thường xuyên từ cơ sở dữ liệu.\n- Yêu cầu logic bộ đệm phía ứng dụng. 25/09/2025 25/09/2025 5 Lab 05: Dịch vụ cơ sở dữ liệu quan hệ Amazon (RDS)\n- Tìm hiểu Amazon RDS là dịch vụ cơ sở dữ liệu quan hệ quản lý:\n- Hỗ trợ OLTP, dữ liệu có cấu trúc và quan hệ.\n- Lợi ích: tự động sao lưu, cập nhật bản vá, mở rộng, sao chép, độ sẵn sàng cao.\n- Tìm hiểu các hệ quản trị cơ sở dữ liệu hỗ trợ: Aurora, MySQL, MariaDB, Oracle, SQL Server, PostgreSQL.\n- Chuẩn bị hạ tầng:\n- Tạo VPC với subnet cho triển khai Multi-AZ.\n- Cấu hình Security Group EC2 cho máy chủ ứng dụng.\n- Cấu hình Security Group RDS (tách biệt với EC2 để tăng bảo mật).\n- Tạo nhóm Subnet DB với subnet riêng cho RDS.\n- Triển khai EC2 instance để kết nối với RDS.\n- Tạo RDS Database Instance với cả Easy Create và tùy chọn nâng cao.\n- Triển khai ứng dụng sử dụng RDS làm cơ sở dữ liệu backend.\n- Thực hành sao lưu và phục hồi:\n- Sao lưu tự động và snapshot thủ công.\n- Khôi phục dữ liệu theo điểm thời gian để bảo vệ dữ liệu. 26/09/2025 26/09/2025 Kết quả đạt được tuần 3: Dịch vụ bảo mật:\nÁp dụng thực tế Mô hình Trách nhiệm chia sẻ. Quản lý IAM với Users, Groups, Roles, Policies, Conditions và Permission Boundaries. Tích hợp IAM Role với EC2 để loại bỏ rủi ro khi dùng Access Keys cố định. Thực hành Liên kết danh tính (Identity Federation) với Cognito (Google, Facebook, SAML). Quản lý tập trung nhiều tài khoản bằng AWS Organizations và Identity Center. Mã hóa \u0026amp; Giám sát:\nTạo và quản lý KMS CMK cho việc mã hóa. Mã hóa dữ liệu trong S3 bằng KMS. Ghi lại hoạt động khóa với CloudTrail và phân tích bằng Athena. Dịch vụ cơ sở dữ liệu:\nHiểu sự khác biệt giữa RDBMS và NoSQL, OLTP và OLAP. Triển khai Amazon RDS với Multi-AZ, subnet groups, backup tự động, snapshots, và phục hồi theo thời gian (point-in-time recovery). Nghiên cứu Aurora (Backtrack, Global DB, Cloning), Redshift (MPP, Spectrum), và ElastiCache (Redis, Memcached). Thực hành:\nHoàn thành nhiều bài lab: IAM Basics, IAM Roles \u0026amp; Conditions, IAM Roles for Applications, Cognito Federation, IAM Permission Boundaries, KMS Encryption, RDS Deployment. Xây dựng được môi trường RDS an toàn với khả năng backup và phục hồi dữ liệu. "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4","tags":[],"description":"","content":"Mục tiêu Tuần 4: Mục tiêu của tuần này là củng cố hiểu biết về các dịch vụ dữ liệu và AI của AWS — từ xây dựng kiến trúc DataLake có khả năng mở rộng đến làm việc với cơ sở dữ liệu NoSQL serverless (DynamoDB) và khám phá quản lý vòng đời phát triển AI. Ngoài ra, tuần này còn nhằm nâng cao kỹ năng dịch thuật kỹ thuật và kỹ năng giao tiếp thông qua các lab thực hành, dịch blog và tham gia các sự kiện của AWS. Các nhiệm vụ thực hiện trong tuần này: Day Task Start Date Completion Date Reference Material 1 Lab 35: DataLake trên AWS\n- Giới thiệu về DataLake:\n- Hiểu DataLake như một kho tập trung lưu trữ dữ liệu thô và đã xử lý để phục vụ phân tích và khai thác thông tin.\n- Nắm các đặc tính chính: thu thập tất cả dữ liệu, truy cập đa người dùng, và mô hình truy cập linh hoạt (batch, interactive, real-time, search).\n- Hiểu cách các dịch vụ AWS (Glue, Athena, QuickSight) tích hợp để xây dựng một giải pháp DataLake hoàn chỉnh.\n- Amazon Glue (dịch vụ ETL):\n- Tìm hiểu về Glue Crawlers để phát hiện schema tự động và tạo Glue Data Catalog.\n- Hiểu cách Glue ETL job sinh script Python tùy chỉnh cho chuyển đổi và nạp dữ liệu.\n- Thực hành tạo Crawler để quét dữ liệu trên S3 và xây dựng Data Catalog cho truy vấn.\n- Amazon Athena (dịch vụ truy vấn tương tác):\n- Athena cho phép truy vấn dữ liệu trên S3 bằng SQL tiêu chuẩn mà không cần pipeline ETL phức tạp.\n- Cấu hình Athena để truy vấn dataset trên S3 và hiểu mô hình chi phí (trả theo truy vấn).\n- Khám phá các định dạng dữ liệu Athena hỗ trợ (CSV, JSON, ORC, Avro, Parquet).\n- Amazon QuickSight (dịch vụ trực quan hóa dữ liệu):\n- Tìm hiểu cách QuickSight kết nối với nguồn dữ liệu và xây dựng dataset để trực quan hóa.\n- Tạo biểu đồ, phân tích và dashboard để thể hiện các chỉ số kinh doanh chính.\n- Hiểu cấu trúc QuickSight: Datasource → Dataset → Analysis → Visual → Dashboard.\n- Các bước triển khai:\n- Tạo IAM Role với quyền S3FullAccess và AWSGlueServiceRole.\n- Chuẩn bị cấu trúc bucket S3 (/data, /ref_data) và tải file lên.\n- Thiết lập Kinesis Delivery Stream để liên tục đưa dữ liệu vào S3.\n- Triển khai stack CloudFormation để tự động hóa hạ tầng.\n- Chạy AWS Glue Crawler để catalog dữ liệu S3 và xác thực bằng Amazon Athena.\n- Khởi chạy SageMaker Notebook qua Glue Studio để thực hiện workflow chuyển đổi dữ liệu bổ sung. 29/09/2025 29/09/2025 2 Lab40:\n- Ôn lại AWS Glue như một dịch vụ ETL quản lý (Extract – Transform – Load) hỗ trợ chuẩn bị dữ liệu cho phân tích. - Hiểu workflow: 1. Tải dữ liệu thô lên Amazon S3. 2. Dùng Glue Crawler để phát hiện schema và tạo database trong Glue Data Catalog. 3. Chuyển đổi dữ liệu sang định dạng tối ưu như Parquet. 4. Truy vấn dữ liệu đã chuyển đổi bằng Amazon Athena. - Cấu hình AWS Glue và Athena cho cập nhật schema tự động và lên lịch chạy crawler. - Thực thi các truy vấn SQL trong Athena để phân tích: - Top 10 tài khoản và dịch vụ AWS có chi phí cao nhất. - Phân tích chi tiết chi phí theo dịch vụ và tag (ví dụ: cost_center). - Phân tách các kỳ tính phí và loại sử dụng. - Học cách tối thiểu hóa chi phí truy vấn Athena bằng: - Sử dụng file Parquet nén. - Hạn chế kết quả truy vấn bằng LIMIT. - Cấu trúc dữ liệu hiệu quả cho truy vấn phân vùng. - Khám phá phân bổ chi phí và tagging cho theo dõi chi phí cấp doanh nghiệp. 30/09/2025 30/09/2025 3 Lab 60: Amazon DynamoDB\n- Tổng quan:\n- Nghiên cứu Amazon DynamoDB — dịch vụ cơ sở dữ liệu NoSQL được quản lý hoàn toàn, cung cấp hiệu năng nhanh và khả năng mở rộng mượt mà.\n- Hiểu cách DynamoDB tự động quản lý hạ tầng, scale và sao chép dữ liệu giữa các Availability Zone.\n- Khám phá các tính năng như chế độ dung lượng on-demand và provisioned, mã hoá dữ liệu khi lưu trữ, point-in-time recovery, và tự động xoá item khi hết hạn.\n- Thành phần chính:\n- Table: Tập hợp logic của các item (tương tự bảng trong DB quan hệ).\n- Item: Bản ghi riêng lẻ trong table (tương tự hàng).\n- Attribute: Thuộc tính trong item (tương tự cột).\n- Khóa chính:\n- Tìm hiểu về Partition Key và Composite Primary Key (Partition + Sort Key) để xác định duy nhất item.\n- Hiểu cách composite key cải thiện tính linh hoạt khi truy vấn.\n- Secondary Indexes:\n- Thực hành sử dụng Global Secondary Index (GSI) và Local Secondary Index (LSI) để tối ưu hiệu năng truy vấn.\n- Nhận biết DynamoDB hỗ trợ tới 20 GSI và 5 LSI cho mỗi bảng.\n- Read Consistency:\n- So sánh Eventually Consistent Reads (nhanh hơn, có thể đọc dữ liệu cũ) và Strongly Consistent Reads (luôn đọc dữ liệu mới nhất, chậm hơn và tốn kém hơn).\n- Chế độ dung lượng đọc/ghi:\n- On-Demand Mode: Phù hợp cho workload không dự báo trước, tự động scale theo nhu cầu.\n- Provisioned Mode: Thích hợp cho workload có thể dự đoán với lưu lượng ổn định hoặc có kế hoạch.\n- Triển khai:\n- Khám phá AWS Management Console và AWS CloudShell để thiết lập và quản lý DynamoDB.\n- Học cách dùng AWS SDK (Boto3) để tương tác chương trình với bảng DynamoDB. 01/10/2025 01/10/2025 4 Hoạt động: Dịch các bài blog kỹ thuật AWS\nNội dung đã dịch:\n- “Accelerating Generative AI Development with Fully Managed MLflow 3.0 on Amazon SageMaker AI” – Tìm hiểu cách AWS tích hợp MLflow để quản lý vòng đời mô hình Generative AI.\n- “AI-Enhanced Subsurface Infrastructure Mapping on AWS” – Hiểu cách deep learning và HPC được áp dụng để phát hiện cơ sở hạ tầng ngầm.\n- “Unlocking the Full Potential of Amazon Connect” – Nắm bắt các best practice khi triển khai trung tâm liên lạc được hỗ trợ AI trên AWS.\nKỹ năng đạt được:\n- Cải thiện kỹ năng dịch thuật kỹ thuật (AI, HPC, Cloud Computing).\n- Hiểu sâu hơn về các dịch vụ AWS: SageMaker, Batch, ParallelCluster và Amazon Connect.\n- Mở rộng vốn từ kỹ thuật tiếng Anh liên quan đến cloud và AI. 2/10/2025 2/10/2025 5 Hoạt động: Tham dự sự kiện AWS về AI Development Lifecycle và giới thiệu Kiro\nChi tiết:\n- Tham gia sự kiện do AWS tổ chức tập trung vào Vòng đời phát triển AI, bao quát các giai đoạn chính từ chuẩn bị dữ liệu, huấn luyện và đánh giá mô hình đến triển khai và giám sát liên tục.\n- Tìm hiểu cách các dịch vụ AWS như Amazon SageMaker, Bedrock và CodeWhisperer hỗ trợ quy trình phát triển và tối ưu mô hình AI.\n- Tham dự phần giới thiệu chi tiết về Kiro – một giải pháp AWS mới nhằm đơn giản hóa và hợp nhất quản lý workflow AI giữa các đội.\n- Hiểu cách Kiro tích hợp với các công cụ AWS khác để quản lý dataset, phiên bản mô hình và tracking experiment hiệu quả hơn, nâng cao hợp tác và quản trị.\n- Khám phá các case study thực tế cho thấy tổ chức tận dụng hạ tầng AWS để tăng tốc tự động hoá nhờ AI, giảm thời gian huấn luyện và cải thiện độ tin cậy mô hình trong môi trường production.\nKỹ năng đạt được:\n- Nâng cao hiểu biết về vòng đời phát triển AI trong hệ sinh thái AWS.\n- Học các ứng dụng thực tiễn của quản lý vòng đời mô hình bằng dịch vụ AWS và Kiro.\n- Tăng kiến thức về observability mô hình, tracking experiment và best practice triển khai.\n- Củng cố vốn từ kỹ thuật và kỹ năng giao tiếp liên quan đến AI, ML và Cloud Computing. 3/10/2025 3/10/2025 Thành tựu Tuần 4: Xây dựng pipeline DataLake trên AWS tích hợp Glue, Athena và QuickSight, có kinh nghiệm thực hành trong ingest, chuyển đổi và trực quan hóa dữ liệu. Cấu hình AWS Glue Crawlers và truy vấn Athena cho phân tích chi phí và tự động hóa schema, áp dụng các chiến lược tối ưu chi phí (ví dụ: Parquet, partitioning, giới hạn truy vấn). Nắm vững các kiến thức cơ bản về DynamoDB, bao gồm khóa chính/khóa hợp nhất, index (GSI, LSI), mô hình nhất quán đọc và chế độ dung lượng. Nâng cao kỹ năng dịch và hiểu nội dung kỹ thuật bằng cách dịch các bài blog kỹ thuật về AI, MLflow và HPC, nắm vững các dịch vụ như SageMaker, Batch, ParallelCluster và Connect. Tham gia một sự kiện AWS tập trung vào AI Development Lifecycle và Kiro, thu nhận kiến thức về quản lý phiên bản mô hình, theo dõi thử nghiệm và best practice triển khai. Cải thiện vốn từ kỹ thuật và hiểu biết thực tiễn về thiết kế kiến trúc dữ liệu, quản trị mô hình AI và cloud computing trong hệ sinh thái AWS. "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 5: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 6: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 7: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 8: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 9: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"Personal Finance Management App 1. Tóm tắt điều hành Dự án Personal Finance Management App hướng đến việc cung cấp một nền tảng quản lý tài chính cá nhân thông minh, hiện đại và mang tính tự động hóa cao. Ứng dụng cho phép người dùng ghi nhận thu chi, tạo và quản lý nhiều hũ tiền (money jars) theo mục đích khác nhau, lập kế hoạch chi tiêu, nhận cảnh báo thông minh và tạo báo cáo phân tích trực quan.\nỨng dụng được xây dựng với kiến trúc microservices trên nền tảng .NET và FastAPI, triển khai trên AWS Cloud, đảm bảo tính linh hoạt, khả năng mở rộng và an toàn dữ liệu. Quy trình phát triển tuân theo mô hình Agile/Scrum (2 tuần/sprint), với thời gian hoàn thành MVP trong 2 tháng.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nTrên thị trường đã có rất nhiều ứng dụng quản lý tài chính, tuy nhiên phần lớn vẫn yêu cầu người dùng nhập liệu thủ công — một công việc tốn thời gian, dễ sai sót và khiến người dùng nhanh chóng bỏ cuộc. Các ứng dụng hiện có chỉ tập trung vào thống kê chi tiêu mà chưa thực sự giúp người dùng tự động hóa quy trình quản lý tài chính cá nhân.\nGiải pháp\nGiải pháp sử dụng AWS Cloud kết hợp kiến trúc microservices để xây dựng một nền tảng quản lý tài chính cá nhân tự động hóa, tích hợp AI trong xử lý giọng nói và nhận diện hóa đơn. Hệ thống được triển khai trên AWS ECS Fargate cho các service backend (.NET), FastAPI cho xử lý AI, và Next.js cho frontend. So với các nền tảng tài chính phổ biến như Money Lover hay Misa Money Keeper, ứng dụng này tập trung vào tự động hóa hoàn toàn nhập liệu tài chính thông qua AI voice-to-text và bill scanning chi tiết tiếng Việt, giúp giảm thao tác thủ công và sai sót. Hệ thống phù hợp cho người dùng cá nhân và nhóm nhỏ, đồng thời có thể mở rộng khi cần cho quy mô doanh nghiệp hoặc ứng dụng ngân hàng số.\nLợi ích và hoàn vốn đầu tư (ROI)\nGiải pháp mang lại nhiều lợi ích thiết thực cả về mặt kỹ thuật và giá trị kinh doanh:\nTự động hóa nhập liệu: Giảm hơn 70% thao tác thủ công nhờ AI nhận diện giọng nói và hóa đơn. Tăng độ chính xác: Hạn chế sai sót nhập liệu, đảm bảo tính toàn vẹn của dữ liệu tài chính (\u0026gt;90% chính xác). Cải thiện hiệu suất người dùng: Ghi nhận và phân loại giao dịch chỉ trong vài giây, tối ưu trải nghiệm sử dụng. Tiết kiệm chi phí: Chi phí hạ tầng thấp nhờ tận dụng AWS Free Tier đến năm 2026; chỉ ước tính ~60 USD/tháng cho AWS và ~30 USD cho compute AI. Hoàn vốn nhanh: Dự kiến hoàn vốn trong 6–12 tháng, nhờ tiết kiệm thời gian nhập liệu và tăng hiệu suất vận hành. Khả năng mở rộng \u0026amp; tích hợp: Kiến trúc microservices trên AWS cho phép dễ dàng bổ sung tính năng (mobile app, phân tích nâng cao, tích hợp ngân hàng). 3. Kiến trúc giải pháp Hệ thống được triển khai theo mô hình microservices trên nền tảng AWS Cloud, kết hợp các dịch vụ serverless, container, và cơ sở dữ liệu quản lý để đảm bảo hiệu năng và khả năng mở rộng.\nNgười dùng truy cập ứng dụng web Next.js thông qua Amazon CloudFront, nội dung tĩnh được lưu trữ trong Amazon S3 và phân phối qua Amazon Route 53. Lớp bảo mật đầu tiên được cung cấp bởi AWS WAF nhằm ngăn chặn các tấn công phổ biến như SQL Injection hoặc XSS.\nKhi người dùng đăng nhập, quá trình xác thực được xử lý bởi Amazon Cognito, cấp token truy cập để frontend gửi các yêu cầu API qua Amazon API Gateway. API Gateway định tuyến yêu cầu đến Application Load Balancer (ALB) thông qua AWS PrivateLink, sau đó chuyển tiếp đến Amazon ECS (Fargate) — nơi triển khai các container backend bao gồm:\nBackend Service (.NET): Xử lý nghiệp vụ chính của hệ thống.\nAI Service (FastAPI): Xử lý hóa đơn, nhận dạng giọng nói và các tác vụ AI.\nKhi người dùng tải hóa đơn hoặc ghi âm, file tạm thời được lưu trong Amazon S3.\nAI Service có thể truy cập tệp từ Amazon S3 để thực hiện các xử lý dữ liệu, sau đó trả kết quả lại cho Backend Service thông qua message broker.\nHình ảnh container được lưu trữ trong Amazon ECR, và quá trình triển khai được tự động hóa qua GitLab CI/CD Pipeline — bao gồm các bước build image, push lên ECR, và cập nhật Task Definition trên ECS.\nTất cả logs, metrics và cảnh báo từ ECS, API Gateway, và ALB được gửi về Amazon CloudWatch để giám sát tập trung, đồng thời Amazon SNS được cấu hình để gửi cảnh báo tự động khi có sự cố.\nDịch vụ AWS sử dụng\nAmazon Route 53: Quản lý DNS và tên miền truy cập. AWS WAF: Bảo vệ hệ thống khỏi các tấn công web phổ biến. Amazon CloudFront: Phân phối nội dung tĩnh toàn cầu và tăng tốc truy cập frontend. Amazon S3: Lưu trữ website tĩnh và file người dùng (hóa đơn, ghi âm). Amazon Cognito: Xác thực và quản lý người dùng. Amazon API Gateway: Cổng vào của hệ thống, định tuyến request từ frontend đến backend. AWS PrivateLink: Tạo kết nối riêng giữa API Gateway và ALB trong VPC để tăng cường bảo mật. Application Load Balancer (ALB): Cân bằng tải giữa các container backend trên ECS. Amazon ECS (Fargate): Chạy các microservices Backend và FastAPI (AI). Amazon ECR: Kho lưu trữ image container cho ECS. Amazon CloudWatch: Giám sát logs, hiệu năng và cảnh báo hệ thống. Amazon SNS: Gửi thông báo hoặc cảnh báo khi có sự cố. GitLab CI/CD: Tự động hóa pipeline build, push và deploy container lên ECS. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nDự án được chia thành 3 giai đoạn chính, tập trung vào việc xây dựng, tối ưu và triển khai nền tảng quản lý tài chính cá nhân trên AWS:\nNghiên cứu và vẽ kiến trúc: Nghiên cứu các mô hình microservices và thiết kế kiến trúc tổng thể trên AWS (bao gồm CloudFront, ECS Fargate, RDS, S3, API Gateway, Cognito) — (Tháng 1). Tính toán chi phí và điều chỉnh giải pháp: Sử dụng AWS Pricing Calculator để ước tính chi phí, tối ưu lựa chọn dịch vụ nhằm đảm bảo chi phí thấp và dễ triển khai cho người mới học — (Tháng 1–2). Phát triển, kiểm thử, triển khai: Xây dựng frontend (Next.js), backend (.NET), và AI service (FastAPI); kiểm thử tích hợp microservices, sau đó triển khai toàn bộ hệ thống lên AWS bằng ECS Fargate và thiết lập giám sát qua CloudWatch — (Tháng 2–3). Yêu cầu kỹ thuật\nFrontend: Ứng dụng web Next.js được lưu trữ trong Amazon S3 và phân phối qua CloudFront, giao tiếp với backend thông qua API Gateway. Người dùng đăng nhập qua Amazon Cognito, nhận token để gọi API bảo mật.\nBackend: Viết bằng .NET hoặc framework tương tự, triển khai trên ECS Fargate. Các service xử lý nghiệp vụ người dùng, giao dịch và các yêu cầu từ frontend. Container image được lưu trong ECR, được cập nhật qua pipeline CI/CD từ GitLab. ALB được dùng để cân bằng tải giữa các container backend.\nAI Service: Viết bằng FastAPI, xử lý hình ảnh hóa đơn và giọng nói, kết nối đến S3 để đọc dữ liệu. Kết quả được trả về Backend Service thông qua API nội bộ.\nHạ tầng Cloud: Sử dụng Amazon VPC (multi-AZ), Application Load Balancer, và CloudWatch để giám sát. Hình ảnh container được lưu trữ trên ECR và triển khai qua ECS Fargate. CI/CD được thực hiện qua GitLab CI/CD để tự động hóa build và deploy.\nBảo mật: Quản lý quyền truy cập người dùng bằng Amazon Cognito. Sử dụng IAM Roles cho ECS, S3, CloudWatch, và API Gateway để giới hạn quyền truy cập. Security Group được cấu hình chặt chẽ giữa ECS, ALB và các dịch vụ khác để đảm bảo an toàn mạng. AWS WAF được cấu hình để bảo vệ tầng frontend khỏi các tấn công web phổ biến.\n5. Lộ trình \u0026amp; Mốc triển khai Trước thực tập (Tháng 0): 1 tháng lên kế hoạch. Thực tập (Tháng 1–3): Tháng 1: Học AWS và nâng cấp kỹ năng lập trình. Tháng 2: Thiết kế và điều chỉnh kiến trúc. Tháng 3: Triển khai, kiểm thử, đưa vào sử dụng. Sau triển khai: Nghiên cứu thêm về mobile và triển khai sau tháng thứ 4. 6. Ước tính ngân sách Chi phí hạ tầng Trong Free Tier (12 tháng đầu)\nAmazon ECS (Fargate): 0,00 USD/tháng (≤ 50 GB-hr CPU, 200 GB-hr RAM). Amazon API Gateway: 0,00 USD/tháng (≤ 1 triệu request). Amazon S3: 0,00 USD/tháng (≤ 5 GB lưu trữ). Amazon CloudWatch: 0,00 USD/tháng (≤ 10 custom metrics + 5 GB logs). Amazon Cognito: 0,00 USD/tháng (≤ 50.000 người dùng hoạt động). Amazon ECR: 0,00 USD/tháng (500 MB lưu trữ image). Amazon Route 53: 1,00 USD/tháng (1 domain). GitLab CI/CD: 0,00 USD/tháng (≤ 2.000 phút build miễn phí). AWS WAF: 0,00 USD/tháng (Free Tier demo). Amazon SNS: 0,00 USD/tháng (≤ 1.000 thông báo đầu tiên). Tổng: ≈ 1,00 USD/tháng, tương đương 12,00 USD/năm trong giai đoạn Free Tier.\nSau khi hết Free Tier (với 50–100 người dùng)\nAmazon ECS (Fargate): 18,00 USD/tháng (3 container nhỏ chạy 24/7, ~0.25 vCPU, 0.5 GB RAM mỗi container). Amazon API Gateway: 3,50 USD/tháng (≈ 2–3 triệu request). Amazon S3: 2,50 USD/tháng (50 GB lưu trữ + 10.000 request). Amazon CloudWatch: 3,50 USD/tháng (log + metric cơ bản). Amazon Cognito: 0,50 USD/tháng (50–100 active user). Amazon ECR: 0,50 USD/tháng (1 GB image lưu trữ). Amazon Route 53: 1,00 USD/tháng (1 domain). AWS WAF: 2,00 USD/tháng (1 WebACL). Amazon SNS: 1,00 USD/tháng (vài nghìn thông báo). GitLab CI/CD: 2,00 USD/tháng (vượt giới hạn free). Tổng: ≈ 34,50 USD/tháng, tương đương 414,00 USD/năm sau khi hết Free Tier.\n7. Đánh giá rủi ro Ma trận rủi ro\nMô hình AI nhận dạng sai (voice/bill): Ảnh hưởng trung bình, xác suất trung bình. Mất kết nối AWS hoặc lỗi dịch vụ vùng (region): Ảnh hưởng cao, xác suất thấp. Vượt ngân sách sử dụng AWS: Ảnh hưởng trung bình, xác suất thấp. Lỗi đồng bộ dữ liệu giữa các microservices: Ảnh hưởng trung bình, xác suất trung bình. Lộ thông tin người dùng (Cognito/Database): Ảnh hưởng cao, xác suất thấp. Chiến lược giảm thiểu\nAI: Cải thiện mô hình OCR và voice-to-text qua huấn luyện thêm, kiểm thử định kỳ với dữ liệu thực tế. AWS Region: Thiết lập triển khai đa vùng (multi-AZ) và backup định kỳ cơ sở dữ liệu RDS. Chi phí: Cấu hình AWS Budget Alert và tối ưu ECS, S3 theo mức sử dụng thực tế. Microservices: Dùng SQS/RabbitMQ để đảm bảo xử lý bất đồng bộ và retry khi lỗi. Bảo mật: Mã hóa dữ liệu (AES-256, HTTPS), kiểm soát IAM theo nguyên tắc “Least Privilege”. Kế hoạch dự phòng\nNếu AWS gặp sự cố: Tạm thời chuyển sang lưu trữ dữ liệu giao dịch cục bộ và đồng bộ lại sau khi khôi phục. Khôi phục hạ tầng bằng AWS CloudFormation hoặc IaC (Infrastructure as Code) đã lưu sẵn. Giữ bản sao cơ sở dữ liệu định kỳ (RDS snapshot) để phục hồi trong tình huống mất dữ liệu. 8. Kết quả kỳ vọng của dự án Tự động hóa nhập liệu tài chính: Ứng dụng giúp người dùng không cần nhập thủ công, chỉ cần chụp hóa đơn hoặc ghi âm giọng nói để hệ thống tự phân loại chi tiêu. Quản lý tài chính trực quan: Người dùng có thể xem biểu đồ chi tiêu, báo cáo tháng, và nhận gợi ý tiết kiệm dựa trên hành vi tiêu dùng. Trải nghiệm người dùng tối giản: Giao diện web thân thiện, thiết kế hiện đại, tối ưu cho thiết bị di động và phù hợp với người mới quản lý tài chính. Hệ thống ổn định, dễ mở rộng: Kiến trúc microservices giúp dễ dàng bổ sung tính năng mới như nhắc nhở chi tiêu, phân tích dự báo AI, hoặc mở rộng sang mobile app. Chi phí vận hành thấp: Tận dụng Free Tier AWS và mô hình serverless để duy trì hệ thống với chi phí trung bình \u0026lt; 50 USD/tháng. Nâng cao kỹ năng nhóm phát triển: Thành viên dự án tiếp cận thực tế với quy trình DevOps, triển khai CI/CD, và tối ưu ứng dụng trên nền tảng cloud. 9. Hạn chế của dự án Mô hình AI tiếng Việt còn hạn chế: Khả năng nhận dạng giọng nói vùng miền hoặc hóa đơn viết tay chưa đạt độ chính xác cao. Chưa có ứng dụng di động riêng: Phiên bản MVP chỉ hỗ trợ nền web, chưa có mobile app native. Giới hạn người dùng: Kiến trúc hiện tại chỉ tối ưu cho 50–100 người dùng hoạt động; khi mở rộng quy mô cần tái cấu trúc hạ tầng. Phụ thuộc kết nối Internet: Mọi thao tác xử lý và lưu trữ đều qua cloud, không thể hoạt động offline. Chưa triển khai hệ thống bảo mật nâng cao: Mới dừng ở xác thực Cognito và mã hóa cơ bản, chưa có MFA (Multi-Factor Authentication) hay log bảo mật chuyên sâu. "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.2-prerequiste/","title":"Các bước chuẩn bị","tags":[],"description":"","content":"IAM permissions Gắn IAM permission policy sau vào tài khoản aws user của bạn để triển khai và dọn dẹp tài nguyên trong workshop này.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudformation:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:AllocateAddress\u0026#34;, \u0026#34;ec2:AssociateAddress\u0026#34;, \u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;, \u0026#34;ec2:AssociateRouteTable\u0026#34;, \u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;, \u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;, \u0026#34;ec2:AttachInternetGateway\u0026#34;, \u0026#34;ec2:AttachNetworkInterface\u0026#34;, \u0026#34;ec2:AttachVolume\u0026#34;, \u0026#34;ec2:AttachVpnGateway\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;, \u0026#34;ec2:CreateClientVpnRoute\u0026#34;, \u0026#34;ec2:CreateCustomerGateway\u0026#34;, \u0026#34;ec2:CreateDhcpOptions\u0026#34;, \u0026#34;ec2:CreateFlowLogs\u0026#34;, \u0026#34;ec2:CreateInternetGateway\u0026#34;, \u0026#34;ec2:CreateLaunchTemplate\u0026#34;, \u0026#34;ec2:CreateNetworkAcl\u0026#34;, \u0026#34;ec2:CreateNetworkInterface\u0026#34;, \u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:CreateRoute\u0026#34;, \u0026#34;ec2:CreateRouteTable\u0026#34;, \u0026#34;ec2:CreateSecurityGroup\u0026#34;, \u0026#34;ec2:CreateSubnet\u0026#34;, \u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;, \u0026#34;ec2:CreateTags\u0026#34;, \u0026#34;ec2:CreateTransitGateway\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:CreateVpc\u0026#34;, \u0026#34;ec2:CreateVpcEndpoint\u0026#34;, \u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;, \u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;, \u0026#34;ec2:CreateVpnConnection\u0026#34;, \u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;, \u0026#34;ec2:CreateVpnGateway\u0026#34;, \u0026#34;ec2:DeleteCustomerGateway\u0026#34;, \u0026#34;ec2:DeleteFlowLogs\u0026#34;, \u0026#34;ec2:DeleteInternetGateway\u0026#34;, \u0026#34;ec2:DeleteNetworkInterface\u0026#34;, \u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:DeleteRoute\u0026#34;, \u0026#34;ec2:DeleteRouteTable\u0026#34;, \u0026#34;ec2:DeleteSecurityGroup\u0026#34;, \u0026#34;ec2:DeleteSubnet\u0026#34;, \u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;, \u0026#34;ec2:DeleteTags\u0026#34;, \u0026#34;ec2:DeleteTransitGateway\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:DeleteVpc\u0026#34;, \u0026#34;ec2:DeleteVpcEndpoints\u0026#34;, \u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;, \u0026#34;ec2:DeleteVpnConnection\u0026#34;, \u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;, \u0026#34;ec2:Describe*\u0026#34;, \u0026#34;ec2:DetachInternetGateway\u0026#34;, \u0026#34;ec2:DisassociateAddress\u0026#34;, \u0026#34;ec2:DisassociateRouteTable\u0026#34;, \u0026#34;ec2:GetLaunchTemplateData\u0026#34;, \u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34;, \u0026#34;ec2:ModifySecurityGroupRules\u0026#34;, \u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:ModifyVpcAttribute\u0026#34;, \u0026#34;ec2:ModifyVpcEndpoint\u0026#34;, \u0026#34;ec2:ReleaseAddress\u0026#34;, \u0026#34;ec2:ReplaceRoute\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:RunInstances\u0026#34;, \u0026#34;ec2:StartInstances\u0026#34;, \u0026#34;ec2:StopInstances\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;, \u0026#34;iam:AddRoleToInstanceProfile\u0026#34;, \u0026#34;iam:AttachRolePolicy\u0026#34;, \u0026#34;iam:CreateInstanceProfile\u0026#34;, \u0026#34;iam:CreatePolicy\u0026#34;, \u0026#34;iam:CreateRole\u0026#34;, \u0026#34;iam:DeleteInstanceProfile\u0026#34;, \u0026#34;iam:DeletePolicy\u0026#34;, \u0026#34;iam:DeleteRole\u0026#34;, \u0026#34;iam:DeleteRolePolicy\u0026#34;, \u0026#34;iam:DetachRolePolicy\u0026#34;, \u0026#34;iam:GetInstanceProfile\u0026#34;, \u0026#34;iam:GetPolicy\u0026#34;, \u0026#34;iam:GetRole\u0026#34;, \u0026#34;iam:GetRolePolicy\u0026#34;, \u0026#34;iam:ListPolicyVersions\u0026#34;, \u0026#34;iam:ListRoles\u0026#34;, \u0026#34;iam:PassRole\u0026#34;, \u0026#34;iam:PutRolePolicy\u0026#34;, \u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;, \u0026#34;lambda:CreateFunction\u0026#34;, \u0026#34;lambda:DeleteFunction\u0026#34;, \u0026#34;lambda:DeleteLayerVersion\u0026#34;, \u0026#34;lambda:GetFunction\u0026#34;, \u0026#34;lambda:GetLayerVersion\u0026#34;, \u0026#34;lambda:InvokeFunction\u0026#34;, \u0026#34;lambda:PublishLayerVersion\u0026#34;, \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:DeleteLogGroup\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:PutRetentionPolicy\u0026#34;, \u0026#34;route53:ChangeTagsForResource\u0026#34;, \u0026#34;route53:CreateHealthCheck\u0026#34;, \u0026#34;route53:CreateHostedZone\u0026#34;, \u0026#34;route53:CreateTrafficPolicy\u0026#34;, \u0026#34;route53:DeleteHostedZone\u0026#34;, \u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;, \u0026#34;route53:GetHostedZone\u0026#34;, \u0026#34;route53:ListHostedZones\u0026#34;, \u0026#34;route53domains:ListDomains\u0026#34;, \u0026#34;route53domains:ListOperations\u0026#34;, \u0026#34;route53domains:ListTagsForDomain\u0026#34;, \u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:AssociateResolverRule\u0026#34;, \u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:CreateResolverRule\u0026#34;, \u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;, \u0026#34;route53resolver:DeleteResolverRule\u0026#34;, \u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:DisassociateResolverRule\u0026#34;, \u0026#34;route53resolver:GetResolverEndpoint\u0026#34;, \u0026#34;route53resolver:GetResolverRule\u0026#34;, \u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;, \u0026#34;route53resolver:ListResolverEndpoints\u0026#34;, \u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;, \u0026#34;route53resolver:ListResolverRules\u0026#34;, \u0026#34;route53resolver:ListTagsForResource\u0026#34;, \u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:UpdateResolverRule\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34;, \u0026#34;s3:CreateBucket\u0026#34;, \u0026#34;s3:DeleteBucket\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;s3:GetBucketOwnershipControls\u0026#34;, \u0026#34;s3:GetBucketPolicy\u0026#34;, \u0026#34;s3:GetBucketPolicyStatus\u0026#34;, \u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:GetObjectVersion\u0026#34;, \u0026#34;s3:GetBucketVersioning\u0026#34;, \u0026#34;s3:ListAccessPoints\u0026#34;, \u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;, \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:ListBucketMultipartUploads\u0026#34;, \u0026#34;s3:ListBucketVersions\u0026#34;, \u0026#34;s3:ListJobs\u0026#34;, \u0026#34;s3:ListMultipartUploadParts\u0026#34;, \u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;, \u0026#34;s3:ListStorageLensConfigurations\u0026#34;, \u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:PutBucketAcl\u0026#34;, \u0026#34;s3:PutBucketPolicy\u0026#34;, \u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;secretsmanager:CreateSecret\u0026#34;, \u0026#34;secretsmanager:DeleteSecret\u0026#34;, \u0026#34;secretsmanager:DescribeSecret\u0026#34;, \u0026#34;secretsmanager:GetSecretValue\u0026#34;, \u0026#34;secretsmanager:ListSecrets\u0026#34;, \u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;, \u0026#34;secretsmanager:PutResourcePolicy\u0026#34;, \u0026#34;secretsmanager:TagResource\u0026#34;, \u0026#34;secretsmanager:UpdateSecret\u0026#34;, \u0026#34;sns:ListTopics\u0026#34;, \u0026#34;ssm:DescribeInstanceProperties\u0026#34;, \u0026#34;ssm:DescribeSessions\u0026#34;, \u0026#34;ssm:GetConnectionStatus\u0026#34;, \u0026#34;ssm:GetParameters\u0026#34;, \u0026#34;ssm:ListAssociations\u0026#34;, \u0026#34;ssm:ResumeSession\u0026#34;, \u0026#34;ssm:StartSession\u0026#34;, \u0026#34;ssm:TerminateSession\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Khởi tạo tài nguyên bằng CloudFormation Trong lab này, chúng ta sẽ dùng N.Virginia region (us-east-1).\nĐể chuẩn bị cho môi trường làm workshop, chúng ta deploy CloudFormation template sau (click link): PrivateLinkWorkshop . Để nguyên các lựa chọn mặc định.\nLựa chọn 2 mục acknowledgement Chọn Create stack Quá trình triển khai CloudFormation cần khoảng 15 phút để hoàn thành.\n2 VPCs đã được tạo 3 EC2s đã được tạo "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/","title":"Kiểm tra Gateway Endpoint","tags":[],"description":"","content":"Tạo S3 bucket Đi đến S3 management console Trong Bucket console, chọn Create bucket Trong Create bucket console Đặt tên bucket: chọn 1 tên mà không bị trùng trong phạm vi toàn cầu (gợi ý: lab\u0026lt;số-lab\u0026gt;\u0026lt;tên-bạn\u0026gt;) Giữ nguyên giá trị của các fields khác (default) Kéo chuột xuống và chọn Create bucket Tạo thành công S3 bucket Kết nối với EC2 bằng session manager Trong workshop này, bạn sẽ dùng AWS Session Manager để kết nối đến các EC2 instances. Session Manager là 1 tính năng trong dịch vụ Systems Manager được quản lý hoàn toàn bởi AWS. System manager cho phép bạn quản lý Amazon EC2 instances và các máy ảo on-premises (VMs)thông qua 1 browser-based shell. Session Manager cung cấp khả năng quản lý phiên bản an toàn và có thể kiểm tra mà không cần mở cổng vào, duy trì máy chủ bastion host hoặc quản lý khóa SSH.\nFirst cloud journey Lab để hiểu sâu hơn về Session manager.\nTrong AWS Management Console, gõ Systems Manager trong ô tìm kiếm và nhấn Enter: Từ Systems Manager menu, tìm Node Management ở thanh bên trái và chọn Session Manager: Click Start Session, và chọn EC2 instance tên Test-Gateway-Endpoint. Phiên bản EC2 này đã chạy trong \u0026ldquo;VPC cloud\u0026rdquo; và sẽ được dùng để kiểm tra khả năng kết nối với Amazon S3 thông qua điểm cuối Cổng mà bạn vừa tạo (s3-gwe).\nSession Manager sẽ mở browser tab mới với shell prompt: sh-4.2 $\nBạn đã bắt đầu phiên kết nối đến EC2 trong VPC Cloud thành công. Trong bước tiếp theo, chúng ta sẽ tạo một S3 bucket và một tệp trong đó.\nCreate a file and upload to s3 bucket Đổi về ssm-user\u0026rsquo;s thư mục bằng lệnh \u0026ldquo;cd ~\u0026rdquo; Tạo 1 file để kiểm tra bằng lệnh \u0026ldquo;fallocate -l 1G testfile.xyz\u0026rdquo;, 1 file tên \u0026ldquo;testfile.xyz\u0026rdquo; có kích thước 1GB sẽ được tạo. Tải file mình vừa tạo lên S3 với lệnh \u0026ldquo;aws s3 cp testfile.xyz s3://your-bucket-name\u0026rdquo;. Thay your-bucket-name bằng tên S3 bạn đã tạo. Bạn đã tải thành công tệp lên bộ chứa S3 của mình. Bây giờ bạn có thể kết thúc session.\nKiểm tra object trong S3 bucket Đi đến S3 console. Click tên s3 bucket của bạn Trong Bucket console, bạn sẽ thấy tệp bạn đã tải lên S3 bucket của mình Tóm tắt Chúc mừng bạn đã hoàn thành truy cập S3 từ VPC. Trong phần này, bạn đã tạo gateway endpoint cho Amazon S3 và sử dụng AWS CLI để tải file lên. Quá trình tải lên hoạt động vì gateway endpoint cho phép giao tiếp với S3 mà không cần Internet gateway gắn vào \u0026ldquo;VPC Cloud\u0026rdquo;. Điều này thể hiện chức năng của gateway endpoint như một đường dẫn an toàn đến S3 mà không cần đi qua pub lic Internet.\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/","title":"Tạo một S3 Interface endpoint","tags":[],"description":"","content":"Trong phần này, bạn sẽ tạo và kiểm tra Interface Endpoint S3 bằng cách sử dụng môi trường truyền thống mô phỏng.\nQuay lại Amazon VPC menu. Trong thanh điều hướng bên trái, chọn Endpoints, sau đó click Create Endpoint.\nTrong Create endpoint console:\nĐặt tên interface endpoint Trong Service category, chọn aws services Trong Search box, gõ S3 và nhấn Enter. Chọn endpoint có tên com.amazonaws.us-east-1.s3. Đảm bảo rằng cột Type có giá trị Interface. Đối với VPC, chọn VPC Cloud từ drop-down. Đảm bảo rằng bạn chọn \u0026ldquo;VPC Cloud\u0026rdquo; và không phải \u0026ldquo;VPC On-prem\u0026rdquo;\nMở rộng Additional settings và đảm bảo rằng Enable DNS name không được chọn (sẽ sử dụng điều này trong phần tiếp theo của workshop) Chọn 2 subnets trong AZs sau: us-east-1a and us-east-1b Đối với Security group, chọn SGforS3Endpoint: Giữ default policy - full access và click Create endpoint Chúc mừng bạn đã tạo thành công S3 interface endpoint. Ở bước tiếp theo, chúng ta sẽ kiểm tra interface endpoint.\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 10: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 11: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Mục tiêu tuần 12: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 12: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":"Tại đây sẽ là phần liệt kê, giới thiệu các blogs mà các bạn đã dịch. Ví dụ:\nBlog 1 - Getting started with healthcare data lakes: Using microservices Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 2 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 3 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 4 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 5 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 6 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/","title":"Kiểm tra Interface Endpoint","tags":[],"description":"","content":"Lấy regional DNS name (tên DNS khu vực) của S3 interface endpoint Trong Amazon VPC menu, chọn Endpoints.\nClick tên của endpoint chúng ta mới tạo ở mục 4.2: s3-interface-endpoint. Click details và lưu lại regional DNS name của endpoint (cái đầu tiên) vào text-editor của bạn để dùng ở các bước sau.\nKết nối đến EC2 instance ở trong \u0026ldquo;VPC On-prem\u0026rdquo; (giả lập môi trường truyền thống) Đi đến Session manager bằng cách gõ \u0026ldquo;session manager\u0026rdquo; vào ô tìm kiếm\nClick Start Session, chọn EC2 instance có tên Test-Interface-Endpoint. EC2 instance này đang chạy trên \u0026ldquo;VPC On-prem\u0026rdquo; và sẽ được sử dụng để kiểm tra kết nối đến Amazon S3 thông qua Interface endpoint. Session Manager sẽ mở 1 browser tab mới với shell prompt: sh-4.2 $\nĐi đến ssm-user\u0026rsquo;s home directory với lệnh \u0026ldquo;cd ~\u0026rdquo;\nTạo 1 file tên testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file vào S3 bucket mình tạo ở section 4.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; Câu lệnh này yêu cầu thông số \u0026ndash;endpoint-url, bởi vì bạn cần sử dụng DNS name chỉ định cho endpoint để truy cập vào S3 thông qua Interface endpoint. Không lấy \u0026rsquo; * \u0026rsquo; khi copy/paste tên DNS khu vực. Cung cấp tên S3 bucket của bạn Bây giờ tệp đã được thêm vào bộ chứa S3 của bạn. Hãy kiểm tra bộ chứa S3 của bạn trong bước tiếp theo.\nKiểm tra Object trong S3 bucket Đi đến S3 console Click Buckets Click tên bucket của bạn và bạn sẽ thấy testfile2.xyz đã được thêm vào s3 bucket của bạn "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.3-s3-vpc/","title":"Truy cập S3 từ VPC","tags":[],"description":"","content":"Sử dụng Gateway endpoint Trong phần này, bạn sẽ tạo một Gateway endpoint để truy cập Amazon S3 từ một EC2 instance. Gateway endpoint sẽ cho phép tải một object lên S3 bucket mà không cần sử dụng Internet Công cộng. Để tạo endpoint, bạn phải chỉ định VPC mà bạn muốn tạo endpoint và dịch vụ (trong trường hợp này là S3) mà bạn muốn thiết lập kết nối.\nNội dung Tạo gateway endpoint Test gateway endpoint "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":"Trong quá trình thực tập, em đã tham gia 2 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 2 Tên sự kiện: Vòng đời phát triển theo hướng AI: Tái định hình kỹ thuật phần mềm\nThời gian: 14:00 ngày 03/10/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: WORKSHOP KHOA HỌC DỮ LIỆU TRÊN AWS\nThời gian: 09:30 ngày 16/10/2025\nĐịa điểm: Đại học FPT, Đường D1, Khu Công nghệ cao, Phường Tăng Nhơn Phú, TP. Hồ Chí Minh.\nVai trò trong sự kiện: Người tham dự\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/","title":"Mô phỏng On-premises DNS ","tags":[],"description":"","content":"AWS PrivateLink endpoint có một địa chỉ IP cố định trong từng AZ nơi chúng được triển khai, trong suốt thời gian tồn tại của endpoint (cho đến khi endpoint bị xóa). Các địa chỉ IP này được gắn vào Elastic network interface (ENI). AWS khuyến nghị sử dụng DNS để resolve địa chỉ IP cho endpoint để các ứng dụng downstream sử dụng địa chỉ IP mới nhất khi ENIs được thêm vào AZ mới hoặc bị xóa theo thời gian.\nTrong phần này, bạn sẽ tạo một quy tắc chuyển tiếp (forwarding rule) để gửi các yêu cầu resolve DNS từ môi trường truyền thống (mô phỏng) đến Private Hosted Zone trên Route 53. Phần này tận dụng cơ sở hạ tầng do CloudFormation triển khai trong phần Chuẩn bị môi trường.\nTạo DNS Alias Records cho Interface endpoint Click link để đi đến Route 53 management console (Hosted Zones section). Mẫu CloudFormation mà bạn triển khai trong phần Chuẩn bị môi trường đã tạo Private Hosted Zone này. Nhấp vào tên của Private Hosted Zone, s3.us-east-1.amazonaws.com: Tạo 1 record mới trong Private Hosted Zone: Giữ nguyên Record name và record type Alias Button: click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Add another record, và add 1 cái record thứ 2 sử dụng những thông số sau: Record name: *. Record type: giữ giá trị default (type A) Alias Button: Click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Create records Record mới xuất hiện trên giao diện Route 53.\nTạo một Resolver Forwarding Rule Route 53 Resolver Forwarding Rules cho phép bạn chuyển tiếp các DNS queries từ VPC của bạn đến các nguồn khác để resolve name. Bên ngoài môi trường workshop, bạn có thể sử dụng tính năng này để chuyển tiếp các DNS queries từ VPC của bạn đến các máy chủ DNS chạy trên on-premises. Trong phần này, bạn sẽ mô phỏng một on-premises conditional forwarder bằng cách tạo một forwarding rule để chuyển tiếp các DNS queries for Amazon S3 đến một Private Hosted Zone chạy trong \u0026ldquo;VPC Cloud\u0026rdquo; để resolve PrivateLink interface endpoint regional DNS name.\nTừ giao diện Route 53, chọn Inbound endpoints trên thanh bên trái\nTrong giao diện Inbound endpoint, Chọn ID của Inbound endpoint.\nSao chép 2 địa chỉ IP trong danh sách vào trình chỉnh sửa. Từ giao diện Route 53, chọn Resolver \u0026gt; Rules và chọn Create rule Trong giao diện Create rule Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: điền cả hai IP bạn đã lưu trữ trên trình soạn thảo (inbound endpoint addresses) và sau đó chọn Submit Bạn đã tạo thành công resolver forwarding rule.\nKiểm tra on-premises DNS mô phỏng. Kết nối đến Test-Interface-Endpoint EC2 instance với Session Manager Kiểm tra DNS resolution. Lệnh dig sẽ trả về địa chỉ IP được gán cho VPC endpoint interface đang chạy trên VPC (địa chỉ IP của bạn sẽ khác): dig +short s3.us-east-1.amazonaws.com Các địa chỉ IP được trả về là các địa chỉ IP VPC enpoint, KHÔNG phải là các địa chỉ IP Resolver mà bạn đã dán từ trình chỉnh sửa văn bản của mình. Các địa chỉ IP của Resolver endpoint và VPC endpoin trông giống nhau vì chúng đều từ khối CIDR VPC Cloud.\nTruy cập vào menu VPC (phần Endpoints), chọn S3 interface endpoint. Nhấp vào tab Subnets và xác nhận rằng các địa chỉ IP được trả về bởi lệnh Dig khớp với VPC endpoint: Hãy quay lại shell của bạn và sử dụng AWS CLI để kiểm tra danh sách các bucket S3 của bạn: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Kết thúc phiên làm việc của Session Manager của bạn: Trong phần này, bạn đã tạo một Interface Endpoint cho Amazon S3. Điểm cuối này có thể được truy cập từ on-premises thông qua Site-to-Site VPN hoặc AWS Direct Connect. Các điểm cuối Route 53 Resolver outbound giả lập chuyển tiếp các yêu cầu DNS từ on-premises đến một Private Hosted Zone đang chạy trên đám mây. Các điểm cuối Route 53 inbound nhận yêu cầu giải quyết và trả về một phản hồi chứa địa chỉ IP của Interface Endpoint VPC. Sử dụng DNS để giải quyết các địa chỉ IP của điểm cuối cung cấp tính sẵn sàng cao trong trường hợp một Availability Zone gặp sự cố.\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.4-s3-onprem/","title":"Truy cập S3 từ môi trường truyền thống","tags":[],"description":"","content":"Tổng quan Trong phần này, bạn sẽ tạo một Interface Endpoint để truy cập Amazon S3 từ môi trường truyền thống mô phỏng. Interface Endpoint sẽ cho phép bạn định tuyến đến Amazon S3 qua kết nối VPN từ môi trường truyền thống mô phỏng của bạn.\nTại sao nên sử dụng Interface Endpoint:\nCác Gateway endpoints chỉ hoạt động với các tài nguyên đang chạy trong VPC nơi chúng được tạo. Interface Endpoint hoạt động với tài nguyên chạy trong VPC và cả tài nguyên chạy trong môi trường truyền thống. Khả năng kết nối từ môi trường truyền thống của bạn với aws cloud có thể được cung cấp bởi AWS Site-to-Site VPN hoặc AWS Direct Connect. Interface Endpoint cho phép bạn kết nối với các dịch vụ do AWS PrivateLink cung cấp. Các dịch vụ này bao gồm một số dịch vụ AWS, dịch vụ do các đối tác và khách hàng AWS lưu trữ trong VPC của riêng họ (gọi tắt là Dịch vụ PrivateLink endpoints) và các dịch vụ Đối tác AWS Marketplace. Đối với workshop này, chúng ta sẽ tập trung vào việc kết nối với Amazon S3. "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.5-policy/","title":"VPC Endpoint Policies","tags":[],"description":"","content":"Khi bạn tạo một Interface Endpoint hoặc cổng, bạn có thể đính kèm một chính sách điểm cuối để kiểm soát quyền truy cập vào dịch vụ mà bạn đang kết nối. Chính sách VPC Endpoint là chính sách tài nguyên IAM mà bạn đính kèm vào điểm cuối. Nếu bạn không đính kèm chính sách khi tạo điểm cuối, thì AWS sẽ đính kèm chính sách mặc định cho bạn để cho phép toàn quyền truy cập vào dịch vụ thông qua điểm cuối.\nBạn có thể tạo chính sách chỉ hạn chế quyền truy cập vào các S3 bucket cụ thể. Điều này hữu ích nếu bạn chỉ muốn một số Bộ chứa S3 nhất định có thể truy cập được thông qua điểm cuối.\nTrong phần này, bạn sẽ tạo chính sách VPC Endpoint hạn chế quyền truy cập vào S3 bucket được chỉ định trong chính sách VPC Endpoint.\nKết nối tới EC2 và xác minh kết nối tới S3. Bắt đầu một phiên AWS Session Manager mới trên máy chủ có tên là Test-Gateway-Endpoint. Từ phiên này, xác minh rằng bạn có thể liệt kê nội dung của bucket mà bạn đã tạo trong Phần 1: Truy cập S3 từ VPC. aws s3 ls s3://\u0026lt;your-bucket-name\u0026gt; Nội dung của bucket bao gồm hai tệp có dung lượng 1GB đã được tải lên trước đó.\nTạo một bucket S3 mới; tuân thủ mẫu đặt tên mà bạn đã sử dụng trong Phần 1, nhưng thêm \u0026lsquo;-2\u0026rsquo; vào tên. Để các trường khác là mặc định và nhấp vào Create. Tạo bucket thành công. Policy mặc định cho phép truy cập vào tất cả các S3 Buckets thông qua VPC endpoint.\nTrong giao diện Edit Policy, sao chép và dán theo policy sau, thay thế yourbucketname-2 với tên bucket thứ hai của bạn. Policy này sẽ cho phép truy cập đến bucket mới thông qua VPC endpoint, nhưng không cho phép truy cập đến các bucket còn lại. Chọn Save để kích hoạt policy. { \u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;, \u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34; ], \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34; } ] } Cấu hình policy thành công.\nTừ session của bạn trên Test-Gateway-Endpoint instance, kiểm tra truy cập đến S3 bucket bạn tạo ở bước đầu aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; Câu lệnh trả về lỗi bởi vì truy cập vào S3 bucket không có quyền trong VPC endpoint policy.\nTrở lại home directory của bạn trên EC2 instance cd~ Tạo file fallocate -l 1G test-bucket2.xyz Sao chép file lên bucket thứ 2 aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; Thao tác này được cho phép bởi VPC endpoint policy.\nSau đó chúng ta kiểm tra truy cập vào S3 bucket đầu tiên\naws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt;\nCâu lệnh xảy ra lỗi bởi vì bucket không có quyền truy cập bởi VPC endpoint policy.\nTrong phần này, bạn đã tạo chính sách VPC Endpoint cho Amazon S3 và sử dụng AWS CLI để kiểm tra chính sách. Các hoạt động AWS CLI liên quan đến bucket S3 ban đầu của bạn thất bại vì bạn áp dụng một chính sách chỉ cho phép truy cập đến bucket thứ hai mà bạn đã tạo. Các hoạt động AWS CLI nhắm vào bucket thứ hai của bạn thành công vì chính sách cho phép chúng. Những chính sách này có thể hữu ích trong các tình huống khi bạn cần kiểm soát quyền truy cập vào tài nguyên thông qua VPC Endpoint.\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Đảm bảo truy cập Hybrid an toàn đến S3 bằng cách sử dụng VPC endpoint Tổng quan AWS PrivateLink cung cấp kết nối riêng tư đến các dịch vụ aws từ VPCs hoặc trung tâm dữ liệu (on-premise) mà không làm lộ lưu lượng truy cập ra ngoài public internet.\nTrong bài lab này, chúng ta sẽ học cách tạo, cấu hình, và kiểm tra VPC endpoints để cho phép workload của bạn tiếp cận các dịch vụ AWS mà không cần đi qua Internet công cộng.\nChúng ta sẽ tạo hai loại endpoints để truy cập đến Amazon S3: gateway vpc endpoint và interface vpc endpoint. Hai loại vpc endpoints này mang đến nhiều lợi ích tùy thuộc vào việc bạn truy cập đến S3 từ môi trường cloud hay từ trung tâm dữ liệu (on-premise).\nGateway - Tạo gateway endpoint để gửi lưu lượng đến Amazon S3 hoặc DynamoDB using private IP addresses. Bạn điều hướng lưu lượng từ VPC của bạn đến gateway endpoint bằng các bảng định tuyến (route tables) Interface - Tạo interface endpoint để gửi lưu lượng đến các dịch vụ điểm cuối (endpoints) sử dụng Network Load Balancer để phân phối lưu lượng. Lưu lượng dành cho dịch vụ điểm cuối được resolved bằng DNS. Nội dung Tổng quan về workshop Chuẩn bị Truy cập đến S3 từ VPC Truy cập đến S3 từ TTDL On-premises VPC Endpoint Policies (làm thêm) Dọn dẹp tài nguyên "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.6-cleanup/","title":"Dọn dẹp tài nguyên","tags":[],"description":"","content":"Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại [Tên công ty/tổ chức] từ [ngày bắt đầu] đến [ngày kết thúc], tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia [mô tả ngắn gọn dự án hoặc công việc chính], qua đó cải thiện kỹ năng [liệt kê kỹ năng: lập trình, phân tích, viết báo cáo, giao tiếp…].\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ☐ ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":" Tại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Bạn có muốn tiếp tục chương trình này trong tương lai? Góp ý khác (tự do chia sẻ): "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]