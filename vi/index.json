[{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders Mục Đích Của Sự Kiện Hoàn thành quá trình di chuyển và hiện đại hóa quy mô lớn với AWS Hiện đại hóa ứng dụng bằng các công cụ hỗ trợ AI tạo sinh Thảo luận nhóm: Hiện đại hóa ứng dụng: Đẩy nhanh quá trình chuyển đổi kinh doanh Chuyển đổi VMware với công nghệ hiện đại hóa đám mây dựa trên AI Bảo mật AWS ở quy mô lớn: Từ phát triển đến sản xuất Danh Sách Diễn Giả Nguyen Van Hai - Director of Software Engineering, Techcombank Nguyen The Vinh - Co-Founder \u0026amp; CTO, Ninety Eight Nguyen Minh Nganh - AI Specialist, OCB Nguyen Manh Tuyen - Head of Data Application, LPBank Securities Nội Dung Nổi Bật 1. Tìm hiểu về các chiến lược di chuyển và hiện đại hóa quy mô lớn với AWS thông qua các nghiên cứu điển hình thực tế từ Techcombank. Hành trình hiện đại hóa của Techcombank\nAssess: Đánh giá được môi trường kiểm kê, và xác định được khoảng trống. Mobilize: Thiết lập CCoE, xác định hàng rào, xây dựng sự lưu loát của điện toán đám mây. Migrate \u0026amp; Modernize: Ưu tiên khối lượng công việc có tác động cao Reinvent: AI, tự động hóa, sản phẩm dữ liệu, mô hình doanh mới. Generative trong hiện đại hóa quy mô.\nCode Transformation: Java 8 -\u0026gt; 21, .NET -\u0026gt; .NET 8 Dependency Mapping: Lập bản đồ phụ thuộc để phân tích tự động các mối quan hệ của hệ thống. Environment Assessment: Amazon có hàng ngàn dịch vụ hiện tại hóa với AI có thể đáp ứng được cho doanh nghiệp. Giải pháp và chiến lược mà Techcombank đã ứng dụng trong việc dùng các dịch vụ của AWS.\nAmazon EKS Amazon Aurora MySQL Amazon MSK Amazon ElastiCache for Redis OSS. Tổng quan về chiến lược Modernization Strategy Blueprint. Hiện đại hóa với các công nghệ gốc của AWS.\nAlign: Tài trợ việc triển khai và động lực doanh nghiệp. | Assess: Hiểu rõ về con người, quy trình, và công nghệ | Mobilize: CoE, quản trị, đào tạo | Modernize: Replatform, refactor, rebuild | Reinvent: Data, AI và hiện đại hóa các ứng dụng cho sự đổi mới 2. Tìm hiểu về việc hiện đại hóa ứng dụng bằng các công cụ Generative AI, với những hiểu biết thực tế từ VPBank Hiện đại hóa là quá trình chuyển đổi dần dần các ứng dụng để đạt được lợi ích về tính khả dụng, khả năng mở rộng, tính linh hoạt trong kinh doanh và tối ưu hóa chi phí khi chạy trên nền tảng đám mây Top 4 trường hợp sử dụng hàng đầu - Hiện đại hóa ứng dụng với Generative AI.\nUse case 1: Streamline VMware Migration with AWS Transform for VMware\nĐẩy nhanh quá trình di chuyển và hiện đại hóa cơ sở hạ tầng với khám phá thông minh và thực thi tự động\nRút ngắn thời gian di chuyển VMware với tính năng tự động hóa thông minh của AWS Transform.\nChuyển đổi các cấu hình mạng phức tạp chỉ trong vài giờ thay vì vài tuần nhờ tính năng khám phá, ánh xạ phụ thuộc và lập kế hoạch làn sóng tự động do AWS cung cấp.\nMở rộng quy trình di chuyển của bạn với tính năng tạo nhóm bảo mật tự động, lựa chọn phiên bản EC2 thông minh và các tùy chọn triển khai linh hoạt, bao gồm cấu hình VPC dạng hub-and-spoke hoặc cấu hình VPC riêng biệt.\nCải thiện thời gian thực hiện lên đến 90%, đồng thời giảm 80% công sức thủ công.\nUse case 2: GenAl Development with AWS Serverless and Container Solutions\nXây dựng các ứng dụng GenAl sẵn sàng cho doanh nghiệp trên nền tảng AWS Serverless và Container\nAWS cung cấp hai giải pháp mạnh mẽ cho việc phát triển và triển khai ứng dụng GenAl:\nKhông máy chủ với AWS Bedrock: Phát triển và triển khai nhanh chóng các ứng dụng GenAl bằng AWS Lambda, ECS với Fargate, Step Functions và EventBridge. Lý tưởng cho chatbot, tạo tài liệu và xử lý nội dung thông minh. Tận dụng các bản cập nhật và kiến ​​trúc tham chiếu mới nhất của AWS Bedrock.\nDựa trên container với Amazon EKS: Xây dựng, đào tạo và chạy các ứng dụng GenAl trên Kubernetes, tận dụng khả năng điều phối mạnh mẽ của nó. Sử dụng các công cụ nguồn mở và dịch vụ đám mây gốc cho khối lượng công việc GenAl có khả năng mở rộng. Triển khai linh hoạt trên cả môi trường đám mây và tại chỗ với sự đổi mới liên tục từ cộng đồng OSS.\nChọn một trong hai cách tiếp cận hoặc kết hợp cả hai để phù hợp nhất với yêu cầu ứng dụng GenAl cụ thể của bạn và đẩy nhanh hành trình AI của bạn.\nUse case 3: Revolutionize NET Modernization with AWS Transform for NET\nChuyển đổi các ứng dụng Windown cũ sang Cloud-native với tự động hóa được hỗ trợ bởi AI-powered.\nHiện đại hóa các ứng dụng chạy trên Windows nhanh hơn tới 4 lần với AWS Transform for NET. Tận dụng khả năng tự động hóa của AI để phân tích các phụ thuộc, tái cấu trúc mã và tối ưu hóa cho việc triển khai Linux, đồng thời cắt giảm chi phí cấp phép tới 40%. Chuyển đổi hàng trăm ứng dụng song song với khả năng kiểm tra và xác thực tự động - từ các ứng dụng MVC cũ sang các dịch vụ WCF. Các tính năng nâng cao bao gồm hiện đại hóa Ul tự động, xử lý gói riêng và lập kế hoạch sóng thông minh, mang lại khả năng hiện đại hóa toàn diện với tốc độ vượt trội. Use case 4: Nâng cao Kỹ thuật Nền tảng với Gen Al \u0026amp; IDP\nTận dụng sức mạnh của các trợ lý thông minh như AWS Transform Developer với Nền tảng phát triển nội bộ.\nViệc mở rộng quy mô hiện đại hóa ở cấp độ doanh nghiệp đòi hỏi thời gian và đầu tư để phát triển Nền tảng Phát triển Nội bộ (IDP). Gartner dự đoán rằng đến năm 2026, 80% các tổ chức kỹ thuật phần mềm sẽ thành lập các nhóm nền tảng với tư cách là nhà cung cấp nội bộ các dịch vụ, thành phần và công cụ có thể tái sử dụng để triển khai ứng dụng.\nKhai thác sức mạnh của các trợ lý thông minh như AWS Transform Developer với IDP để:\nTạo quy trình làm việc và tự động hóa các tác vụ lặp lại.\nTìm hiểu các phương pháp hay nhất của IDP từ các tổ chức hàng đầu, chẳng hạn như Adobe, Expedia, JPMC và Goldman Sachs.\nHiểu rõ các bản thiết kế container và kiến ​​trúc tham chiếu của AWS để mang lại tốc độ và khả năng mở rộng nhanh chóng cho sáng kiến ​​hiện đại hóa quy mô doanh nghiệp.\nCác động lực hiện đại hóa phổ biến\nGiảm chi phí\nGiảm/loại bỏ chi phí bản quyền Windows \u0026amp; SQL Server Xây dựng kiến trúc khớp với tải thực tế để tối ưu chi phí Tận dụng kiến trúc ARM64 để có hiệu năng/giá thành tốt hơn Tăng tốc độ đổi mới\nTách monolith thành các dịch vụ nhỏ hơn / microservices Tận dụng công nghệ mới và các tính năng ngôn ngữ C# Tự động hóa các quy trình thủ công Cải thiện khả năng mở rộng\nMở rộng từng thành phần / dịch vụ riêng lẻ Mở rộng chi tiết với containers / serverless Thu hút và giữ chân nhân tài\n3. Nhận thông tin chuyên sâu từ các chuyên gia hàng đầu trong ngành thông qua các buổi thảo luận chuyên đề về hiện đại hóa ứng dụng .NET Framework so với đa nền tảng .NET\n.NET Framework:\nChỉ hệ điều hành Windows Phiên bản 1.0 được phát hành vào năm 2002 Phiên bản cuối cùng là 4.8*, phát hành năm 2019 Cài đặt nguyên khối - Số lượng lớn các thư viện được cài đặt cùng một lúc. EC2, Elastic Beanstalk, ECS và EKS. .NET (trước đây là .NET Core)\nĐa nền tảng (Windows, Linux, MacOS) Phiên bản 1.0 được phát hành năm 2016 Phiên bản GA hiện tại là 8.0, được phát hành vào năm 2023 Hỗ trợ nhiều phiên bản để cài đặt Hầu hết các thư viện được phân phối riêng lẻ EC2, Elastic Beanstalk, ECS, EKS, Lambda Fargate AWS Transform: Trí thông minh được phối hợp\nTrải nghiệm web thống nhất -\u0026gt; Tự động hóa đầu cuối -\u0026gt; Cơ quan chuyên trách -\u0026gt; Định hướng mục tiêu -\u0026gt; Con người trong vòng lặp -\u0026gt; Hợp tác được đơn giản hóa AWS Transform cho .NET\nLợi ích khách hàng\nGiảm chi phí vận hành lên đến 40% Loại bỏ thương mại giấy phép hệ điều hành Tiếp cận nhóm nhà phát triển lớn hơn Quy mô đám mây và hiệu suất. Lợi ích kỹ thuật\nHỗ trợ khắc phục lỗ hổng bảo mật Hỗ trợ đa nền tảng: Windows, macOS, Linux (x86-64, arm64) Tương thích với x86-64 và arm64 LightweightContainer Kiến trúc Lambda Serverless Hoàn thành nâng cấp ngôn ngữ trong vài phút thông qua Amazon Q\nĐẩy nhanh hiện đại hóa ứng dụng Nâng cấp Ngôn ngữ Tự động (Java, .NET) Giảm Nợ Kỹ thuật Tiết kiệm Chi phí và Hiệu quả Vận hành Nâng cao Lợi thế Cạnh tranh Ứng dụng Kiro: Giải pháp cho việc phát triển theo thông số kĩ thuật\nKiro giúp các nhà phát triển và nhóm kỹ thuật vận chuyển phần mềm chất lượng cao với các tác nhân AI. Kiro biến lời nhắc của bạn thành các yêu cầu rõ ràng, thiết kế hệ thống và các nhiệm vụ riêng biệt Lặp lại với Kiro trên thông số kỹ thuật và kiến ​​trúc của bạn Các tác nhân Kiro triển khai thông số kỹ thuật trong khi vẫn giúp bạn kiểm soát. Agent hook\nPhân quyền các tác vụ cho các tác nhân Al được kích hoạt khi có sự kiện như \u0026rsquo;lưu tệp' Các tác nhân tự động thực thi ở chế độ nền dựa trên các lời nhắc được xác định trước của bạn Các hook tác nhân giúp bạn mở rộng quy mô công việc bằng cách tạo tài liệu, kiểm tra đơn vị hoặc tối ưu hóa hiệu suất mã Quản lí ngữ cảnh nâng cao\nKết nối với tài liệu, cơ sở dữ liệu, API và nhiều hơn nữa với tích hợp MCP gốc Cấu hình cách bạn muốn các tác nhân Kiro tương tác với từng dự án thông qua các tệp chỉ đạo Thả một hình ảnh về thiết kế Ul của bạn hoặc một bức ảnh về buổi thảo luận kiến ​​trúc của bạn và Kiro có thể sử dụng nó để hướng dẫn việc triển khai Sức mạnh, tính linh hoạt và bảo mật\nTương thích với VS code\nKiro hỗ trợ plugin, theme và cài đặt VS Code Open VSX trong môi trường Al-ready được sắp xếp hợp lý Các mô hình Claude tiên tiến\nLựa chọn giữa các mô hình Claude Sonnet 3.7 hoặc Sonnet 4, với nhiều tùy chọn hơn sẽ sớm được bổ sung Bảo mật cấp doanh nghiệp\nKiro được xây dựng và vận hành bởi AWS Các trường hợp sử dụng\nXây dựng ứng dụng mới\nNhanh chóng chuyển từ nguyên mẫu sang mã sản xuất và triển khai, với các phương pháp hay nhất được tích hợp sẵn, bao gồm thiết kế có cấu trúc, tài liệu hướng dẫn hoặc phạm vi kiểm thử Xây dựng trên các ứng dụng hiện có\nVới thông số kỹ thuật và quản lý ngữ cảnh thông minh, Kiro giúp bạn dễ dàng tích hợp và xây dựng trên các ứng dụng hiện có mà vẫn duy trì tính nhất quán Tái cấu trúc và hiện đại hóa\nKiro hiểu rõ cơ sở mã của bạn và có thể hướng dẫn bạn chính xác trong việc tái cấu trúc hơn một triệu cơ sở mã LOC 4. Tìm hiểu về hiện đại hóa đám mây dựa trên AI dành riêng cho môi trường VMware Trạng thái tương lai của khối lượng công việc VMware của bạn\nRELOCATE: Amazon EVS | REHOST: Amazon EC2 | REPLATFORM TO CONTAINERS: Amazon ECS or Amazon EKS | REPLATFORM TO MANAGED SERVICES: Amazon RDS, Amazon FSx, Amazon WorkSpaces, and more | REFACTOR: Modern Application =\u0026gt; Áp dụng nhanh chóng, nền tảng của lợi ích đám mây và ROI nhanh....................----\u0026gt;....................Tất cả các lợi ích gốc của đám mây và ROl cao Chuyển đổi AWS cho VMware\nHiện đại hóa khối lượng công việc VMware lên Amazon EC2 với các tác nhân AI được thiết kế riêng Tự động hóa và đơn giản hóa các tác vụ chuyển đổi Giảm chi phí và phí cấp phép với Amazon EC2 Nâng cao bảo mật, khả năng mở rộng và phục hồi Thúc đẩy đổi mới với hơn 200 dịch vụ gốc của AWS Lập bản đồ công nghệ gốc từ VMware sang AWS\nMột cách tiếp cận dựa trên AI của agentic để hiện đại hóa VMware\n1. Kết nối với môi trường VMware của bạn | 2. Phân tích khối lượng công việc, sự phụ thuộc và mức độ sẵn sàng | 3. Chuyển đổi cấu hình mạng VMware sang các cấu trúc AWS gốc | 4. Tạo các kế hoạch sóng thông minh dựa trên sự phụ thuộc của ứng dụng | 5. Xác thực với nhóm của bạn, sau đó thực hiện =\u0026gt; Chuyển đổi từng bước với xác thực human-in-the-loop Lí do AWS Transform dành cho việc di chuyển sang VMware?\nChi phí thấp hơn\nLoại bỏ phí cấp phép VMware Tối ưu hóa chi phí cơ sở hạ tầng với khả năng điều chỉnh kích thước phiên bản do AI điều khiển Di chuyển nhanh hơn\nTăng tốc chuyển đổi mạng lên đến 80 lần Giảm thiểu gián đoạn, bảo toàn tính toàn vẹn của ứng dụng và đẩy nhanh quá trình chuyển đổi Cải thiện bảo mật\nTăng cường bảo mật với nền tảng đám mây gốc Di chuyển an toàn với quy trình xác thực human-in-the-loop Đổi mới ở quy mô lớn\nGiảm nợ kỹ thuật và xây dựng các ứng dụng hiện đại, có khả năng mở rộng Tích hợp liền mạch với hơn 200 dịch vụ gốc của AWS như data lakes, phân tích nâng cao và AI/ML 5. Kết nối và học hỏi trực tiếp từ các Kiến trúc sư Giải pháp AWS và các chuyên gia trong ngành Phần này các chuyên gia đưa ra những vấn đề khó khăn khi những bước đầu triển khai hiện đại hóa toàn bộ hệ thống từ on-premises lên AWS.\nHọ đưa ra những kế hoạch và chiến lược cụ thể ở từng phần, và họ chuyển những phần quan trọng nhất và thực hiện nó trước. Trong đó họ cũng tuân thủ các quy định và luật pháp hiện hành trong việc quản lí và không thu thập thông tin người dùng. Khi họ đưa lên AWS điều quan trọng nhất là họ có thể mở rộng quy mô của mình rất nhanh, và do đó họ nhận được rất nhiều lợi nhuận khi chuyển lên môi trường AWS. Và việc ứng dụng AI hiện nay rất hiệu quả trong công việc kinh doanh của họ, như anh Vinh đã ứng dụng AI trong việc nhận biết những giao dịch có khả năng lừa đảo, chống Hacker trong Blockchain. 6. Hiểu các phương pháp hay nhất về bảo mật AWS từ phát triển đến môi trường sản xuất Những Gì Học Được Khung 5 bước: Align → Assess → Mobilize → Modernize → Reinvent. GenAI-assisted modernization: code transformation (Java 8→21, .NET→8), dependency mapping, environment assessment. Ưu tiên workloads tác động cao, human-in-the-loop, đo ROI. Tư Duy Thiết Kế Problem→Pilot→Scale; ưu tiên value-first. Strangler Fig refactor từng phần; event-driven mindset. Platform thinking/IDP, security-by-design, governance sớm. Kiến Trúc Kỹ Thuật Microservices, containers (EKS/ECS/Fargate), serverless (Lambda/Step Functions/EventBridge). Data: Aurora MySQL, MSK (Kafka), ElastiCache (Redis). VMware→AWS: rehost EC2 → replatform containers/managed → refactor app. Multi-arch (x86_64 + ARM64), observability end-to-end. Chiến Lược Hiện Đại Hóa Assess/Mobilize/MM/Reinvent (Techcombank blueprint). AWS Transform: for VMware \u0026amp; .NET (tự động hóa di trú/kiểm thử/UL modernization). Cost-first: bỏ license Windows/SQL, right-size, ARM64. Scale \u0026amp; Innovate: tách monolith, automation CI/CD, adopt GenAI. Ứng Dụng Vào Công Việc Lập migration backlog theo ROI; chọn pilot nhỏ. Chuẩn hóa container baseline (EKS) + Bedrock pattern cho GenAI. Dùng Amazon Q/Transform để nâng cấp ngôn ngữ \u0026amp; refactor nhanh. Thiết kế IDP nội bộ: template dịch vụ, golden path, policy guardrails. Trải nghiệm trong event “GenAI-powered Migration \u0026amp; Modernization mang lại cái nhìn toàn diện về cách chuyển đổi ứng dụng \u0026amp; DB ở quy mô doanh nghiệp. Điểm nổi bật: demo tự động hóa di chuyển VMware/.NET, kiến trúc tham chiếu serverless–container, bài học định lượng ROI và mô hình governance thực chiến, cùng case study giúp rút ngắn thời gian di chuyển và giảm chi phí đáng kể.”\nHọc hỏi từ các diễn giả có chuyên môn cao Techcombank: vận hành theo CCoE, đo business outcomes, lộ trình 5 bước. Ninety Eight: AI chống gian lận, security posture mạnh, realtime. OCB/LPBankS: data products, automation, cloud scale an toàn. Trải nghiệm kỹ thuật thực tế Thấy rõ dependency mapping, wave planning, auto SG/EC2 sizing, hub-and-spoke VPC. Auto code upgrade, cross-platform .NET, UI modernization tự động. Ứng dụng công cụ hiện đại AWS Transform (VMware/.NET), Amazon Q (auto language upgrade). Bedrock, Lambda, ECS/Fargate, EKS, Step Functions, EventBridge. Aurora, MSK, ElastiCache, EC2; IDP tooling; Kiro (spec→tasks/agents, MCP). Kết nối và trao đổi Chốt best practices từ SA \u0026amp; ngân hàng lớn; checklist governance/security. Kết nối để mentorship, pattern reuse, đối chiếu ROI \u0026amp; benchmark. Event tạo cơ hội trao đổi trực tiếp với các chuyên gia, đồng nghiệp và team business, giúp nâng cao ngôn ngữ chung (ubiquitous language) giữa business và tech. Bài học rút ra Việc áp dụng DDD và event-driven patterns giúp giảm coupling, tăng scalability và resilience cho hệ thống.\nChiến lược hiện đại hóa cần phased approach và đo lường ROI, không nên vội vàng chuyển đổi toàn bộ hệ thống.\nCác công cụ AI như Amazon Q Developer có thể boost productivity nếu được tích hợp vào workflow phát triển hiện tại.\nModernize có chiến lược: đo lường ROI, ưu tiên theo giá trị.\nTự động hóa + GenAI rút ngắn thời gian, giảm nợ kỹ thuật.\nPlatform/IDP là đòn bẩy quy mô; security-by-default không thể thiếu.\nHuman-in-the-loop đảm bảo an toàn khi tự động hóa diện rộng.\nHơn 400 nhà phát triển công nghệ đầy nhiệt huyết tại Thành phố Hồ Chí Minh, văn phòng AWS (Tầng 36) đã tụ họp để theo dõi phiên họp toàn thể trực tiếp từ Hà Nội, cùng chia sẻ sự phấn khích và kiến ​​thức về AWS Cloud Day Vietnam 2025\nTổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Trần Huỳnh Bảo Minh\nSố điện thoại: 078 222 4 999\nEmail: baominhbrthcs@gmail.com\nTrường: Đại học FPT TP.HCM\nNgành: Trí tuệ nhân tạo\nLớp: SE193028\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Các tính năng mới trong Amazon SageMaker AI tiếp tục thay đổi cách các tổ chức phát triển mô hình AI Bởi Ankur Mehrotra | Ngày 10 tháng 7 năm 2025 | liên quan Amazon Bedrock, Amazon SageMaker AI, Amazon SageMaker HyperPod, Amazon SageMaker JumpStart, Announcements\nKhi các mô hình trí tuệ nhân tạo (AI) ngày càng trở nên phức tạp và chuyên biệt, khả năng huấn luyện và tùy chỉnh mô hình một cách nhanh chóng chính là yếu tố quyết định giữa việc dẫn đầu hay tụt lại phía sau. Đó cũng là lý do hàng trăm nghìn khách hàng trên toàn cầu tin tưởng sử dụng Amazon SageMaker AI — nền tảng cung cấp hạ tầng mạnh mẽ, công cụ toàn diện và quy trình làm việc được quản lý hoàn chỉnh để mở rộng và tăng tốc phát triển mô hình AI của họ. Kể từ khi ra mắt vào năm 2017, SageMaker AI đã định hình lại cách các tổ chức phát triển mô hình AI, giúp giảm thiểu độ phức tạp đồng thời tối ưu hiệu suất và khả năng mở rộng. Trong suốt quá trình đó, AWS không ngừng đổi mới — bổ sung hơn 420 tính năng mới kể từ khi ra mắt — nhằm mang đến cho khách hàng những công cụ tiên tiến nhất để xây dựng, huấn luyện và triển khai mô hình AI một cách nhanh chóng, linh hoạt và hiệu quả. Hôm nay, chúng tôi tiếp tục hành trình đó với việc giới thiệu những cải tiến mới nhất của SageMaker AI, được thiết kế để đẩy nhanh quá trình phát triển và huấn luyện mô hình, giúp các tổ chức rút ngắn thời gian đổi mới và khai thác tối đa tiềm năng của AI.\nAmazon SageMaker HyperPod: Hạ tầng lý tưởng cho việc phát triển các mô hình trí tuệ nhân tạo AWS ra mắt Amazon SageMaker HyperPod vào năm 2023 nhằm giảm độ phức tạp và tối đa hóa hiệu năng cũng như hiệu quả khi xây dựng mô hình AI. Với SageMaker HyperPod, bạn có thể nhanh chóng mở rộng phát triển mô hình AI sinh (generative) trên hàng nghìn bộ gia tốc AI và giảm tới 40% chi phí huấn luyện và tinh chỉnh mô hình nền tảng (FM). Nhiều mô hình hàng đầu hiện nay được huấn luyện trên SageMaker HyperPod, bao gồm mô hình từ Hugging Face, Luma AI, Perplexity AI, Salesforce, Thomson Reuters, Writer và Amazon. Bằng cách huấn luyện các FM Amazon Nova trên SageMaker HyperPod, Amazon đã tiết kiệm được hàng tháng công việc và nâng mức sử dụng tài nguyên tính toán lên hơn 90%.\nAmazon Trains Nova Foundation Models at Scale with SageMaker HyperPod | Amazon Web Services\nĐể tối ưu quy trình và tăng tốc phát triển, triển khai mô hình, một giao diện dòng lệnh (CLI) và bộ SDK mới cung cấp một giao diện thống nhất, nhất quán, đơn giản hóa quản lý hạ tầng, hợp nhất việc gửi tác vụ giữa huấn luyện và suy luận, và hỗ trợ cả quy trình theo “recipe” lẫn tùy biến với giám sát và điều khiển tích hợp. Hôm nay, chúng tôi cũng bổ sung hai khả năng cho SageMaker HyperPod giúp bạn giảm chi phí huấn luyện và tăng tốc phát triển mô hình AI.\nGiảm thời gian xử lý sự cố hiệu năng từ vài ngày xuống vài phút với khả năng quan sát của SageMaker HyperPod Để đưa các đổi mới AI ra thị trường nhanh nhất, tổ chức cần khả năng quan sát xuyên suốt các tác vụ phát triển mô hình AI và tài nguyên tính toán nhằm tối ưu hiệu suất huấn luyện và phát hiện, khắc phục gián đoạn hoặc nút thắt hiệu năng sớm nhất. Ví dụ, để điều tra xem một tác vụ huấn luyện hay tinh chỉnh thất bại có do lỗi phần cứng hay không, các nhà khoa học dữ liệu và kỹ sư ML muốn nhanh chóng lọc và xem dữ liệu giám sát của các GPU cụ thể đã chạy tác vụ, thay vì phải duyệt thủ công tài nguyên phần cứng của cả cụm để xác lập tương quan giữa lỗi tác vụ và sự cố phần cứng.\nKhả năng quan sát mới trong SageMaker HyperPod thay đổi cách bạn giám sát và tối ưu khối lượng công việc phát triển mô hình. Thông qua một bảng điều khiển hợp nhất được cấu hình sẵn trong Amazon Managed Grafana, với dữ liệu giám sát tự động được gửi tới một workspace Amazon Managed Service for Prometheus, bạn có thể xem các chỉ số hiệu năng tác vụ AI sinh, mức sử dụng tài nguyên và sức khỏe cụm trong một màn hình duy nhất. Nhóm có thể nhanh chóng phát hiện nút thắt, ngăn chặn trì hoãn tốn kém và tối ưu tài nguyên tính toán. Bạn có thể định nghĩa cảnh báo tự động, chỉ định các chỉ số và sự kiện theo trường hợp sử dụng, và xuất chúng lên bảng điều khiển hợp nhất chỉ với vài cú nhấp.\nBằng cách rút ngắn thời gian khắc phục sự cố từ ngày xuống phút, khả năng này giúp bạn tăng tốc đưa vào sản xuất và tối đa hóa lợi nhuận từ đầu tư AI.\nDatologyAI xây dựng công cụ để tự động chọn dữ liệu tốt nhất để huấn luyện mô hình học sâu.\n“Chúng tôi háo hức sử dụng giải pháp quan sát một-cú-nhấp của Amazon SageMaker HyperPod. Các nhân sự cấp cao của chúng tôi cần hiểu sâu cách chúng tôi sử dụng tài nguyên GPU. Các bảng điều khiển Grafana dựng sẵn sẽ mang đến đúng những gì chúng tôi cần, với khả năng quan sát tức thì các chỉ số quan trọng - từ mức sử dụng GPU theo tác vụ đến hiệu năng hệ thống tệp (FSx for Lustre) - mà không cần tự vận hành hạ tầng giám sát. Là người đánh giá cao sức mạnh của Prometheus Query Language, tôi thích việc có thể tự viết truy vấn và phân tích các chỉ số tùy chỉnh mà không phải lo về hạ tầng.”\n- Josh Wills, Thành viên Đội ngũ Kỹ thuật tại DatologyAI\nArticul8 giúp doanh nghiệp xây dựng các ứng dụng AI sinh cho doanh nghiệp ở mức độ tinh vi.\n“Với khả năng quan sát của SageMaker HyperPod, giờ đây chúng tôi có thể triển khai hệ thống thu thập và trực quan hóa chỉ số trong một cú nhấp, tiết kiệm cho đội ngũ nhiều ngày thiết lập thủ công và tăng cường quy trình, insight quan sát cụm. Các nhà khoa học dữ liệu có thể nhanh chóng theo dõi các chỉ số hiệu năng tác vụ, như độ trễ, và xác định vấn đề phần cứng mà không cần cấu hình thủ công. Khả năng quan sát của HyperPod sẽ tinh gọn quy trình phát triển mô hình nền tảng, cho phép chúng tôi tập trung vào sứ mệnh mang đến đổi mới AI đáng tin cậy, dễ tiếp cận cho khách hàng.”\n- Renato Nascimento, trưởng bộ phận công nghệ tại Articul8\nTriển khai các mô hình Amazon SageMaker JumpStart trên SageMaker HyperPod để suy luận nhanh, mở rộng Sau khi phát triển mô hình AI sinh trên SageMaker HyperPod, nhiều khách hàng nhập các mô hình này vào Amazon Bedrock, dịch vụ được quản lý toàn phần để xây dựng và mở rộng ứng dụng AI sinh. Tuy nhiên, một số khách hàng muốn dùng tài nguyên tính toán của SageMaker HyperPod để tăng tốc đánh giá và đưa mô hình vào sản xuất nhanh hơn.\nGiờ đây, bạn có thể triển khai các mô hình open-weights từ Amazon SageMaker JumpStart, cũng như các mô hình tùy chỉnh đã tinh chỉnh, trên SageMaker HyperPod chỉ trong vài phút mà không cần thiết lập hạ tầng thủ công. Nhà khoa học dữ liệu có thể chạy suy luận trên các mô hình JumpStart chỉ với một cú nhấp, đơn giản hóa và tăng tốc việc đánh giá mô hình. Quy trình cấp phát một lần, đơn giản này giảm thiết lập thủ công, mang lại môi trường suy luận đáng tin cậy và có khả năng mở rộng với nỗ lực ít nhất. Việc tải xuống các mô hình lớn được rút ngắn từ hàng giờ xuống còn vài phút, tăng tốc triển khai và rút ngắn thời gian ra thị trường.\nH.AI tồn tại để phá vỡ giới hạn siêu trí tuệ với AI hướng tác vụ (agentic AI).\n“Với Amazon SageMaker HyperPod, chúng tôi dùng hạ tầng tính toán hiệu năng cao để xây dựng và triển khai các mô hình nền tảng đứng sau nền tảng AI hướng tác vụ của mình. Việc chuyển đổi liền mạch từ huấn luyện sang suy luận đã tinh gọn quy trình, rút ngắn thời gian vào sản xuất và mang lại hiệu năng ổn định trong môi trường thực. HyperPod giúp chúng tôi đi từ thử nghiệm đến tác động thực tế nhanh chóng và hiệu quả hơn.”\n- Laurent Sifre, Đồng sáng lập \u0026amp; CTO tại H.AI\nTruy cập liền mạch tài nguyên tính toán mạnh mẽ của SageMaker AI từ môi trường phát triển cục bộ Hiện nay, nhiều khách hàng chọn các môi trường phát triển tích hợp (IDE) được quản lý toàn phần trong SageMaker AI để phát triển mô hình, gồm JupyterLab, Code Editor dựa trên Code-OSS, và RStudio. Dù các IDE này mang lại thiết lập an toàn và hiệu quả, một số nhà phát triển thích dùng IDE cục bộ trên máy cá nhân vì khả năng gỡ lỗi và tùy biến sâu. Tuy nhiên, khách hàng dùng IDE cục bộ như Visual Studio Code trước đây không thể dễ dàng chạy các tác vụ phát triển mô hình trên SageMaker AI.\nVới các kết nối từ xa mới tới SageMaker AI, nhà phát triển và nhà khoa học dữ liệu có thể nhanh chóng, liền mạch kết nối tới SageMaker AI từ VS Code cục bộ, vẫn giữ quyền truy cập công cụ tùy chỉnh và quy trình quen thuộc giúp họ làm việc hiệu quả nhất. Nhà phát triển có thể xây dựng và huấn luyện mô hình AI bằng IDE cục bộ trong khi SageMaker AI quản lý thực thi từ xa, nên bạn có thể làm việc trong môi trường ưa thích đồng thời hưởng lợi từ hiệu năng, khả năng mở rộng và bảo mật của SageMaker AI. Giờ đây bạn có thể chọn IDE ưa thích - dù là IDE đám mây được quản lý toàn phần hay VS Code - để tăng tốc phát triển mô hình AI bằng hạ tầng mạnh mẽ và khả năng mở rộng liền mạch của SageMaker AI.\nCyberArk là công ty dẫn đầu về Bảo mật Danh tính, cung cấp cách tiếp cận toàn diện xoay quanh kiểm soát đặc quyền để bảo vệ trước các mối đe dọa mạng tiên tiến.\n“Với kết nối từ xa tới SageMaker AI, các nhà khoa học dữ liệu của chúng tôi có sự linh hoạt chọn IDE giúp họ năng suất nhất. Các đội có thể tận dụng thiết lập cục bộ đã tùy chỉnh trong khi tiếp cận hạ tầng và kiểm soát bảo mật của SageMaker AI. Là công ty đặt an ninh lên hàng đầu, điều này cực kỳ quan trọng vì đảm bảo dữ liệu nhạy cảm luôn được bảo vệ, đồng thời cho phép đội ngũ cộng tác an toàn và tăng năng suất.”\nNir Feldman, Phó Chủ tịch cấp cao Kỹ thuật tại CyberArk Xây dựng mô hình và ứng dụng AI sinh nhanh hơn với MLflow 3.0 được quản lý toàn phần Khi khách hàng trong nhiều ngành tăng tốc phát triển AI sinh, họ cần khả năng theo dõi thí nghiệm, quan sát hành vi và đánh giá hiệu năng của mô hình và ứng dụng AI. Khách hàng như Cisco, SonRai và Xometry đã sử dụng MLflow được quản lý trên SageMaker AI để quản lý hiệu quả thí nghiệm mô hình ML ở quy mô lớn. Việc giới thiệu MLflow 3.0 được quản lý toàn phần trên SageMaker AI giúp việc theo dõi thí nghiệm, giám sát tiến trình huấn luyện và có insight sâu hơn về hành vi của mô hình và ứng dụng AI chỉ với một công cụ duy nhất, hỗ trợ bạn tăng tốc phát triển AI sinh.\nKết luận Trong bài viết này, chúng tôi đã chia sẻ một số đổi mới trong SageMaker AI để tăng tốc cách bạn xây dựng và huấn luyện mô hình AI.\nĐể tìm hiểu thêm về các tính năng mới, SageMaker AI, và cách các công ty sử dụng dịch vụ này, hãy tham khảo các tài nguyên sau:\nTăng tốc phát triển mô hình nền tảng với khả năng quan sát một-cú-nhấp trong Amazon SageMaker HyperPod Tăng tốc quy trình AI của bạn bằng cách kết nối tới SageMaker Studio từ Visual Studio Code Tăng tốc phát triển AI sinh với MLflow 3.0 được quản lý toàn phần trên Amazon SageMaker AI Amazon SageMaker HyperPod ra mắt triển khai mô hình để tăng tốc vòng đời phát triển mô hình AI sinh Amazon SageMaker AI Khách hàng của Amazon SageMaker AI Về tác giả Ankur Mehrotra gia nhập Amazon từ năm 2008 và hiện là Tổng Giám đốc Amazon SageMaker AI. Trước SageMaker AI, anh đã tham gia xây dựng hệ thống quảng cáo và công nghệ định giá tự động của Amazon.com.\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Nâng cao độ chính xác dự báo thời tiết bằng các phiên bản đồ họa chuyên sâu của Amazon AppStream 2.0 Bởi Rayette Toles-Abdullah, Austin Park, và Chris Quarcoo | Ngày 13 tháng 5 năm 2025 | liên quan Amazon AppStream 2.0, Best Practices, Customer Solutions, Public Sector\nKhả năng truy cập ứng dụng và dữ liệu từ bất cứ đâu trên bất kỳ thiết bị nào ngày càng quan trọng đối với lực lượng lao động làm việc từ xa, kết nối hạn chế, và phân tán. Các nhà nghiên cứu thực địa và nhà khí tượng học trên toàn cầu phụ thuộc vào việc thu nhận dữ liệu theo thời gian thực cho các khả năng thời tiết thiết yếu.\nHệ thống Xử lý Tương tác Thời tiết Nâng cao (AWIPS) là một hệ thống dự báo và hiển thị thời tiết được sử dụng bởi Cơ quan Thời tiết Quốc gia Hoa Kỳ (NWS) và các cơ quan khí tượng trên toàn thế giới. Hệ thống cho phép các nhà khí tượng giám sát, phân tích và dự đoán các mô hình thời tiết với độ chính xác cao hơn, mang lại dự báo tốt hơn và cảnh báo hiệu quả hơn nhằm giúp bảo vệ tính mạng và tài sản. AWIPS tích hợp dữ liệu từ nhiều nguồn như vệ tinh, radar và bóng thám không. Common AWIPS Visualization Environment (CAVE) là ứng dụng phía khách mà các nhà dự báo dùng để tương tác với hệ thống AWIPS. CAVE nhận dữ liệu đã xử lý từ các máy chủ AWIPS và cung cấp các công cụ trực quan hóa giúp các nhà khí tượng lập dự báo, phát hành cảnh báo, và trực quan hóa dữ liệu thời tiết.\nTrong bài viết này, chúng tôi sẽ hướng dẫn bạn cách truyền phát ứng dụng Common AWIPS Visualization Environment (CAVE) bằng Amazon AppStream 2.0-một dịch vụ truyền phát ứng dụng được quản lý, cho phép người dùng truyền phát các ứng dụng desktop từ Amazon Web Services (AWS) đến bất kỳ thiết bị nào mà không cần phần cứng hay phần mềm bổ sung.\nLợi ích khi chạy các ứng dụng đồ họa chuyên sâu bằng Amazon AppStream 2.0 AppStream 2.0 mang lại nhiều lợi ích. Với dịch vụ truyền phát này:\nNgười dùng có thể truy cập các ứng dụng desktop từ bất kỳ thiết bị được hỗ trợ nào, bao gồm laptop, máy tính để bàn, máy tính bảng và điện thoại. Điều này mang lại sự linh hoạt và tính di động, giúp nhân viên duy trì năng suất dù ở văn phòng, làm việc tại nhà hay đang di chuyển. Bạn có thể dễ dàng tăng hoặc giảm dung lượng GPU theo nhu cầu. Điều này giúp tối ưu chi phí bằng cách chỉ trả tiền cho những gì bạn sử dụng, loại bỏ nhu cầu duy trì phần cứng đắt tiền có thể bị nhàn rỗi trong giờ thấp điểm. Bạn không cần cấp thừa nguồn lực GPU, điều đặc biệt giá trị đối với các tổ chức có khối lượng công việc biến động hoặc theo mùa. Người dùng có thể truy cập các ứng dụng tăng tốc GPU từ bất kỳ thiết bị nào, bao gồm thiết bị di động. Điều này mang lại sự linh hoạt hơn so với việc gắn ứng dụng với các desktop cụ thể, và cung cấp hiệu năng nhất quán bất kể khả năng của thiết bị người dùng cuối. AppStream 2.0 xử lý các phức tạp của việc quản lý driver GPU, các đội máy (fleet) hỗ trợ GPU và các stack ứng dụng tối ưu cho GPU. Điều này giảm gánh nặng quản trị cho đội ngũ IT, giúp họ tập trung vào các sáng kiến chiến lược thay vì bảo trì định kỳ và xử lý sự cố. GPU được cung cấp theo mô hình trả tiền theo mức sử dụng (pay-as-you-go) trong AppStream 2.0, loại bỏ chi phí đầu tư ban đầu cao để mua và bảo trì máy chủ GPU vật lý. Điều này giúp giải pháp trở nên phải chăng hơn đối với nhiều tổ chức, đặc biệt là những đơn vị mới bắt đầu hoặc muốn mở rộng năng lực đồ họa mà không cần chi tiêu vốn lớn. AppStream 2.0 cung cấp các loại phiên bản tối ưu cho khối lượng công việc đồ họa như Graphics G4dn và Graphics G5 sử dụng GPU NVIDIA. Điều này mang lại hiệu năng cao cho các tác vụ như mô hình 3D và biên tập video, đồng thời cho phép bạn chọn loại phiên bản phù hợp nhất với yêu cầu ứng dụng và nhu cầu người dùng cụ thể. Khối lượng công việc GPU và dữ liệu của bạn không bao giờ lưu trú trên thiết bị người dùng cuối và được cô lập trong Đám mây AWS. Điều này tăng cường bảo mật và tuân thủ cho các ứng dụng nhạy cảm, đồng thời cung cấp khả năng kiểm soát tập trung đối với quyền truy cập dữ liệu và giảm rủi ro mất mát tài sản trí tuệ do thiết bị cục bộ bị xâm phạm. Hình 1. Trực quan hóa AWIPS CAVE về Bão Lee ngày 13/9/2023 sử dụng Amazon AppStream 2.0.\nKhám phá giải pháp AWIPS Trạm làm việc AWIPS CAVE là giao diện chính mà các nhà dự báo sử dụng. AWIPS CAVE có các yêu cầu hệ thống sau:\nThiết bị tương thích OpenGL 2.0 Tối thiểu 4GB RAM Tối thiểu 2GB dung lượng đĩa cho bộ nhớ đệm Card đồ họa NVIDIA Driver NVIDIA mới nhất Để cấu hình ứng dụng AWIPS cho Amazon AppStream 2.0, bạn sẽ thực hiện các bước sau:\nTạo Image dựa trên Linux Trước tiên, chúng ta sẽ chuẩn bị môi trường Linux nền tảng và cài đặt AWIPS CAVE cùng các phụ thuộc của nó. Điều này tạo nền tảng cho ứng dụng truyền phát của chúng ta.\nTạo Manifest Tối ưu hóa Ứng dụng Amazon AppStream 2.0 sử dụng các tệp manifest để tối ưu hiệu năng truyền phát ứng dụng bằng cách nạp trước các tệp cần thiết. Script này giúp xác định tất cả các tệp mà CAVE cần trong thời gian chạy.\nThêm Ứng dụng vào Danh mục Amazon AppStream Đăng ký CAVE trong danh mục ứng dụng Amazon AppStream, xác định đường dẫn khởi chạy, tên hiển thị và tệp manifest tối ưu hóa mà chúng ta đã tạo.\nCấu hình Fleet Tạo một fleet để quản lý các phiên bản sẽ chạy ứng dụng truyền phát của bạn. Chọn giữa cấu hình on-demand (tiết kiệm chi phí) hoặc always-on (sẵn sàng tức thì).\nKhuyến nghị chọn Graphics G4dn (stream.graphics.g4dn.xlarge) hoặc Graphics Pro (stream.graphics-pro.4xlarge) Chọn loại fleet “On-demand” Đặt các giới hạn dung lượng mong muốn Tạo Image Tạo image Amazon AppStream cuối cùng sẽ được dùng để khởi chạy các phiên truyền phát. Quá trình này chụp lại tất cả ứng dụng và cấu hình đã cài đặt.\nCấu hình Xác thực Người dùng Chọn giữa việc quản lý người dùng trực tiếp trong Amazon AppStream hoặc tích hợp với nhà cung cấp danh tính hiện có của bạn.\nCấu hình xác thực Amazon Cognito User Pool Tích hợp Môi trường Amazon AppStream với AWS Identity Center. Hình sau mô tả kiến trúc cấp cao của giải pháp.\nHình 2. Sơ đồ kiến trúc của giải pháp mô tả trong bài. Các thành phần chính của giải pháp gồm Amazon AppStream 2.0, Amazon S3, Amazon EFS, Amazon Aurora, và Amazon EC2.\nCác trường hợp sử dụng AWIPS ngoài hiện trường Các Trung tâm Dự báo Sông (RFC) của NWS sử dụng AWIPS CAVE để giám sát và dự đoán mực nước sông, suối, phát hành cảnh báo lũ, và cung cấp thông tin về nguồn nước và điều kiện hạn hán. Các Văn phòng Dự báo Thời tiết (WFO) dựa vào AWIPS CAVE để cung cấp cho công chúng các dự báo thời tiết địa phương, cảnh báo và khuyến cáo. Các văn phòng này cũng sử dụng AWIPS CAVE để phối hợp với các WFO khác, các cơ quan liên bang và tiểu bang, cũng như các đối tác khu vực tư nhân. Trung tâm Bão Quốc gia NWS (NHC) sử dụng AWIPS CAVE để theo dõi và dự báo xoáy thuận nhiệt đới, bao gồm bão và áp thấp nhiệt đới. AWIPS CAVE hỗ trợ NHC trong việc cung cấp thông tin kịp thời và chính xác cho công chúng, các quan chức quản lý khẩn cấp và các bên liên quan khác. Ngoài ra, một số trường đại học và viện nghiên cứu tập trung vào khí tượng và khoa học khí quyển cũng sử dụng AWIPS CAVE cho mục đích nghiên cứu, giảng dạy và đào tạo.\nKết luận Việc tích hợp AWIPS CAVE với Amazon AppStream 2.0 đại diện cho một bước tiến đáng kể trong công nghệ và khả năng tiếp cận của dự báo thời tiết. Giải pháp này đáp ứng nhu cầu ngày càng tăng về truy cập từ xa tới các ứng dụng trọng yếu trong lĩnh vực khí tượng, đồng thời mang lại nhiều lợi ích về tính linh hoạt, hiệu quả chi phí và hiệu năng.\nBằng cách tận dụng sức mạnh của điện toán đám mây và tăng tốc GPU, các nhà khí tượng và nhà nghiên cứu hiện có thể truy cập các công cụ phân tích thời tiết tinh vi từ bất kỳ đâu, trên bất kỳ thiết bị nào. Điều này không chỉ nâng cao khả năng cung cấp các dự báo chính xác và kịp thời mà còn cải thiện hiệu quả tổng thể của các dịch vụ thời tiết.\nKhi chúng ta tiếp tục đối mặt với các mô hình thời tiết ngày càng phức tạp và thách thức khí hậu, những đổi mới công nghệ như vậy sẽ đóng vai trò then chốt trong việc hỗ trợ công việc của các nhà khí tượng và cuối cùng là góp phần vào an toàn, sẵn sàng của cộng đồng.\nVề tác giả Rayette Toles-Abdullah Rayette là kiến trúc sư giải pháp chính trong đội Worldwide Public Sector Federal Civilian tại AWS. Rayette là một chuyên gia công nghệ với hơn 23 năm kinh nghiệm, chuyên về tích hợp hệ thống, hiện đại hóa ứng dụng, và triển khai các giải pháp công nghệ tác động cao để giải quyết nhu cầu kinh doanh và nhiệm vụ. Austin Park Austin là kiến trúc sư giải pháp trong đội Worldwide Public Sector Federal Civilian tại AWS. Austin là một chuyên gia công nghệ với hơn 2 năm kinh nghiệm, chuyên về hệ thống lưu trữ. Austin đam mê hỗ trợ khách hàng AWS trên hành trình lên đám mây. Chris Quarcoo Chris là kiến trúc sư giải pháp trong đội Worldwide Public Sector tại AWS, với hơn 4 năm kinh nghiệm trong ngành CNTT. Chuyên về vận hành đám mây và công nghệ container, anh thiết kế và triển khai các giải pháp đám mây cho các tổ chức chính phủ và khu vực công. Chris tận dụng công nghệ AWS để giúp khách hàng hiện đại hóa hạ tầng CNTT, nâng cao chất lượng dịch vụ, và đạt được các mục tiêu nhiệm vụ trọng yếu trong khu vực công. "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Hồ dữ liệu địa không gian với Amazon Redshift Bởi Jeremy Spell và Jeff DeMuth | Ngày 10 tháng 7 năm 2025 | liên quan Amazon Redshift, AWS Glue, AWS Lake Formation, Technical How-to\nKiến trúc hồ dữ liệu giúp tổ chức chuyển dữ liệu khỏi các hệ thống lưu trữ cao cấp mà vẫn không mất khả năng truy vấn và phân tích. Cách tiếp cận này hữu ích với dữ liệu địa không gian, khi các nhà xây dựng có thể có hàng terabyte dữ liệu ít truy cập trong cơ sở dữ liệu cần duy trì tiết kiệm chi phí. Tuy nhiên, điều này đòi hỏi công cụ truy vấn hồ dữ liệu phải hỗ trợ kiểu dữ liệu và hàm của hệ thống thông tin địa lý (GIS).\nAmazon Redshift hỗ trợ truy vấn dữ liệu không gian, bao gồm các kiểu và hàm GEOMETRY và GEOGRAPHY dùng trong truy vấn hệ thống GIS. Ngoài ra, Amazon Redshift cho phép bạn truy vấn dữ liệu địa không gian cả trong hồ dữ liệu trên Amazon S3 và trong kho dữ liệu Redshift, giúp bạn linh hoạt trong cách truy cập dữ liệu. Bên cạnh đó, AWS Lake Formation và hỗ trợ AWS Identity and Access Management (IAM) trong Eris’s ArcGIS Pro cung cấp cách kết nối an toàn giữa hồ dữ liệu địa không gian và công cụ trực quan hóa bản đồ. Bạn có thể thiết lập, quản lý, và bảo mật hồ dữ liệu địa không gian trên đám mây chỉ với vài cú nhấp.\nTrong bài viết, chúng tôi hướng dẫn cách thiết lập hồ dữ liệu địa không gian bằng Lake Formation và truy vấn dữ liệu với ArcGIS Pro qua Amazon Redshift Serverless.\nTổng quan giải pháp Trong ví dụ, một sở y tế quận dùng Lake Formation để bảo vệ hồ dữ liệu chứa dữ liệu thông tin sức khỏe (PHI). Các nhà dịch tễ học muốn tạo bản đồ các phòng khám cung cấp tiêm chủng cho cộng đồng. Các nhà phân tích GIS của quận cần quyền truy cập hồ dữ liệu để tạo bản đồ yêu cầu nhưng không được phép truy cập dữ liệu PHI.\nGiải pháp dùng thẻ Lake Formation để cho phép truy cập cấp cột trong cơ sở dữ liệu đối với thông tin công khai gồm tên phòng khám, địa chỉ, mã zip và tọa độ kinh độ/vĩ độ, trong khi không cho phép truy cập dữ liệu PHI trong cùng bảng. Chúng tôi dùng Redshift Serverless và Amazon Redshift Spectrum để truy cập dữ liệu này từ ArcGIS Pro, phần mềm bản đồ GIS của Esri, một đối tác của AWS.\nSau đây là lược đồ mẫu cho bài viết.\nMô tả Tên cột Thẻ Geoproperty ID bệnh nhân patient_id Không ID phòng khám clinic_id Có Địa chỉ phòng khám clinic_address Có Mã ZIP phòng khám clinic_zip Có Thành phố phòng khám clinic_city Có Tên bệnh nhân first_name Không Họ bệnh nhân last_name Không Địa chỉ bệnh nhân patient_address Không Mã ZIP bệnh nhân patient_zip Không Loại vắc xin vaccination_type Không Vĩ độ phòng khám clinic_lat Có Kinh độ phòng khám clinic_long Có Các bước thiết lập giải pháp:\nTriển khai hạ tầng bằng AWS CloudFormation. Tải một CSV với dữ liệu mẫu lên bucket Amazon S3 và chạy AWS Glue crawler để dò dữ liệu. Thiết lập quyền Lake Formation. Cấu hình Amazon Redshift Query Editor v2. Thiết lập schema trong Amazon Redshift. Tạo view trong Amazon Redshift. Tạo người dùng cơ sở dữ liệu cục bộ trong ArcGIS Pro. Kết nối ArcGIS Pro với cơ sở dữ liệu Redshift. Điều kiện tiên quyết Bạn cần:\nTài khoản AWS Lake Formation được bật ở AWS Region mục tiêu Hiểu biết về Lake Formation và thiết lập quyền trên bảng ArcGIS Pro Kết nối mạng từ client ArcGIS Pro tới VPC nơi tài nguyên Amazon Redshift được triển khai qua VPN hoặc AWS Direct Connect Thiết lập hạ tầng với AWS CloudFormation Để tạo môi trường demo, làm theo các bước:\nĐăng nhập AWS Management Console bằng tài khoản quản trị AWS và quản trị hồ dữ liệu Lake Formation-tài khoản này cần vừa là admin của tài khoản vừa là admin của hồ dữ liệu để template hoàn tất. Mở console AWS CloudFormation Chọn Launch Stack. Template CloudFormation tạo các thành phần:\nS3 bucket – samp-clinic-db-{ACCOUNT\\_ID} AWS Glue database – samp-clinical-glue-db AWS Glue crawler – samp-glue-crawler Redshift Serverless workgroup – samp-clinical-rs-wg Redshift Serverless namespace – samp-clinical-rs-ns IAM role for Amazon Redshift – demo-RedshiftIAMRole-{UNIQUE\\_ID} IAM role for AWS Glue – samp-clinical-glue-role Lake Formation tag – geoproperty Tải CSV lên S3 và chạy AWS Glue crawler Tiếp theo, tạo hồ dữ liệu trong môi trường demo, rồi dùng AWS Glue crawler để điền cơ sở dữ liệu AWS Glue và cập nhật schema và metadata trong AWS Glue Data Catalog.\nStack CloudFormation đã tạo sẵn S3 bucket, cơ sở dữ liệu AWS Glue và crawler. Chúng tôi cung cấp bộ dữ liệu thử hư cấu đại diện thông tin bệnh nhân và phòng khám. Tải file và làm theo:\nTrên console AWS CloudFormation, mở stack vừa khởi chạy. Ở tab Resources, chọn liên kết tới S3 bucket. Chọn Upload và tải file CSV (data-with-geocode.csv), rồi chọn Upload. Trên console AWS Glue, chọn Crawlers trong điều hướng. Chọn crawler bạn tạo với stack và nhấn Run.\nCrawler chạy khoảng một phút và sẽ điền bảng tên clinic-sample-s3\\_ACCOUNT\\_ID với dữ liệu hư cấu. Chọn Tables trong điều hướng và mở bảng crawler đã tạo. Bạn sẽ thấy tập dữ liệu chứa các trường PHI và thông tin nhận dạng cá nhân (PII).\nGiờ ta đã có cơ sở dữ liệu và Data Catalog được điền schema và metadata để dùng cho phần còn lại.\nThiết lập quyền Lake Formation Tiếp theo, chúng tôi minh họa cách bảo vệ dữ liệu PHI để tuân thủ và vẫn hỗ trợ nhà phân tích GIS làm việc hiệu quả. Để bảo vệ hồ dữ liệu, dùng AWS Lake Formation. Để thiết lập đúng quyền Lake Formation, cần hiểu cách truy cập hồ dữ liệu được thiết lập.\nData Catalog cung cấp metadata và schema cho phép dịch vụ truy cập dữ liệu trong hồ. Để truy cập hồ dữ liệu từ ArcGIS Pro, dùng ArcGIS Pro Redshift connector, cho phép kết nối từ ArcGIS Pro tới Amazon Redshift. Amazon Redshift có thể truy cập Data Catalog và cung cấp kết nối tới hồ dữ liệu. Template CloudFormation đã tạo Redshift Serverless instance và namespace cùng một vai trò IAM để cấu hình kết nối này. Ta vẫn cần thiết lập quyền Lake Formation để nhà phân tích GIS chỉ truy cập các trường công khai, không truy cập các trường chứa PHI hoặc PII. Ta sẽ gán thẻ Lake Formation cho các cột chứa thông tin công khai và gán quyền cho nhà phân tích GIS để truy cập các cột có thẻ này.\nMặc định, cấu hình Lake Formation cho Super access tới IAMAllowedPrinciples; điều này nhằm tương thích ngược như nêu trong thay đổi cài đặt mặc định cho hồ dữ liệu. Để minh họa cấu hình an toàn hơn, chúng ta sẽ gỡ cấu hình mặc định này.\nTrên console Lake Formation, chọn Administration trong điều hướng. Trong mục Data Catalog settings, đảm bảo Use only IAM access control for new databases và Use only IAM access control for new tables in new databases không được chọn.\nTrong điều hướng, dưới Permissions, chọn Data permissions. Chọn IAMAllowedPrincipals và nhấn Revoke. Chọn Tables trong điều hướng. Mở bảng clinic-sample-s3\\_ACCOUNT\\_ID và chọn Edit schema. Chọn các trường bắt đầu bằng clinic_ và chọn Edit LF-Tags. Stack CloudFormation đã tạo thẻ Lake Formation tên geoproperty. Gán geoproperty là khóa và giá trị true cho tất cả các trường clinic_, rồi chọn Save.\nTiếp theo, cấp quyền cho vai trò IAM của Amazon Redshift để truy cập các trường gắn thẻ geoproperty = true. Chọn Data lake permissions, rồi chọn Grant. Với IAM role, chọn demo-RedshiftIAMRole-UNIQUE_ID. Chọn geoproperty cho khóa và true cho giá trị. Trong Database permissions, chọn Describe, và trong Table permissions, chọn Select và Describe. Cấu hình Amazon Redshift Query Editor v2\nTiếp theo, cấu hình ban đầu cho Amazon Redshift cần thiết cho vận hành cơ sở dữ liệu. Chúng tôi dùng một secret của AWS Secrets Manager do template tạo để quản lý mật khẩu an toàn theo best practice của AWS.\nTrên console Amazon Redshift, chọn Query editor v2. Lần đầu khởi chạy Amazon Redshift sẽ hiện cấu hình một lần cho tài khoản. Với bài này, để mặc định và chọn Configure account. Xem thêm các tùy chọn tại Configuring your AWS account.\nTrình soạn truy vấn cần thông tin xác thực để kết nối tới serverless instance; thông tin này đã được template tạo và lưu trong Secrets Manager.\nChọn Other ways to connect, rồi chọn AWS Secrets Manager. Ở Secret, chọn (Redshift-admin-credentials). Chọn Save.\nThiết lập schema trong Amazon Redshift\nExternal schema trong Amazon Redshift là tính năng tham chiếu schema tồn tại ở nguồn dữ liệu bên ngoài. Tham khảo External schemas in Amazon Redshift Spectrum để tạo external schema. Ta dùng external schema để cung cấp quyền truy cập hồ dữ liệu trong Amazon Redshift. Từ ArcGIS Pro, ta sẽ kết nối tới Amazon Redshift để truy cập dữ liệu địa không gian.\nVai trò IAM dùng khi tạo external schema cần được liên kết với namespace Redshift. Việc này đã được template thiết lập, nhưng nên kiểm tra lại trước khi tiếp tục.\nTrong Redshift Serverless console, chọn Namespace configuration ở bảng điều hướng. Chọn namespace (sample-rs-namespace).\nỞ tab Security and encryption, bạn sẽ thấy vai trò IAM do CloudFormation tạo. Nếu vai trò hoặc namespace không có, hãy kiểm tra stack trong AWS CloudFormation trước khi tiếp tục. Sao chép ARN của vai trò để dùng sau.\nChọn Query data để quay lại trình soạn truy vấn. Trong query editor, nhập lệnh SQL sau; nhớ thay ví dụ ARN bằng ARN của bạn. Lệnh SQL này tạo external schema dùng cùng vai trò Redshift gắn với namespace để gắn vào cơ sở dữ liệu AWS Glue. CREATE EXTERNAL SCHEMA samp\\_clinic\\_sch\\_ext FROM DATA CATALOG database \u0026#39;sample-glue-database\u0026#39; IAM\\_ROLE \u0026#39;arn:aws:iam::{ACCOUNT\\_ID}:role/demo-RedshiftIAMRole-{UNIQUE\\_ID}’; Trong query editor, thực hiện truy vấn select trên sample-glue-database SELECT * FROM \u0026#34;dev\u0026#34;.\u0026#34;samp_clinic_sch_ext\u0026#34;.\u0026#34;clinic-sample_s3_{ACCOUNT_ID}\u0026#34;; Vì vai trò liên quan đã được cấp quyền truy cập các cột gắn thẻ geoproperty = true, chỉ các vùng này sẽ được trả về, thể hiện trong hình ảnh sau (dữ liệu minh họa là hư cấu).\n7. Dùng lệnh sau để tạo local schema trong Amazon Redshift. External schema không thể cập nhật; ta sẽ dùng local schema để thêm trường hình học với hàm Redshift.\nCREATE SCHEMA samp_clinic_sch_local Tạo view trong Amazon Redshift Để dữ liệu hiển thị từ ArcGIS Pro, chúng ta cần tạo một view. Sau khi thiết lập schema, ta tạo view có thể truy cập từ ArcGIS Pro.\nAmazon Redshift cung cấp nhiều hàm địa không gian dùng để tạo view với các trường mà ArcGIS Pro sử dụng để thêm điểm lên bản đồ. Ta sẽ dùng một hàm vì tập dữ liệu có vĩ độ và kinh độ.\nDùng lệnh SQL sau trong Amazon Redshift Query Editor để tạo view tên clinic_location_view. Thay {ACCOUNT_ID} bằng ID tài khoản của bạn.\nCREATE OR REPLACE VIEW \u0026#34;samp_clinic_sch_local\u0026#34;.\u0026#34;clinic_location_view\u0026#34; AS SELECT clinic_id as id, clinic_lat as lat, clinic_long as long, ST_MAKEPOINT(long, lat) as geom FROM “dev”.\u0026#34;samp_clinic_sch_ext\u0026#34;.\u0026#34;clinic-sample_s3_{ACCOUNT_ID}\u0026#34; WITH NO SCHEMA BINDING; View mới trong local schema sẽ có cột geom chứa các điểm bản đồ dùng bởi ArcGIS Pro để thêm điểm khi tạo bản đồ. Các điểm trong ví dụ là vị trí phòng khám cung cấp vắc xin. Thực tế, khi phòng khám mới được xây và dữ liệu mới được thêm vào hồ dữ liệu, vị trí của họ sẽ xuất hiện trên bản đồ sử dụng dữ liệu này.\nTạo người dùng cơ sở dữ liệu cục bộ cho ArcGIS Pro Trong demo, chúng tôi dùng một người dùng và nhóm cơ sở dữ liệu để cấp quyền cho client ArcGIS Pro. Nhập SQL sau trong Amazon Redshift Query Editor để tạo người dùng và nhóm:\nCREATE USER dbuser with PASSWORD ‘SET_PASSWORD_HERE’; CREATE GROUP esri_developer_group; ALTER GROUP esri_developer_group ADD USER dbuser; Sau khi chạy xong, dùng các lệnh sau để cấp quyền cho nhóm:\nGRANT USAGE ON SCHEMA samp_clinic_sch_local TO GROUP esri_developer_group; ALTER DEFAULT PRIVILEGES IN SCHEMA samp_clinic_sch_local GRANT SELECT ON TABLES TO GROUP esri_developer_group; GRANT SELECT ON ALL TABLES IN SCHEMA samp_clinic_sch_local TO GROUP esri_developer_group; Kết nối ArcGIS Pro với cơ sở dữ liệu Redshift Để thêm các kết nối cơ sở dữ liệu vào ArcGIS Pro, bạn cần endpoint cho workgroup của Redshift Serverless. Bạn có thể xem thông tin endpoint ở trang chi tiết workgroup sample-rs-wg trên console Redshift Serverless. Namespace và workgroup Redshift được liệt kê mặc định, thể hiện qua hình ảnh bên dưới.\nBạn có thể sao chép endpoint trong phần General information. Endpoint này sẽ cần được chỉnh sửa; đoạn :5439/dev sẽ cần được loại bỏ khi cấu hình connector trong ArcGIS Pro.\nMở ArcGIS Pro với dự án bạn muốn thêm kết nối Redshift. Đảm bảo đã cài đặt Amazon Redshift ODBC connector; đây là yêu cầu để kết nối. Trên menu, chọn Insert rồi Connections, Database, và New Database Connection. Ở Database Platform, chọn Amazon Redshift. Ở Server, dán endpoint đã sao chép (xóa mọi thứ sau .com khỏi endpoint). Ở Database, chọn cơ sở dữ liệu của bạn.\nNếu client ArcGIS Pro của bạn không truy cập được endpoint, bạn sẽ gặp lỗi ở bước này. Một đường mạng giữa client ArcGIS Pro và endpoint Redshift Serverless cần phải được tồn tại. Bạn có thể thiết lập đường mạng với Direct Connect, AWS Site-to-Site VPN, hoặc AWS Client VPN. Dù không khuyến nghị vì lí do bảo mật, bạn cũng có thể cấu hình endpoint công khai cho Amazon Redshift. Hãy tham vấn đội an ninh mạng để có hướng dẫn tốt nhất trước khi cho phép truy cập công khai tới Redshift Serverless.\nNếu có đường mạng mà vẫn lỗi kết nối, kiểm tra security group cho phép inbound từ subnet của ArcGIS Pro qua cổng mà Redshift Serverless dùng. Mặc định là 5439, nhưng có thể cấu hình dải cổng tùy môi trường; xem Connecting to Amazon Redshift Serverless để biết thêm.\nNếu kết nối thành công, ArcGIS Pro sẽ thêm kết nối Amazon Redshift dưới Connection File Name.\nChọn OK. Chọn kết nối để hiển thị view đã tạo có geometry (clinic_location_view). Nhấp phải view và chọn Add To Current Map. ArcGIS Pro sẽ thêm các điểm từ view lên bản đồ. Bản đồ cuối cùng được chỉnh ký hiệu để dùng biểu tượng dấu thập đỏ đại diện phòng khám thay vì chấm tròn.\nDọn dẹp tài nguyên Sau khi hoàn tất demo, làm theo bước sau:\nTrong console Amazon S3, mở bucket do stack CloudFormation tạo và xóa file data-with-geocode.csv. Trong console AWS CloudFormation, xóa stack demo để gỡ các tài nguyên đã tạo. Kết luận Bài viết đã hướng dẫn cách thiết lập Redshift Serverless để dùng dữ liệu địa không gian trong hồ dữ liệu nhằm tăng cường bản đồ trong ArcGIS Pro. Kỹ thuật này giúp nhà xây dựng và nhà phân tích GIS tận dụng bộ dữ liệu sẵn có trong hồ dữ liệu và biến đổi trong Amazon Redshift để làm giàu dữ liệu trước khi trình bày trên bản đồ. Chúng tôi cũng cho thấy cách bảo vệ hồ dữ liệu bằng Lake Formation, dò tập dữ liệu địa không gian với AWS Glue, và trực quan hóa dữ liệu trong ArcGIS Pro. Để biết thêm các thực hành tốt nhất về lưu trữ dữ liệu địa không gian trong Amazon S3 và truy vấn với Amazon Redshift, xem How to partition your geospatial data lake for analysis with Amazon Redshift. Mời bạn để lại phản hồi trong phần bình luận.\nVề tác giả Jeremy Spell là kiến trúc sư hạ tầng đám mây làm việc tại AWS Professional Services. Anh thích thiết kế và xây dựng giải pháp cho khách hàng. Trong thời gian rảnh, Jeremy thường làm món BBQ kiểu Texas và dành thời gian cho gia đình, cộng đồng nhà thờ. Jeff Demuth là kiến trúc sư giải pháp gia nhập AWS từ 2016. Anh tập trung vào cộng đồng địa không gian và đam mê hệ thống thông tin địa chất (GIS) và công nghệ. Ngoài công việc, Jeff thích du lịch, xây dựng ứng dụng IoT, và mày mò các thiết bị mới.\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.1-workshop-overview/5.1.1-whatisrag/","title":"Giải thích RAG","tags":[],"description":"","content":"Định nghĩa ngắn gọn RAG (viết tắt của Retrieval-Augmented Generation) là một kỹ thuật hoặc kiến trúc phần mềm trong lĩnh vực Trí tuệ nhân tạo (AI), được thiết kế để tối ưu hóa đầu ra của một Mô hình Ngôn ngữ Lớn (LLM).\nVề mặt bản chất, RAG là sự kết hợp giữa hai cơ chế:\nCơ chế truy xuất thông tin (Information Retrieval): Tìm kiếm dữ liệu từ một nguồn kiến thức bên ngoài (External Knowledge Base) có độ tin cậy cao. Cơ chế tạo sinh văn bản (Text Generation): Sử dụng khả năng hiểu và tổng hợp ngôn ngữ của LLM để tạo ra câu trả lời tự nhiên. Mục tiêu của RAG là cung cấp cho LLM thêm ngữ cảnh (context) chính xác, cập nhật và cụ thể, giúp mô hình vượt qua giới hạn của dữ liệu huấn luyện tĩnh (static training data).\nVì sao cần RAG? Các mô hình LLM truyền thống thường gặp 3 vấn đề lớn mà RAG có thể giải quyết:\nCập nhật thông tin (Freshness): LLM không cần huấn luyện lại (Re-training) hay tinh chỉnh (Fine-tuning) mà vẫn trả lời được các thông tin mới nhất, chỉ cần cập nhật vào cơ sở dữ liệu tìm kiếm. Sở hữu dữ liệu (Proprietary Data): Cho phép AI trả lời các câu hỏi về dữ liệu riêng tư của doanh nghiệp (tài liệu nội bộ, code base, thông tin khách hàng) mà mô hình gốc không hề biết. Tính xác thực (Grounding): Giảm thiểu \u0026ldquo;ảo giác\u0026rdquo; (Hallucination - AI bịa thông tin) bằng cách buộc AI phải trích dẫn hoặc dựa trên đoạn văn bản thực tế được tìm thấy. Kiến trúc hoạt động Quy trình xử lý một câu hỏi của RAG diễn ra như sau:\nBước Tên gọi Mô tả hành động 1 Retrieval (Truy xuất) Hệ thống tìm kiếm các đoạn văn bản liên quan nhất đến câu hỏi trong kho dữ liệu (thường dùng Vector Database). 2 Augmentation (Tăng cường) Ghép câu hỏi của người dùng + Dữ liệu vừa tìm được thành một \u0026ldquo;lời nhắc\u0026rdquo; (prompt) hoàn chỉnh. 3 Generation (Tạo sinh) Gửi prompt đó cho AI (LLM) để nó tổng hợp và viết ra câu trả lời cuối cùng cho người dùng. "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.1-workshop-overview/","title":"Giới thiệu","tags":[],"description":"","content":"Giới thiệu tổng quan Trong bài thực hành này, chúng ta sẽ tập trung xây dựng một trợ lý AI thông minh có khả năng \u0026ldquo;đọc hiểu\u0026rdquo; và trả lời câu hỏi dựa trên dữ liệu riêng của doanh nghiệp (kỹ thuật RAG).\nMục tiêu chính là thiết lập một quy trình xử lý dữ liệu hoàn toàn tự động và không máy chủ (Serverless), bao gồm các bước:\nIngestion (Nhập liệu): Đưa tài liệu gốc vào hệ thống. Indexing (Tạo chỉ mục): Chuyển đổi văn bản thành vector và lưu trữ để tra cứu. Retrieval \u0026amp; Generation (Truy xuất \u0026amp; Tạo sinh): Cấu hình mô hình AI để tìm kiếm thông tin liên quan và trả lời câu hỏi của người dùng. 💡 Điểm nổi bật: Giải pháp này giúp bạn không cần quản lý bất kỳ hạ tầng máy chủ nào, tối ưu hóa chi phí và thời gian vận hành.\nNội dung Giải thích RAG Giới thiệu các dịch vụ "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.1-workshop-overview/5.1.2-services/","title":"Giới thiệu các dịch vụ","tags":[],"description":"","content":"Kiến trúc giải pháp được xây dựng dựa trên sự phối hợp của 4 thành phần dịch vụ chính sau đây:\nKnowledge Bases for Amazon Bedrock Đây là một khả năng được quản lý toàn diện (fully managed capability) giúp kết nối các Mô hình Nền tảng (Foundation Models) với nguồn dữ liệu nội bộ của doanh nghiệp.\nTự động hóa quy trình RAG: Quản lý toàn bộ luồng công việc từ đầu đến cuối (end-to-end), bao gồm nhập dữ liệu (ingestion), chia nhỏ văn bản (chunking), tạo vector (embedding) và truy xuất thông tin (retrieval). Kết nối ngữ cảnh: Giúp các ứng dụng AI trả lời câu hỏi dựa trên dữ liệu riêng tư thay vì chỉ dựa vào dữ liệu huấn luyện chung chung. Không cần quản lý hạ tầng: Loại bỏ nhu cầu tự xây dựng và duy trì các đường ống dữ liệu (data pipelines) phức tạp. Amazon Simple Storage Service (Amazon S3) Là dịch vụ lưu trữ đối tượng (object storage) với khả năng mở rộng, độ bền dữ liệu 99,999999999% (11 số 9) và bảo mật hàng đầu.\nVai trò nguồn dữ liệu (Data Source): Đóng vai trò là kho chứa \u0026ldquo;sự thật\u0026rdquo; (source of truth). Lưu trữ tài liệu: Chứa các tệp phi cấu trúc như PDF, Word, hoặc Text mà doanh nghiệp muốn AI học. Đồng bộ hóa: Knowledge Base sẽ định kỳ quét bucket S3 này để đồng bộ hóa và cập nhật kiến thức mới nhất. Amazon OpenSearch Serverless Là tùy chọn triển khai không máy chủ (serverless) của Amazon OpenSearch Service, giúp chạy khối lượng công việc tìm kiếm và phân tích mà không cần quản lý cụm (cluster).\nVai trò kho lưu trữ Vector (Vector Store): Lưu trữ các chỉ mục vector (vector embeddings) được tạo ra từ tài liệu gốc. Tìm kiếm ngữ nghĩa (Semantic Search): Thực hiện thuật toán tìm kiếm tương đồng (similarity search/k-NN) để xác định các đoạn văn bản có ý nghĩa gần nhất với câu hỏi của người dùng. Tự động mở rộng: Tự động điều chỉnh tài nguyên tính toán và lưu trữ dựa trên nhu cầu thực tế. Amazon Bedrock Foundation Models (FMs) Cung cấp quyền truy cập vào các mô hình AI hàng đầu thông qua API thống nhất. Trong kiến trúc này, chúng ta sử dụng hai loại mô hình với vai trò riêng biệt:\nEmbedding Model (Amazon Titan Embeddings v2): Chuyển đổi văn bản (tài liệu từ S3 và câu hỏi của người dùng) thành các vector số học. Giúp máy tính có thể so sánh mức độ tương đồng về ý nghĩa giữa các đoạn văn. Text Generation Model (Anthropic Claude 3): Đóng vai trò là \u0026ldquo;bộ não\u0026rdquo; suy luận. Nhận câu hỏi kèm theo thông tin ngữ cảnh đã được truy xuất từ Vector Store. Tổng hợp thông tin và sinh ra câu trả lời tự nhiên, chính xác, có kèm trích dẫn nguồn. "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.3-knowledge-base/5.3.1-create-kb/","title":"Khởi tạo Knowledge Base","tags":[],"description":"","content":"Mục tiêu Chúng ta sẽ sử dụng Amazon Bedrock Wizard để thiết lập toàn bộ kiến trúc RAG. Quá trình này sẽ kết nối nguồn dữ liệu S3, mô hình Embedding và tự động khởi tạo kho lưu trữ Vector (OpenSearch Serverless).\nCác Bước Thực hiện Đăng nhập vào AWS Management Console và truy cập dịch vụ Amazon Bedrock. Trong menu bên trái, chọn Knowledge bases. Nhấp vào nút Create knowledge base ở góc trên bên phải của màn hình. Chọn Knowledge Base with vector store Bước 1: Cấu hình Knowledge Base\nTrên màn hình cấu hình đầu tiên:\nKnowledge base name: Nhập tên knowledge-base-demo Knowledge Base description - optional: Nhập Knowledge Base from AWS Overview (Phần này bạn cần mô tả dữ liệu bạn đã upload lên S3 trước đó). IAM permissions: Chọn tùy chọn Create and use a new service role. Service role name: Giữ giá trị mặc định do AWS đề xuất (bắt đầu bằng AmazonBedrockExecutionRoleForKnowledgeBase_...). Nhấp Next. Bước 2: Cấu hình Nguồn Dữ liệu\nKết nối đến S3 Bucket chứa các tài liệu:\nData source name: Nhập knowledge-base-demo S3 URI: Nhấp vào nút Browse S3. Trong cửa sổ pop-up, chọn bucket rag-workshop-demo\u0026gt; mà bạn đã tạo trong phần trước. Nhấp Choose. Giữ lại các cấu hình Default. Nhấp Next. Bước 3: Lưu trữ \u0026amp; Xử lý Đây là bước quan trọng nhất để xác định mô hình AI và vị trí lưu trữ vector:\nEmbeddings model:\nNhấp Select model. Chọn model: Titan Embeddings G1 - Text v2. Vector Store:\nVector store creation method: Chọn Quick create a new vector store - Recommended Vector store type - new: Chọn Amazon OpenSearch Serverless Lưu ý: Tùy chọn này cho phép AWS tự động tạo một cluster Amazon OpenSearch Serverless để lưu trữ dữ liệu, giúp bạn không phải quản lý cơ sở hạ tầng thủ công. Nhấp Next. Bước 4: Xem xét và Tạo Knowledge Base\nXem xét tất cả thông tin cấu hình trên trang Review. Đảm bảo các mục S3 URI và Model đều chính xác. Cuộn xuống cuối trang và nhấp vào nút Create knowledge base. Bước 5: Chờ Khởi tạo\nSau khi nhấp Create, hệ thống sẽ bắt đầu quá trình khởi tạo cơ sở hạ tầng nền cho Vector Store.\nThời gian chờ: Khoảng 2 - 5 phút. Lưu ý: Vui lòng không đóng trình duyệt trong thời gian này. Thành công: Khi màn hình hiển thị thông báo màu xanh \u0026ldquo;Knowledge base created successfully\u0026rdquo;, bạn đã hoàn thành bước này và sẵn sàng cho phần tiếp theo. "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.2-prerequiste/5.2.1-model-access/","title":"Kiểm tra truy cập Model","tags":[],"description":"","content":"Tổng quan Theo chính sách mới của AWS, các mô hình nền tảng (Foundation Models) thường được tự động kích hoạt. Tuy nhiên, đối với các mô hình của đối tác thứ ba như Anthropic (Claude), người dùng lần đầu tiên sử dụng tại một Region mới bắt buộc phải khai báo thông tin sử dụng (Use Case) mới có thể gọi được mô hình.\nĐảm bảo tài khoản AWS của bạn có quyền truy cập và sử dụng mô hình Anthropic Claude 3 Sonnet. Đây là bước bắt buộc để tránh lỗi AccessDenied khi Chatbot hoạt động sau này. Nếu đây là lần đầu tiên bạn sử dụng model này tại Region mới, bạn cần thực hiện khai báo mục đích sử dụng (Use Case).\nKiểm tra truy cập Chúng ta sẽ thực hiện một bài kiểm tra nhanh (Test Run) để đảm bảo tài khoản của bạn đã sẵn sàng.\nĐầu tiên ở thanh tìm kiếm, truy cập vào Amazon Bedrock.\nBước 1. Truy cập Chat Playground\nTại menu bên trái Bedrock Console, tìm mục Playgrounds. Click Chat. Bước 2. Chọn Model kiểm thử\nClick Select model (phía trên khung chat). Category: Chọn Anthropic. Model: Chọn Claude 3 Sonnet (hoặc Claude 3.5 Sonnet). Throughput: Chọn On-demand. Click Apply. Bước 3. Gửi tin nhắn kích hoạt\nTrong khung chat: Nhập Hello. Click Run. Quan sát kết quả: Nếu AI trả lời: Thành công (Chuyển ngay sang phần 5.2.2). Nếu hiện lỗi màu đỏ hoặc popup \u0026ldquo;Submit use case details\u0026rdquo;: Cần khai báo thông tin (Làm tiếp bước 4 bên dưới).\nBước 4. Khai báo Use Case (Chỉ thực hiện nếu gặp lỗi ở bước 3)\nClick Submit use case details (trong thông báo lỗi). Điền biểu mẫu: Company Name: Nhập Personal Learning. Company website URL: Nhập https://daihoc.fpt.edu.vn/ Industry: Chọn Education. Chọn Intended Use Describe\u0026hellip; Nhập Research \u0026amp; Development. Click Submit. Đợi 1 phút, quay lại khung chat, Click Run lại tin nhắn Hello để xác nhận thành công. "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Trong trang này bạn sẽ cần giới thiệu worklog của bạn như thế nào? Bạn hoàn thành chương trình trong vòng bao nhiêu tuần? Bạn đã làm gì trong các tuần đó?\nThông thường và cũng là tiêu chuẩn, một worklog được thực hiện trong khoảng 3 tháng (trong suốt thời gian thực tập) với nội dung các tuần như sau:\nTuần 1: Làm quen với các nền tảng AWS/chương trình FCJ 2025\nTuần 2: Dịch vụ mạng trên AWS\nTuần 3: Dịch vụ Compute VM trên AWS\nTuần 4: Dịch vụ lưu trữ trên AWS\nTuần 5: Dịch vụ Bảo Mật trên AWS\nTuần 6: Dịch vụ Cơ sở dữ liệu trên AWS\nTuần 7: Học khóa học trên Skill Builder\nTuần 8: Học về NLP và FastAPI để ứng dụng vào dự án cuối kì\nTuần 9: Triển khai dự án Sprint 01 - Nghiên cứu về mô hình Speech to Text và OCR\nTuần 10: Triển khai dự án Sprint 02 - Cải tiến và nâng cấp chất lượng các mô hình\nTuần 11: Triển khai dự án Sprint 03 - Làm quen với các dịch vụ hỗ trợ trên AWS và ứng dụng vào dự án\nTuần 12: Triển khai dự án Sprint 04 - Kiểm tra toàn bộ các mô hình và xử lý lỗi\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Mục tiêu tuần 1: Kết nối với những bạn trong team và làm quen với các anh chị Champion trong First Cloud Journey. Tìm hiểu về các dịch vụ của AWS đem lại cho khách hàng. Hoàn thành bài Lab cũng như kiến thức của Module 1 trong FJC 2025 Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 - Đọc nội quy, quy định AWS.\n- Kết nối team, lập nhóm.\n- Lên kế hoạch học tập và dự án thực tập.\n- Tạo Google Sheet quản lý tiến độ. 08/09/2025 08/09/2025 Module 01 3 - Tìm hiểu khái niệm \u0026amp; lợi ích Cloud Computing.\n- Điểm khác biệt của AWS.\n- Lộ trình Cloud Journey. 09/09/2025 09/09/2025 Module 01 4 - Tìm hiểu AWS Global Infrastructure \u0026amp; Management Tools.\n- Tối ưu hóa chi phí AWS.\n- Lab 01: Tạo Account, cài đặt MFA, tạo Admin Group/User, dùng AWS Support. 10/09/2025 10/09/2025 Module 01 5 - Lab 07: Tạo các loại Budget (Cost, Usage, RI, Saving Plan).\n- Cách xóa tài nguyên.\n- Phân loại và ứng dụng Budget phù hợp. 11/09/2025 11/09/2025 Module 01 6 - Lab 09: Tìm hiểu các gói AWS Support.\n- Truy cập và khởi tạo yêu cầu hỗ trợ (Support Case). 12/09/2025 12/09/2025 Module 01 Kết quả đạt được tuần 1: Hiểu AWS là gì và các khái niệm và dịch vụ mà AWS cung cấp:\nĐiện toán đám mây. Sự khác biệt của AWS Cách để bắt đầu một hành trình lên mây Hạ tầng toàn cầu của AWS Công cụ quản lí AWS Services Cách tối ưu hóa chi phí trên AWS Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định MFA cho tài khoản Admin Group Admin User AWS Support Biết cách thiết lập các Budget:\nCost Budget Usage Budget RI Budget Saving Plan Budget Clean tài nguyên Hiểu rõ về các gói hỗ trợ và cách truy cập AWS Support\nGói Basic Gói Developer Gói Business Gói Enterprise "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"Vòng đời phát triển theo hướng AI: Tái định hình kỹ thuật phần mềm Mục Đích Của Sự Kiện Hiểu rõ cách AI có thể tự động hóa và tối ưu hóa từng giai đoạn trong vòng đời phát triển phần mềm (Software Development Lifecycle – SDLC). Nắm bắt được triết lý AI hỗ trợ con người thay vì thay thế con người trong quá trình xây dựng ứng dụng. Trực tiếp quan sát cách Amazon Q và các công cụ AI khác hỗ trợ lập trình viên từ giai đoạn khởi tạo ý tưởng, viết mã, đến triển khai hạ tầng (IaC – Infrastructure as Code). Nhận thức được xu hướng “AI-first development” – nơi AI trở thành một phần tự nhiên của quy trình phát triển phần mềm tương lai. Danh Sách Diễn Giả Anh Toan Huynh - PMP, Senior Solutions Architect, AWS Chị My Nguyen - Senior Solutions Architect, AWS Nội Dung Nổi Bật Thử thách khi lập trình với AI Phần mở đầu trình bày những hạn chế và thách thức khi đưa AI vào lập trình:\nAI chưa thể xử lý các project có logic phức tạp, đòi hỏi hiểu biết sâu về ngữ cảnh nghiệp vụ. Lập trình viên khó kiểm soát chi tiết trong mã sinh ra nếu không mô tả rõ ràng mục tiêu và phạm vi. Chất lượng code phụ thuộc nhiều vào prompt và context mà người dùng cung cấp. Đây chính là lý do AI-DLC ra đời: tạo ra một quy trình có cấu trúc, giúp AI và con người phối hợp hiệu quả hơn.\nAI in Development – How AI is Changing Software Phần này phân tích cách AI đang thay đổi ngành phần mềm:\nAI hỗ trợ sinh code, tạo tài liệu kỹ thuật, thiết kế API, và kiểm thử tự động. Developer chuyển vai trò từ “code writer” sang “AI orchestrator” — người điều phối, định hướng và đánh giá đầu ra. Các công cụ như Amazon Q, GitHub Copilot, ChatGPT for Developers trở thành công cụ trung tâm trong workflow của team dev hiện đại. Giới thiệu về AI-DLC là gì AI-Driven Development Lifecycle (AI-DLC) là phương pháp tiếp cận phát triển phần mềm có sự đồng hành của AI, nơi mỗi bước được thiết kế để cung cấp cho AI ngữ cảnh và mục tiêu cụ thể nhằm tạo ra kết quả chính xác hơn.\nInception\nBuild Context on Existing Codes – AI được “nuôi” bằng mã nguồn hiện tại để hiểu cấu trúc dự án. Elaborate Intent with User Stories – Developer mô tả yêu cầu thông qua user story, làm rõ mục tiêu. Plan with Units of Work – Phân tách công việc thành các đơn vị nhỏ để AI có thể thực thi và sinh code từng phần. Construction\nDomain Model (Component Model) – Xây dựng mô hình miền hoặc sơ đồ kiến trúc logic. Generate Code \u0026amp; Test – AI sinh code và test tự động dựa trên thông tin đã lên kế hoạch. Add Architectural Components – Bổ sung các thành phần kiến trúc như API, data layer, logging, security. Deploy with IaC \u0026amp; Tests – Tự động triển khai hệ thống với Infrastructure as Code và test tích hợp. Mỗi bước đều cung cấp thêm “rich context” cho bước kế tiếp, giúp AI hiểu sâu hơn về hệ thống và sinh ra kết quả ngày càng chính xác.\nCORE CONCEPTS – Ba nguyên lý cốt lõi Context Awareness – AI cần có ngữ cảnh rõ ràng về mã, yêu cầu và domain để hoạt động hiệu quả. Collaborative Generation – Con người và AI hợp tác: AI sinh code, con người định hướng và kiểm duyệt. Continuous Refinement – Quy trình lặp lại liên tục để tinh chỉnh đầu ra và cải thiện chất lượng. Mob Elaboration Mob Elaboration là phương pháp mở rộng yêu cầu (intent elaboration) theo hình thức cộng tác nhóm:\nNhiều thành viên cùng nhau mô tả yêu cầu, đặt câu hỏi, và bổ sung thông tin cho AI. Giúp AI hiểu sâu hơn về nghiệp vụ, mục tiêu và logic phức tạp của dự án. Cách tiếp cận này giúp giảm rủi ro hiểu sai yêu cầu, đặc biệt trong các team lớn hoặc đa miền. 5-Stage Sequential Process của AI-DLC AI-DLC được thực hiện qua 5 giai đoạn:\nInception – Hiểu yêu cầu, phân tích hệ thống. Construction – Tạo mô hình miền và cấu trúc ban đầu. Generation – Sinh mã tự động. Testing – Tự động hóa kiểm thử đơn vị và tích hợp. Deployment – Triển khai ứng dụng với IaC và CI/CD pipelines. Mỗi vòng lặp giúp AI học thêm và cải thiện chất lượng đầu ra.\nDemo 1 – Trải nghiệm trực quan AI DLC với Amazon Q Buổi demo minh họa cách áp dụng AI-DLC trong thực tế thông qua một dự án nhỏ:\nBắt đầu từ ý tưởng đơn giản → chuyển thành user story mô tả yêu cầu nghiệp vụ. AI hỗ trợ phân chia công việc (Units of Work) và lập kế hoạch chi tiết cho từng module. Người tham dự có thể điều khiển AI thông qua câu hỏi, checkbox và điều kiện logic, giúp AI hiểu rõ phạm vi công việc. AI tiếp tục sinh code, viết test, tạo cấu trúc dự án và triển khai thử nghiệm tự động. Demo thể hiện rõ cách AI và con người phối hợp nhịp nhàng: AI làm việc lặp đi lặp lại, con người định hướng và ra quyết định chiến lược. Giới Thiệu Về Kiro Triết Lý Của Kiro\nPhần tiếp theo của workshop giới thiệu Kiro, một môi trường phát triển thông minh được thiết kế xoay quanh triết lý “AI-native development” – nơi AI là một phần cốt lõi, không phải chỉ là công cụ hỗ trợ.\nTriết lý của Kiro tập trung vào ba yếu tố chính:\nTích hợp sâu với quy trình phát triển – AI không chỉ hỗ trợ viết code, mà còn tham gia lập kế hoạch, quản lý context, và phân tích tác động thay đổi. Hiểu ngữ cảnh dự án toàn diện – Kiro duy trì trạng thái hiểu biết liên tục về cấu trúc hệ thống, cho phép AI tương tác với toàn bộ project thay vì từng file riêng lẻ. Kiểm soát \u0026amp; cộng tác thông minh – Lập trình viên có thể hướng dẫn AI thông qua contextual commands, giúp đảm bảo rằng mỗi thay đổi đều có mục đích rõ ràng và nhất quán với hệ thống. Cấu Trúc Project Trong Kiro\nKhác với các text editor truyền thống như VSCode hay JetBrains, Kiro không chỉ là môi trường viết mã — nó là AI workspace có nhận thức cấu trúc.\nCấu trúc project trong Kiro bao gồm:\nContext Layer – Lưu trữ ngữ cảnh, domain model, và quan hệ giữa các module. Task Layer – Quản lý các đơn vị công việc (Units of Work) được AI theo dõi và hoàn thành dần. AI Agent Layer – Mỗi tác vụ (code, test, refactor, deploy) có agent riêng đảm nhận, tạo ra mô hình phát triển đa agent – hợp tác – song song. Human-in-the-Loop Control – Lập trình viên có thể can thiệp ở mọi bước: xác nhận, sửa đổi hoặc từ chối đầu ra của AI. Điều này giúp Kiro không chỉ là công cụ sinh code mà trở thành một hệ sinh thái phát triển hợp tác giữa người và AI.\nDemo 2: Kiro – Áp Dụng AI-DLC Trong phần trình diễn, diễn giả minh họa cách Kiro vận hành AI-DLC một cách liền mạch:\nNgười dùng nhập một yêu cầu nghiệp vụ cơ bản, ví dụ “xây dựng hệ thống quản lý sự kiện”. Kiro tự động phân tích intent, tạo domain model và chia nhỏ thành các user story. AI trong Kiro sinh ra các module, component và test case tương ứng. Developer có thể tương tác qua bảng kiểm (checkbox-based task control) để xác nhận từng phần việc. Cuối cùng, Kiro triển khai hệ thống hoàn chỉnh với IaC và kiểm thử tự động. Buổi demo cho thấy AI-DLC không chỉ là lý thuyết, mà có thể được triển khai thực tế ngay trong môi trường Kiro — nơi AI, con người, và quy trình phát triển hòa quyện thành một hệ thống thống nhất.\nTrải nghiệm trong event Tham gia buổi workshop “AI DLC x Kiro: Reinventing Developer Experience with AI” là một trải nghiệm vô cùng bổ ích, giúp tôi hiểu rõ hơn về cách AI được tích hợp sâu vào môi trường phát triển phần mềm và cách mà triết lý thiết kế của Kiro mang lại hướng tiếp cận mới cho developer.\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đã chia sẻ về AI DLC – một nền tảng hỗ trợ phát triển phần mềm dựa trên AI, giúp tự động hóa nhiều quy trình trong SDLC. Ngoài ra, phần giới thiệu về Kiro Editor mang lại cái nhìn sâu sắc về cách xây dựng một text editor theo hướng AI-native thay vì chỉ “thêm plugin AI” vào môi trường cũ. Tôi đặc biệt ấn tượng với triết lý của Kiro: tối giản, hiệu năng cao, tập trung vào trải nghiệm người dùng và khả năng mở rộng theo module. Trải nghiệm kỹ thuật thực tế Trong học tập:\nÁp dụng AI-DLC structure cho personal projects Practice \u0026ldquo;Context Awareness\u0026rdquo; principle với AI assistants Build habit of writing clear requirements as user stories Cho career tương lai:\nUnderstand modular, extensible, maintainable system design như Kiro Master Amazon Q và AI tools khác hiệu quả Recognize importance of providing quality context cho AI Thay đổi mindset:\nApproach problems với \u0026ldquo;AI-augmented\u0026rdquo; thinking Consider building custom tools với deep AI integration Always ask: \u0026ldquo;How can AI assist better at this step?\u0026rdquo; Ứng dụng công cụ hiện đại Việc trải nghiệm AI DLC trên Kiro giúp tôi hiểu rõ hơn về khả năng tự động hóa quy trình phát triển, đặc biệt là ở các bước như code generation, documentation và debugging. Tôi nhận ra tiềm năng của việc xây dựng công cụ học tập và làm việc cá nhân có khả năng gợi ý thông minh, giúp rút ngắn thời gian phát triển và nâng cao chất lượng sản phẩm. Các khái niệm về modular design của Kiro cũng gợi ý cho tôi hướng đi trong việc thiết kế hệ thống linh hoạt, dễ mở rộng và dễ bảo trì. Kết nối và trao đổi Workshop tạo cơ hội để tôi giao lưu với các developer, nhà nghiên cứu AI và product designer, từ đó hiểu thêm về xu hướng AI-augmented development. Qua các cuộc thảo luận, tôi học được nhiều về cách AI có thể đóng vai trò cộng tác viên sáng tạo, giúp developer tập trung hơn vào logic và tư duy hệ thống thay vì những thao tác lặp lại. Bài học rút ra Tham gia workshop \u0026ldquo;AI DLC x Kiro\u0026rdquo; là một turning point trong cách tôi nhìn nhận về vai trò của AI trong software development.\nĐiều quan trọng nhất tôi học được không phải là các công cụ cụ thể, mà là mindset shift cần thiết:\nAI không phải là công cụ để code nhanh hơn AI là partner để tư duy và thiết kế hệ thống tốt hơn Structured process (như AI-DLC) quan trọng hơn là raw AI power Workshop cũng cho tôi thấy tương lai của development tools - nơi AI-first architecture như Kiro sẽ trở thành standard, và developers cần prepare cho paradigm shift này.\nNhững insights từ AWS Solution Architects và hands-on experience với Kiro đã trang bị cho tôi foundation vững chắc để áp dụng AI vào learning journey và future career trong software engineering.\nMột số hình ảnh khi tham gia sự kiện Hình nhóm check-in sau sự kiện\nĐây là khoảnh khắc check-in của nhóm sau khi kết thúc workshop. Sự kiện này mang lại nhiều insights quý giá về cách AI đang reshape development workflow.\nKhông gian sự kiện chuyên nghiệp\nWorkshop được tổ chức bài bản với đầy đủ demo stations và networking opportunities. Đây là một trong những sự kiện quan trọng giúp em hiểu sâu về AI-driven development.\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu tuần 2: Hiểu rõ AWS VPC: Nắm vững khái niệm cơ bản về VPC (Virtual Private Cloud) như một môi trường mạng logic cô lập, bao gồm các thành phần chính như Subnets (Public và Private), Route Tables, và ENI.\nKiểm soát lưu lượng và bảo mật: Học cách cấu hình các lớp bảo mật (Security Groups và NACLs) và kiểm soát đường đi của lưu lượng mạng ra/vào Internet (Internet Gateway và NAT Gateway).\nKết nối mạng phức tạp: Phân biệt và biết cách sử dụng các phương thức kết nối giữa các VPC (VPC Peering) và mô hình kết nối trung tâm (Transit Gateway).\nXây dựng môi trường Hybrid Cloud: Tìm hiểu các giải pháp kết nối mạng tại chỗ (on-premises) với AWS, bao gồm VPN (Site-to-Site) và kết nối riêng tư (AWS Direct Connect).\nPhân phối tải ứng dụng: Hiểu chức năng của Elastic Load Balancing (ELB) và phân biệt được các loại bộ cân bằng tải khác nhau (ALB, NLB, CLB, GLB) để đảm bảo tính sẵn sàng cao và khả năng mở rộng cho ứng dụng.\nCác công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 - Tìm hiểu kiến trúc VPC và các thành phần cốt lõi: Subnets, Route Table, ENI, Endpoints.\n- Các cổng kết nối: Internet Gateway, NAT Gateway.\n- Bảo mật: Security Group, NACL, Flow Logs. 15/09/2025 15/09/2025 Module 02 3 - Tìm hiểu kết nối mạng: VPC Peering, Transit Gateway.\n- Các giải pháp kết nối lai (Hybrid): VPN (Site-to-Site, Client-to-Site) \u0026amp; AWS Direct Connect. 16/09/2025 16/09/2025 Module 02 4 - Tổng quan về Elastic Load Balancing (ELB).\n- Phân biệt kiến trúc và ứng dụng của các loại: Application (ALB), Network (NLB), Classic (CLB) và Gateway Load Balancer. 17/09/2025 17/09/2025 Module 02 5 - Lab 03: Khởi tạo VPC, cấu hình Firewall và Site-to-Site VPN.\n- Lab 58: SSM Session Manager (kết nối EC2, quản lý logs, Port Forwarding).\n- Lab 19: Thiết lập VPC Peering (Network ACL, Route tables, DNS). 18/09/2025 18/09/2025 Module 02 6 - Lab 20: Cấu hình Transit Gateway (kết nối đa VPC, Route Tables).\n- Lab 10: Hybrid DNS (Outbound/Inbound Endpoints, Resolver Rules).\n- Nghiên cứu thêm: AWS Advanced Networking Specialty. 19/09/2025 19/09/2025 Module 02 Research Link Kết quả đạt được tuần 2: Giải thích được VPC là gì, vai trò của nó trong AWS, và các thành phần cốt lõi của nó (Subnet, Route Table, ENI). Phân biệt rõ ràng giữa Public Subnet (có Internet Gateway) và Private Subnet (sử dụng NAT Gateway để truy cập Internet). So sánh và đối chiếu hai cơ chế tường lửa chính: Security Group (stateful, áp dụng cho ENI) và NACL (stateless, áp dụng cho Subnet). Trình bày được cách thức kết nối riêng tư từ VPC đến các dịch vụ AWS (như S3) mà không cần qua Internet bằng VPC Endpoint. Đánh giá được ưu nhược điểm giữa hai giải pháp kết nối VPC: VPC Peering (kết nối 1:1, không hỗ trợ bắc cầu) và Transit Gateway (mô hình hub-and-spoke, đơn giản hóa quản lý). Mô tả được các phương thức thiết lập kết nối hybrid cloud, bao gồm VPN Site-to-Site (qua Internet) và AWS Direct Connect (kết nối vật lý riêng). Phân loại và lựa chọn được loại Elastic Load Balancer phù hợp cho từng kịch bản cụ thể: Application Load Balancer (ALB): Cho lưu lượng HTTP/HTTPS (Layer 7), hỗ trợ path-based routing. Network Load Balancer (NLB): Cho lưu lượng TCP/TLS (Layer 4), cần hiệu suất cực cao và IP tĩnh. Gateway Load Balancer (GLB): Dùng để tích hợp các thiết bị mạng ảo (virtual appliances). Xác định được các bài thực hành (Lab) cần thiết để củng cố kiến thức đã học về VPC, Peering, Transit Gateway và các dịch vụ liên quan. "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"Ứng dụng quản lý tài chính cá nhân (Vicobi) Bạn có thể đọc toàn bộ proposal ở đây: Vicobi Proposal 1. Tóm tắt điều hành Dự án Vicobi (Personal Finance Management App) hướng đến việc cung cấp một nền tảng quản lý tài chính cá nhân thông minh, hiện đại và mang tính tự động hóa cao. Vicobi đơn giản hóa việc quản lý tài chính qua 4 trụ cột chính:\nGhi chép thông minh (Smart Recording): Nhập liệu bằng giọng nói và quét hóa đơn, loại bỏ rào cản nhập liệu thủ công. Lập ngân sách theo mục tiêu (Goal-based Budgeting): Tự động hóa tạo và quản lý các hũ tiền (money jars) linh hoạt. Phân tích \u0026amp; Kiểm soát: Cung cấp báo cáo trực quan và hệ thống cảnh báo thông minh. Trợ lý tài chính (AI Chatbot): Tích hợp Chatbot AI đóng vai trò tư vấn viên, hỗ trợ giải đáp và nâng cao kiến thức tài chính. Về mặt công nghệ, Vicobi được xây dựng trên kiến trúc Microservices sử dụng .NET Aspire và FastAPI, triển khai trên AWS Cloud, đảm bảo tính linh hoạt và an toàn dữ liệu. Quy trình phát triển tuân theo mô hình Agile/Scrum (2 tuần/sprint trong giai đoạn phát triển chính), với mục tiêu hoàn thành MVP trong 2 tháng thực thi.\n2. Tuyên bố vấn đề Vấn đề hiện tại Trong thị trường năng động hiện nay, người dùng gặp khó khăn trong việc kiểm soát tài chính do \u0026ldquo;sức ỳ hành vi\u0026rdquo; — ngại ghi chép thủ công từng giao dịch. Các ứng dụng hiện có (như Money Lover, Misa Money Keeper) vẫn dựa nhiều vào nhập liệu bằng tay, gây ra tình trạng \u0026ldquo;mệt mỏi khi nhập liệu\u0026rdquo; (input fatigue) và tỷ lệ bỏ cuộc cao.\nGiải pháp Vicobi giải quyết vấn đề bằng cách tự động hóa cao độ quy trình nhập liệu thông qua AWS Cloud và Microservices:\nCông nghệ lõi: Tích hợp AI xử lý giọng nói tiếng Việt (Voice-to-Text) và nhận diện hóa đơn (OCR) chi tiết. Kiến trúc tối ưu: Sử dụng AWS ECS Fargate chạy mô hình Multi-container Task (gộp Backend .NET và AI Service) để giảm chi phí hạ tầng nhưng vẫn đảm bảo giao tiếp liền mạch. Frontend hiện đại: Sử dụng Next.js được lưu trữ trên Amazon S3 và phân phối toàn cầu qua Amazon CloudFront. Lợi ích và hoàn vốn đầu tư (ROI) Giải pháp mang lại lợi thế cạnh tranh rõ rệt:\nGiá trị người dùng: Giảm hơn 70% thao tác thủ công. Độ chính xác nhận diện giọng nói đạt 90% và trích xuất hóa đơn đạt 80%. Hiệu quả kinh tế: Tận dụng tối đa AWS Free Tier (S3, CloudFront, Cognito). Ngân sách vận hành tinh gọn khoảng ~$60/tháng cho hạ tầng và ~$15/tháng cho AI compute. Hoàn vốn: Dự kiến đạt ROI trong 6–12 tháng nhờ tiết kiệm thời gian và tăng hiệu suất. Khả năng mở rộng: Kiến trúc Microservices sẵn sàng cho việc tích hợp Mobile App hoặc Open Banking. 3. Kiến trúc giải pháp Hệ thống được thiết kế theo mô hình Microservices phân tán, sử dụng API Gateway làm điểm nhập duy nhất.\nChi tiết Tech Stack: Thành phần Công nghệ Chi tiết Frontend Next.js 16 App Router, TypeScript, Tailwind CSS, Zustand, React Query. Backend Core .NET Aspire Điều phối Microservices (User, Wallet, Transaction, Report, Notification). AI Service FastAPI (Python) Xử lý Voice (PhoWhisper), OCR (Bedrock), Chatbot (RAG). Database Polyglot PostgreSQL, MongoDB, Elasticsearch, Qdrant (Vector DB). Messaging RabbitMQ Giao tiếp bất đồng bộ giữa các service. Luồng hoạt động trên AWS: Truy cập: Người dùng truy cập qua Route 53, được bảo vệ bởi AWS WAF và tăng tốc bởi CloudFront. Xác thực: Amazon Cognito quản lý định danh và cấp phát JWT Token. Xử lý API: Request đi qua API Gateway, kết nối an toàn qua AWS PrivateLink tới Application Load Balancer (ALB). Compute: ALB phân phối tải tới các container trong ECS Fargate (nằm trong Private Subnet). DevOps: Quy trình CI/CD tự động hóa hoàn toàn bằng GitLab, build image đẩy lên Amazon ECR và update task trên ECS. 4. Triển khai kỹ thuật Các giai đoạn triển khai Dự án kéo dài 4 tháng (bao gồm thực tập):\nTháng 0 (Pre-internship): Lên ý tưởng và kế hoạch tổng thể. Tháng 1 (Foundation): Học AWS, nâng cấp kỹ năng .NET/Next.js/AI. Thiết lập VPC, IAM. Tháng 2 (Design): Thiết kế kiến trúc High-level \u0026amp; Detailed trên AWS. Tháng 3-4 (Realization): Coding, Integration Testing, Deploy lên AWS Production, thiết lập Monitoring. Sau tháng 5: Nghiên cứu phát triển Mobile App. Yêu cầu kỹ thuật chi tiết: Frontend: Triển khai Next.js 16 trên S3 + CloudFront. Sử dụng Origin Access Control (OAC) để bảo mật bucket. Backend: Sử dụng .NET Aspire để quản lý cấu hình Cloud-native. Database-per-service: PostgreSQL \u0026amp; MongoDB. Elasticsearch cho tìm kiếm giao dịch phức tạp. Background Jobs: Sử dụng Hangfire. AI Service Pipelines: Voice: Tiền xử lý bằng Pydub, Model PhoWhisper-small (VinAI) cho tiếng Việt. OCR: Amazon Bedrock (Claude 3.5 Sonnet Multimodal) để trích xuất thông tin hóa đơn chính xác. Chatbot (RAG): Knowledge Base lưu trong Qdrant, sinh câu trả lời qua Amazon Bedrock (Claude 3.5 Sonnet). Bảo mật: Mã hóa dữ liệu đường truyền (HTTPS/TLS 1.2+) và lưu trữ (AES-256). Quản lý bí mật (Secrets) chưa tích hợp sâu (đang ở mức MVP), sẽ nâng cấp lên AWS Secrets Manager trong tương lai. 5. Lộ trình \u0026amp; Mốc triển khai (Sprints) Giai đoạn thực thi chính được chia thành 4 Sprint:\nSprint 1: Core Foundation Xác thực (Cognito), Quản lý Ví (Wallets), Hũ chi tiêu (Spending Jars). Sprint 2: Core Features Giao dịch (CRUD), Xử lý giọng nói AI (Voice Processing). Sprint 3: Analytics Báo cáo/Biểu đồ, Hệ thống thông báo (SES), Message Broker. Sprint 4: Stabilization Kiểm thử tích hợp (Integration Testing), Tinh chỉnh UI, Deploy lên AWS ECS \u0026amp; CloudFront. Testing \u0026amp; Go-live: Cấu hình Domain, SSL, Monitoring Dashboard, UAT và bảo vệ đồ án. 6. Ước tính ngân sách Dựa trên bảng dự toán chi tiết cho giai đoạn MVP.\nBạn có thể xem chi tiết bảng dự toán chi phí bằng cách tải về các tệp sau: 📊 Tệp định dạng CSV 💾 Tệp định dạng JSON\nDịch vụ AWS Thành phần / Sử dụng Chi Phí (USD/tháng) Elastic Load Balancing Application Load Balancer $18.98 Amazon ECS Fargate (vCPU \u0026amp; Memory) $17.30 Amazon VPC VPC Endpoints \u0026amp; NAT $10.49 AWS WAF Web ACL \u0026amp; Requests $7.20 Amazon API Gateway API Calls \u0026amp; Data Transfer $2.50 Amazon CloudFront Data Transfer Out $2.00 Amazon ECR Storage $1.00 Amazon Route 53 Hosted Zones $0.54 Amazon S3 Standard Storage $0.34 TỔNG CHI PHÍ AWS ~$60.35 Chi phí khác:\nHạng mục Chi tiết Chi Phí (USD/tháng) AI Compute / Tooling Gemini API, Amazon Bedrock ~$15.00 TỔNG CỘNG DỰ ÁN ~$75.35 / tháng (Dựa trên giá On-Demand khu vực Singapore - ap-southeast-1)\n7. Đánh giá rủi ro Rủi ro chính: Lộ thông tin người dùng (Impact: High), Mất kết nối AWS Region (Impact: High), AI nhận diện sai (Impact: Medium). Chiến lược giảm thiểu: Bảo mật: Mã hóa AES-256, HTTPS, IAM Least Privilege, AWS WAF. High Availability: Triển khai Multi-AZ cho ECS và ALB. AI: Cải thiện model liên tục với dữ liệu thực tế. Resilience: Sử dụng RabbitMQ nội bộ để xử lý bất đồng bộ và retry. Kế hoạch dự phòng (Disaster Recovery): Sử dụng IaC (Infrastructure as Code) để khôi phục nhanh hạ tầng. 8. Kết quả kỳ vọng \u0026amp; Đội ngũ Kết quả mong đợi của dự án Nhập liệu tài chính tự động: Ứng dụng giúp người dùng tránh nhập liệu thủ công, chỉ cần chụp ảnh hóa đơn hoặc ghi âm giọng nói để hệ thống tự động phân loại chi tiêu. Quản lý tài chính trực quan: Người dùng có thể xem biểu đồ chi tiêu, báo cáo hàng tháng và nhận đề xuất tiết kiệm dựa trên hành vi tiêu dùng. Trải nghiệm người dùng tối thiểu: Giao diện web thân thiện, thiết kế hiện đại, được tối ưu hóa cho thiết bị di động và phù hợp với người mới bắt đầu quản lý tài chính. Hệ thống ổn định, có khả năng mở rộng: Kiến trúc microservices giúp dễ dàng thêm các tính năng mới như nhắc nhở chi tiêu, phân tích dự đoán AI hoặc mở rộng sang ứng dụng di động. Nâng cao kỹ năng nhóm phát triển: Các thành viên dự án có quyền truy cập thực tế vào các quy trình DevOps, triển khai CI/CD và tối ưu hóa ứng dụng trên nền tảng đám mây. Hạn chế của dự án Mô hình AI Việt Nam còn hạn chế: Khả năng nhận dạng giọng nói vùng miền hoặc hóa đơn viết tay vẫn chưa đạt độ chính xác cao.\nKhông có ứng dụng di động riêng biệt: Phiên bản MVP chỉ hỗ trợ nền tảng web, không có ứng dụng di động gốc.\nĐội ngũ thực hiện (Team): Họ tên Vai trò Email Lê Vũ Phương Hòa Backend Developer (Leader) hoalvpse181951@fpt.edu.vn Nguyễn Văn Anh Duy AI Developer (Member) duynvase181823@fpt.edu.vn Uông Tuấn Vũ Frontend Developer (Member) vuutse180241@fpt.edu.vn Trần Huỳnh Bảo Minh AI Developer (Member) baominhbrthcs@gmail.com Mentor Support:\nNguyễn Gia Hưng - Head of Solution Architects Văn Hoàng Kha - Cloud Security Engineer "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.2-prerequiste/5.2.2-prepare-data/","title":"Chuẩn bị dữ liệu nguồn","tags":[],"description":"","content":"Tổng quan Khởi tạo một kho lưu trữ đối tượng (S3 Bucket) để chứa các tài liệu gốc (PDF, Word, Text). Đây đóng vai trò là \u0026ldquo;nguồn sự thật\u0026rdquo; (Source of Truth) mà Knowledge Base sẽ truy cập để đọc hiểu, phân tích và đồng bộ hóa kiến thức cho AI. Bạn có thể lưu trữ kiến thức liên quan đến lĩnh vực của bạn sử dụng trong việc tạo trợ lý cá nhân hoặc Chatbot cho riêng bạn.\nChuẩn bị dữ liệu Chúng ta sẽ tạo một S3 Bucket để lưu trữ tài liệu gốc, đóng vai trò là nguồn tri thức cho Chatbot.\nBước 1. Tạo S3 Bucket\nTruy cập dịch vụ S3 từ thanh tìm kiếm. AWS Region: Chọn United States (N. Virginia us-east-1). Click Create bucket. Cấu hình thông tin Bucket: Bucket Type: Chọn General purpose Bucket name: Nhập rag-workshop-demo Object Ownership: Giữ mặc định ACLs disabled. Block Public Access settings: Giữ mặc định (Đã chọn Block all public access). Kéo xuống cuối trang, Click Create bucket. Kiểm tra tạo S3 Bucket thành công. Bước 2. Tải lên tài liệu mẫu\nĐây tài liệu mẫu, liên quan để tổng quan về kiến thức điện toán đám mây của AWS. Bạn có thể sử dụng để chạy demo hoặc upload dữ liệu của bạn. Tệp định dạng PDF\nTại danh sách Buckets, Click vào tên bucket bạn vừa tạo. Click Upload. Tại giao diện Upload: Click Add files. Chọn file tài liệu mẫu đính kèm ở phần trên hoặc file từ máy tính của bạn (Khuyên dùng file PDF hoặc Word có nhiều nội dung văn bản). Khi upload file xong, chọn file vừa upload, kéo xuống cuối trang, Click Upload. Khi thấy thông báo màu xanh \u0026ldquo;Upload succeeded\u0026rdquo;, Click Close. "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.2-prerequiste/","title":"Chuẩn bị môi trường","tags":[],"description":"","content":"1. Mục tiêu Trước khi bắt tay vào xây dựng ứng dụng, chúng ta cần thiết lập một nền tảng vững chắc. Giống như việc chuẩn bị nguyên liệu trước khi nấu ăn, phần này đảm bảo rằng tài khoản AWS của bạn đã sẵn sàng với đầy đủ quyền hạn và dữ liệu cần thiết.\nTrong phần này, chúng ta sẽ hoàn thành 3 mục tiêu khởi tạo quan trọng:\nChọn Region (Vùng): Thiết lập môi trường làm việc tại vùng United States N. Virginia (us-east-1) để tối ưu hóa tốc độ kết nối và đảm bảo tính sẵn sàng của dịch vụ. Kích hoạt Model (Model Access): Kiểm tra và đảm bảo tài khoản có quyền gọi model Anthropic Claude 3 – \u0026ldquo;bộ não\u0026rdquo; ngôn ngữ chính của hệ thống. Chuẩn bị Dữ liệu (Data Setup): Khởi tạo kho lưu trữ (S3 Bucket) và tải lên tài liệu nguồn để phục vụ cho quá trình nạp kiến thức (Ingestion) sau này. 2. Các thành phần chính Trong phần chuẩn bị này, chúng ta sẽ tương tác với các thành phần sau:\nAWS Management Console (Region Selector): Giao diện quản lý chung để chuyển đổi Region làm việc sang United States N. Virginia. Amazon Bedrock (Model Access \u0026amp; Playground): Nơi quản lý quyền truy cập các mô hình nền tảng (Foundation Models) và công cụ chat để kiểm tra nhanh khả năng phản hồi của AI. Amazon S3 (Simple Storage Service): Dịch vụ lưu trữ đối tượng, nơi chúng ta sẽ tạo Bucket để chứa các file tài liệu gốc (PDF, Word, Text). 3. Các bước triển khai Kiểm tra truy cập Model Chuẩn bị dữ liệu nguồn "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.3-knowledge-base/5.3.2-sync-data/","title":"Kiểm tra Vector Store và Đồng bộ Dữ liệu","tags":[],"description":"","content":"Mục tiêu Trước khi AI có thể trả lời, dữ liệu phải được nhập vào kho lưu trữ vector (Vector Store). Chúng ta sẽ thực hiện kiểm tra \u0026ldquo;Trước và Sau\u0026rdquo; để thấy rõ cách Bedrock tự động mã hóa và lưu trữ dữ liệu vào OpenSearch.\nCác Bước Thực hiện Bước 1: Kiểm tra Vector Store (Trạng thái Rỗng)\nChúng ta sẽ truy cập trực tiếp vào Amazon OpenSearch Serverless để xác nhận rằng chưa có dữ liệu nào tồn tại.\nTrong thanh tìm kiếm AWS Console, gõ Amazon OpenSearch Service và chọn Amazon OpenSearch Service. Trong menu bên trái, ở phần Serverless, chọn Collections. Nhấp vào tên Collection mới được tạo bởi Bedrock (thường có tên dạng bedrock-knowledge-data...). Trên trang chi tiết Collection, nhấp vào nút Open Dashboard (nằm ở góc trên bên phải màn hình).\nLưu ý: Nếu được yêu cầu đăng nhập, hãy sử dụng thông tin đăng nhập AWS hiện tại của bạn. Trong giao diện OpenSearch Dashboard: Nhấp vào biểu tượng Menu (3 đường ngang) ở góc trên bên trái. Chọn Dev Tools (thường nằm ở cuối danh sách menu). Trong ngăn Console (bên trái), nhập lệnh sau để kiểm tra dữ liệu: GET _search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} } } Nhấp vào nút Play (Run) (tam giác nhỏ bên cạnh dòng lệnh). Kết quả: Quan sát ngăn bên phải, hits -\u0026gt; total -\u0026gt; value là 0. Bước 2: Đồng bộ Dữ liệu\nBây giờ chúng ta sẽ kích hoạt Bedrock để đọc các file từ S3 và tải chúng vào OpenSearch.\nQuay lại tab Amazon Bedrock trên trình duyệt. Chọn Knowledge bases trong menu bên trái và nhấp vào tên KB bạn vừa tạo. Cuộn xuống phần Data source, đánh dấu vào ô (tick) bên cạnh tên nguồn dữ liệu (s3-datasource). Nhấp vào nút Sync (Màu cam). Chờ đợi: Quá trình này sẽ mất 5 - 10 phút tùy thuộc vào kích thước tài liệu mẫu. Chờ cho đến khi cột Sync status chuyển từ Syncing sang Available. Bước 3: Kiểm tra lại Vector Store (Đã có Dữ liệu)\nSau khi Bedrock báo hoàn tất Sync, chúng ta quay lại kho lưu trữ để xác minh dữ liệu đã được nhập thành công.\nChuyển sang tab OpenSearch Dashboard (vẫn còn mở từ Bước 1). Trong Dev Tools, nhấp lại nút Play (Run) với lệnh cũ: GET _search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} } } Kết quả: Phần hits -\u0026gt; total -\u0026gt; value sẽ lớn hơn 0 (ví dụ: 10, 20\u0026hellip; tùy thuộc vào số lượng đoạn văn bản). Bạn sẽ thấy chi tiết các vector (mảng số) và nội dung văn bản được lưu trữ trong trường _source. Chúc mừng! Bạn đã hoàn thành việc xây dựng \u0026ldquo;bộ não\u0026rdquo; cho AI. Dữ liệu đã được mã hóa và nằm an toàn trong Vector Database, sẵn sàng cho việc truy xuất.\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/4-eventparticipated/4.3-event3/","title":"Event 3","tags":[],"description":"","content":"WORKSHOP “KHOA HỌC DỮ LIỆU TRÊN NỀN TẢNG AWS” Mục Đích Của Sự Kiện Giới thiệu tổng quan hệ sinh thái các dịch vụ trí tuệ nhân tạo (AI) hiện có trên AWS. Hướng dẫn quy trình thực tế để xây dựng và huấn luyện mô hình AI sử dụng Amazon SageMaker. Minh họa cách thức đưa mô hình AI từ phòng thí nghiệm ra thực tế (deployment) và tích hợp vào ứng dụng thông qua API. Danh Sách Diễn Giả Anh Văn Hoàng Kha - Cloud Solutions Architect, Leader của AWS User Group (Chia sẻ góc nhìn kiến trúc giải pháp). Anh Bạch Doãn Vương - Cloud DevOps Engineer, AWS Community Builder (Chia sẻ góc nhìn vận hành và triển khai). Nội Dung Chuyên Sâu Tầm Quan Trọng Của Điện Toán Đám Mây Trong Data Science Phân tích vai trò cốt lõi của Cloud Computing: Không chỉ là nơi lưu trữ, Cloud cung cấp sức mạnh tính toán vô hạn để xử lý dữ liệu lớn (Big Data) và huấn luyện các mô hình AI phức tạp mà máy tính cá nhân khó đáp ứng.\nSo sánh hiệu quả giữa Cloud và On-premise (Máy chủ vật lý):\nCloud: Điểm mạnh nằm ở tính đàn hồi (Elasticity) — có thể tăng/giảm tài nguyên tức thì, triển khai cực nhanh, chuyển đổi chi phí đầu tư (CAPEX) thành chi phí vận hành (OPEX), và dễ dàng tích hợp các công nghệ mới. On-premise: Gặp rào cản lớn về chi phí phần cứng ban đầu, khó khăn trong việc mở rộng hạ tầng khi dữ liệu tăng đột biến và tốn kém nhân lực bảo trì. AWS đóng vai trò là xương sống cho toàn bộ Data Science pipeline: Cung cấp một quy trình khép kín từ lúc thu thập dữ liệu thô, làm sạch, huấn luyện đến khi mô hình được đưa vào sử dụng thực tế.\nPhân Tầng Kiến Trúc AI Trên AWS AWS phân loại các dịch vụ AI thành 3 tầng (layers) riêng biệt, được thiết kế để phù hợp với từng đối tượng người dùng có trình độ kỹ thuật và nhu cầu kiểm soát khác nhau:\n1. AI Services (Tầng Dịch Vụ Được Quản Lý Hoàn Toàn)\nGiải pháp \u0026ldquo;Mì ăn liền\u0026rdquo; dành cho Developer muốn tích hợp trí thông minh vào ứng dụng mà không cần am hiểu sâu về thuật toán ML.\nĐây là các mô hình đã được AWS huấn luyện sẵn (Pre-trained models) với hàng tỷ điểm dữ liệu.\nNgười dùng chỉ cần gửi dữ liệu qua API và nhận lại kết quả phân tích.\nCác dịch vụ tiêu biểu:\nAmazon Comprehend: Hiểu và phân tích ý nghĩa văn bản, cảm xúc người dùng (NLP). Amazon Translate: Xóa bỏ rào cản ngôn ngữ với khả năng dịch thuật tự động. Amazon Textract: \u0026ldquo;Đọc\u0026rdquo; tài liệu, bóc tách chữ viết và bảng biểu từ file scan/ảnh. Amazon Rekognition: Thị giác máy tính, nhận diện vật thể, khuôn mặt trong ảnh/video. Amazon Polly: Giọng đọc nhân tạo tự nhiên (Text-to-Speech). Amazon Bedrock: Cổng kết nối đến các mô hình ngôn ngữ lớn (LLMs) hàng đầu hiện nay. Lợi ích: Tốc độ đưa sản phẩm ra thị trường (Time-to-market) cực nhanh, không tốn công sức xây dựng mô hình từ số 0.\n2. ML Services (Tầng Bán Quản Lý)\nCông cụ đắc lực cho Data Scientist \u0026amp; ML Engineer cần môi trường chuyên nghiệp để tự xây dựng mô hình.\nAmazon SageMaker là trái tim của tầng này, cung cấp một nền tảng thống nhất để quản lý vòng đời của mô hình ML (ML Ops).\nCác module quan trọng:\nData Wrangler: Giảm thiểu thời gian chuẩn bị và làm sạch dữ liệu (vốn chiếm 80% thời gian dự án). Feature Store: Kho lưu trữ các đặc trưng dữ liệu để tái sử dụng, tránh lãng phí tài nguyên tính toán. AutoML (SageMaker Autopilot): Tự động thử nghiệm nhiều thuật toán để tìm ra mô hình tốt nhất mà không cần can thiệp thủ công. Model Registry \u0026amp; Monitoring: Quản lý phiên bản mô hình và giám sát độ chính xác của mô hình theo thời gian thực (tránh hiện tượng model drift). Lợi ích: Cân bằng hoàn hảo giữa tính tiện lợi và khả năng tùy biến sâu vào quy trình huấn luyện.\n3. AI Infrastructure (Tầng Hạ Tầng Tự Quản Lý)\nDành cho các chuyên gia nghiên cứu (Researchers) cần can thiệp sâu vào phần cứng và tối ưu hóa ở mức thấp nhất.\nCung cấp \u0026ldquo;gạch nền\u0026rdquo; để tự xây dựng hệ thống AI tùy chỉnh:\nAmazon EC2 P5/G6/Inferentia: Các máy ảo gắn chip chuyên dụng (GPU/ASIC) cho hiệu suất tính toán cực cao. Amazon EKS / ECS: Quản lý container cho các ứng dụng ML quy mô lớn. AWS Lambda: Chạy code suy luận (inference) dạng serverless, tiết kiệm chi phí cho các tác vụ nhỏ. Amazon S3 / EFS: Hệ thống lưu trữ \u0026ldquo;hồ dữ liệu\u0026rdquo; (Data Lake) khổng lồ. Lợi ích: Không bị giới hạn bởi khuôn mẫu, tối ưu hóa chi phí triệt để cho các hệ thống siêu lớn, nhưng đòi hỏi kỹ năng DevOps cao.\nCác Dịch Vụ AI Phổ Biến Hỗ Trợ Sinh Viên \u0026amp; Nhà Nghiên Cứu 1. Amazon SageMaker\nLà một IDE (Môi trường phát triển tích hợp) dành riêng cho ML trên mây:\nTích hợp mọi công đoạn từ xử lý dữ liệu thô đến tinh chỉnh tham số (hyperparameter tuning). Cung cấp khả năng CI/CD cho Machine Learning, giúp tự động hóa quy trình train và deploy. Hỗ trợ Notebooks (Jupyter) quen thuộc với sinh viên. 2. Amazon Comprehend\nMang lại khả năng \u0026ldquo;đọc hiểu\u0026rdquo; cho ứng dụng:\nPhân tích cảm xúc: Biết khách hàng đang vui, giận hay hài lòng qua email/comment. Nhận dạng thực thể: Tự động phát hiện tên người, địa điểm, tổ chức trong văn bản. Bảo mật: Tự động tìm và che giấu thông tin cá nhân (PII) trong dữ liệu. 3. Amazon Translate\nDịch thuật chất lượng cao dựa trên Deep Learning (Neural Network). Khả năng tùy chỉnh từ vựng chuyên ngành (ví dụ: dịch đúng các thuật ngữ y khoa hoặc kỹ thuật). Giúp mở rộng phạm vi người dùng cho ứng dụng ra toàn cầu. 4. Amazon Textract\nVượt xa công nghệ OCR truyền thống nhờ khả năng hiểu cấu trúc tài liệu. Giữ nguyên định dạng bảng biểu, form mẫu khi trích xuất, giúp số hóa giấy tờ hành chính nhanh chóng và chính xác. Quy Trình Data Science Tiêu Chuẩn Trên AWS Ingest \u0026amp; Store: Thu thập dữ liệu từ nhiều nguồn vào \u0026ldquo;kho chứa\u0026rdquo; Amazon S3. Prepare: Làm sạch và chuẩn hóa dữ liệu bằng AWS Glue hoặc Lambda. Train \u0026amp; Tune: Sử dụng SageMaker để huấn luyện và tối ưu hóa thuật toán. Deploy: Đóng gói mô hình thành API Endpoint hoặc tích hợp vào ứng dụng. Monitor: Sử dụng CloudWatch để theo dõi sức khỏe hệ thống và chất lượng dự đoán của mô hình. Demo 1: Tối Ưu Hóa Workflow Với Low-Code/No-Code Mục tiêu: Chứng minh rằng rào cản kỹ thuật trong AI đang dần được xóa bỏ nhờ các công cụ trực quan.\nCông cụ: Amazon SageMaker Canvas (Giao diện kéo thả).\nQuy trình thực hiện:\nUpload bộ dữ liệu thô lên S3. Sử dụng giao diện đồ họa để định nghĩa luồng xử lý: Input -\u0026gt; Xử lý thiếu dữ liệu -\u0026gt; Chọn target column -\u0026gt; Train. Hệ thống tự động chạy thử nghiệm và trả về các chỉ số đánh giá (Accuracy, F1-score\u0026hellip;) dưới dạng biểu đồ dễ hiểu. Ý nghĩa: Giúp sinh viên và Business Analyst có thể tạo ra giá trị từ dữ liệu ngay lập tức mà không cần viết hàng ngàn dòng code Python.\nDemo 2: Từ Mô Hình Đến Ứng Dụng Thực Tế (Deployment) Mục tiêu: Minh họa \u0026ldquo;cây cầu\u0026rdquo; nối giữa mô hình toán học và người dùng cuối.\nCông cụ: SageMaker Endpoint kết hợp với API Gateway và Lambda.\nQuy trình thực hiện:\nBiến mô hình đã train thành một HTTP Endpoint (địa chỉ mạng). Thiết lập API Gateway để nhận yêu cầu từ bên ngoài (ví dụ: từ mobile app). Xử lý logic trung gian bằng AWS Lambda (serverless) để gọi model và trả kết quả về cho người dùng. Ý nghĩa: Cho thấy bức tranh toàn cảnh của việc làm sản phẩm AI: Model chỉ là một phần, việc tích hợp và phục vụ (serving) model mới tạo ra sản phẩm hoàn chỉnh.\nBảng So Sánh: Cloud vs. On-premise (Góc nhìn Hiệu Năng \u0026amp; Kinh Tế) Tiêu chí Cloud (AWS) On-premise (Máy chủ riêng) Khả năng mở rộng Vô hạn \u0026amp; Tức thì: Tự động scale theo lượng traffic thực tế. Cứng nhắc: Bị giới hạn bởi số lượng phần cứng hiện có. Mô hình chi phí OPEX (Chi phí vận hành): Dùng bao nhiêu trả bấy nhiêu, không lãng phí. CAPEX (Chi phí vốn): Phải bỏ tiền cục lớn mua máy móc, rủi ro khấu hao. Tốc độ triển khai Phút: Chỉ cần vài click chuột để có server. Tuần/Tháng: Phải đặt hàng, lắp đặt, cài đặt OS. Bảo trì hệ thống AWS lo: Tập trung hoàn toàn vào phát triển ứng dụng. Tự làm: Tốn nhân sự IT để vận hành điện, lạnh, phần cứng. Phù hợp với sinh viên Cao: Tận dụng gói Free Tier để học tập miễn phí. Thấp: Yêu cầu máy cấu hình cao đắt tiền. Kết Luận Chung AWS cung cấp một hệ sinh thái toàn diện và liền mạch, xóa nhòa khoảng cách giữa việc học thuật và ứng dụng thực tế. Dù là người mới bắt đầu hay doanh nghiệp lớn, AWS đều có bộ công cụ (Layer) phù hợp để giải quyết bài toán dữ liệu. Cảm Nhận Cá Nhân Sau Sự Kiện Buổi workshop “AI Services on AWS for Data Science” không chỉ cung cấp kiến thức lý thuyết mà còn mở ra tư duy mới về cách tiếp cận công nghệ, giúp tôi định hình rõ hơn con đường từ nghiên cứu dữ liệu đến xây dựng sản phẩm.\nMở rộng tư duy nhờ các chuyên gia Hiểu rõ lý do tại sao thế giới đang dịch chuyển lên Cloud: Đó là sự giải phóng khỏi gánh nặng hạ tầng để tập trung vào giá trị cốt lõi là dữ liệu. Nắm bắt được bức tranh tổng thể về 3 tầng AI, từ đó biết cách lựa chọn dịch vụ phù hợp cho từng giai đoạn của dự án cá nhân. Trực quan hóa kiến thức qua Demo Demo 1 (Canvas): Ấn tượng với khả năng \u0026ldquo;bình dân hóa\u0026rdquo; AI. Việc train model giờ đây trực quan như lắp ghép lego, giúp kiểm chứng ý tưởng cực nhanh. Demo 2 (Deployment): Đây là mảnh ghép tôi thường thiếu sót. Hiểu được cách tạo ra một API để người khác có thể dùng model của mình là bước ngoặt từ việc \u0026ldquo;làm bài tập\u0026rdquo; sang \u0026ldquo;làm sản phẩm\u0026rdquo;. Tiếp cận công nghệ tiên tiến Các dịch vụ như Comprehend hay Textract cho thấy sức mạnh của Pre-trained models. Chúng giúp giải quyết các bài toán khó (như đọc hóa đơn, phân tích sentiment) chỉ trong tích tắc mà không cần tự build model phức tạp. Giá trị kết nối Cơ hội thảo luận về bài toán chi phí (Cost optimization) là rất thực tế, giúp sinh viên như tôi biết cách dùng Cloud mà không \u0026ldquo;cháy túi\u0026rdquo;. Mạng lưới networking với các anh chị trong ngành giúp tôi có thêm động lực và định hướng nghề nghiệp rõ ràng hơn. Bài học cốt lõi Cloud First: Tư duy đưa mọi thứ lên mây là xu hướng tất yếu của Data Science hiện đại. Tính thực tiễn: Một mô hình AI chỉ có giá trị khi nó được deploy và giải quyết vấn đề cho người dùng cuối. Hệ sinh thái AWS: Là kho công cụ khổng lồ mà tôi cần tiếp tục khai phá để nâng cao năng lực bản thân. Một số hình ảnh ghi lại tại sự kiện Hình ảnh sự truyền đạt kiến thức từ 2 anh đến từ AWS\nHình ảnh đội FPTers check-in sau sự kiện\nĐây là khoảnh khắc check-in của toàn bộ các bạn đang thực tập tại AWS sau khi kết thúc workshop.\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":"Mục tiêu tuần 3: Hiểu kiến thức toàn diện về các dịch vụ máy chủ ảo (Compute VM) trên AWS. Tập trung vào dịch vụ cốt lõi là Amazon EC2, bao gồm cách lựa chọn cấu hình (Instance Types), các loại lưu trữ (EBS, Instance Store), và cách tự động hóa (User data, Auto Scaling). Tìm hiểu về các các dịch vụ liên quan như Amazon Lightsail (dịch vụ chi phí thấp), các giải pháp lưu trữ file chia sẻ (EFS cho Linux và FSx cho Windows/Linux), và dịch vụ di dời ứng dụng AWS MGN để chuyển máy chủ lên AWS hoặc xây dựng Disaster Recovery. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 Amazon EC2:\n- Kiến trúc, Instance Types, AMI, Key Pair.\n- Lưu trữ: Phân biệt EBS và Instance Store.\n- Cấu hình: User Data, Meta Data.\n- Quản lý: Auto Scaling và các tùy chọn giá (Pricing Options). 22/09/2025 22/09/2025 Module 03 3 Amazon Lightsail: VPS chi phí thấp \u0026amp; kết nối VPC Peering.\nAmazon EFS/FSx:\n- EFS: File storage cho Linux (NFS).\n- FSx: File storage cho Windows/Linux (SMB) \u0026amp; tính năng deduplication.\nAWS MGN: Di dời máy chủ (Migration) và thiết lập Disaster Recovery (DR). 23/09/2025 23/09/2025 Module 03 4 Lab 000004: Thao tác EC2 cơ bản (Tạo máy, Snapshot, Cài ứng dụng).\nLab 000027: Quản lý tài nguyên bằng Tag và Resource Group. 24/09/2025 24/09/2025 Module 03 5 Lab 000008: Giám sát tài nguyên với Amazon CloudWatch (Agent, Dashboard).\nLab 000006: Triển khai Auto Scaling Group (Launch Template, Target Group, Load Balancer). 25/09/2025 25/09/2025 Module 03 6 Lab 000045: Amazon Lightsail (Load Balancer, RDS, Migrating to EC2).\nNghiên cứu thêm: Microsoft Workloads on AWS, quản trị hệ điều hành Linux/Windows. 26/09/2025 26/09/2025 Module 03 Research Link Kết quả đạt được tuần 3: Dịch vụ EC2: Hiểu rõ EC2 là dịch vụ máy chủ ảo cốt lõi của AWS. Kĩ thuật cấu hình EC2: Biết cách lựa chọn Instance Type (cấu hình CPU, RAM, Network) và sử dụng AMI để khởi tạo hệ điều hành cho máy chủ. Kĩ thuật bảo mật EC2: Nắm được cách dùng Key Pair (public/private key) để mã hóa thông tin đăng nhập, thay vì dùng mật khẩu. Dịch vụ lưu trữ (Storage): Phân biệt rõ ràng 2 loại lưu trữ đĩa chính cho EC2: EBS (Elastic Block Store): Là ổ đĩa mạng, hoạt động độc lập, dữ liệu được replicate x3 trong 1 AZ (độ sẵn sàng 99.999%), có thể backup bằng snapshot. Instance Store: Là ổ đĩa vật lý (NVME) tốc độ cực cao, nhưng dữ liệu là tạm thời (sẽ bị xóa khi stop EC2), thường dùng cho cache/buffer hoặc swap. Kĩ thuật tự động hóa (Automation): Biết cách dùng User Data để chạy script 1 lần khi máy chủ khởi động (ví dụ: cài đặt web server). Hiểu Meta Data là gì và cách dùng nó để lấy thông tin (IP, hostname) của máy chủ từ bên trong chính nó, phục vụ cho các script tự động hóa. Kĩ thuật co giãn (Scaling): Nắm vững khái niệm EC2 Auto Scaling để tự động tăng (scale-out) hoặc giảm (scale-in) số lượng máy chủ theo tải (ví dụ: khi ActiveConnectionCount cao hoặc thấp). Kĩ thuật tối ưu chi phí (Pricing): Nhận biết 4 mô hình giá EC2: On-demand (theo giờ/giây, đắt nhất), Reserved Instance (cam kết 1-3 năm), Saving Plans (cam kết 1-3 năm, linh hoạt hơn), và Spot Instance (giá rẻ, tận dụng tài nguyên dư nhưng có thể bị đòi lại). Dịch vụ Lightsail: Hiểu Amazon Lightsail là dịch vụ VM chi phí thấp, đơn giản hóa, phù hợp cho workload nhẹ, và biết cách peering nó với VPC. Dịch vụ lưu trữ file (File Storage): Phân biệt 2 dịch vụ lưu trữ file chia sẻ cho nhiều máy chủ: EFS (Elastic File System): Dùng cho Linux (giao thức NFSv4), tính phí theo dung lượng sử dụng. FSx: Dùng cho Windows/Linux (giao thức SMB), hỗ trợ tính năng deduplication để giảm chi phí. Dịch vụ di dời (Migration): Hiểu AWS MGN là dịch vụ để di dời máy chủ từ on-premise lên AWS hoặc dùng để xây dựng hệ thống Disaster Recovery (DR) với chi phí thấp thông qua staging area. Thực hành: Nắm được các bước thực hành cơ bản với EC2 (tạo, snapshot), triển khai một cụm Auto Scaling Group hoàn chỉnh (với Load Balancer), và làm quen với Lightsail. "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":"Các blogs mà tôi đã dịch:\nBlog 1 - Các tính năng mới trong Amazon Sagemaker AI tiếp tục thay cách các tổ chức phát triển mô hình AI Blog này giới thiệu các tính năng mới nhất trong Amazon SageMaker AI nhằm tăng tốc quy trình phát triển và triển khai mô hình AI sinh quy mô lớn. Bạn sẽ tìm hiểu cách Amazon SageMaker HyperPod tối ưu hóa hiệu suất thông qua khả năng quan sát giúp giảm thời gian khắc phục sự cố từ ngày xuống phút, cũng như tính năng triển khai nhanh các mô hình open-weights từ JumpStart để phục vụ suy luận. Bài viết cũng hướng dẫn cách kết nối liền mạch môi trường phát triển cục bộ (như Visual Studio Code) với hạ tầng đám mây mạnh mẽ, và cách sử dụng MLflow 3.0 được quản lý toàn phần để theo dõi thí nghiệm và đánh giá hiệu năng ứng dụng AI sinh hiệu quả hơn.\nBlog 2 - Nâng cao độ chính xác dự báo thời tiết bằng các phiên bản đồ họa chuyên sâu của Amazon AppStream 2.0 Blog này giới thiệu giải pháp nâng cao khả năng dự báo thời tiết bằng cách triển khai ứng dụng Common AWIPS Visualization Environment (CAVE) trên Amazon AppStream 2.0. Bạn sẽ tìm hiểu cách dịch vụ này cho phép các nhà khí tượng học truy cập các công cụ đồ họa chuyên sâu từ bất kỳ thiết bị nào, giúp loại bỏ sự phụ thuộc vào phần cứng đắt tiền và tối ưu hóa chi phí thông qua mô hình trả phí theo mức sử dụng GPU. Bài viết cũng hướng dẫn các bước kỹ thuật từ việc tạo image Linux, tối ưu hóa manifest ứng dụng, đến cấu hình fleet và xác thực người dùng, giúp đảm bảo hiệu suất cao và bảo mật dữ liệu cho các nhiệm vụ dự báo quan trọng.\nBlog 3 - Hồ dữ liệu địa không gian với Amazon Redshift Blog này giới thiệu giải pháp xây dựng hồ dữ liệu địa không gian bảo mật bằng cách tận dụng khả năng của Amazon Redshift và AWS Lake Formation. Bạn sẽ tìm hiểu cách lưu trữ dữ liệu bản đồ quy mô lớn trên Amazon S3 và thực hiện truy vấn trực tiếp thông qua Redshift Serverless mà không cần di chuyển dữ liệu, giúp tối ưu hóa chi phí lưu trữ và hiệu suất phân tích. Bài viết hướng dẫn chi tiết quy trình kỹ thuật từ việc triển khai hạ tầng, sử dụng AWS Glue để quản lý metadata, đến việc áp dụng các thẻ bảo mật trong Lake Formation để kiểm soát quyền truy cập cấp cột, đảm bảo thông tin nhạy cảm (như dữ liệu y tế PHI) được bảo vệ tuyệt đối. Cuối cùng, bạn sẽ được hướng dẫn cách tạo các view địa lý trong Redshift và kết nối phần mềm ArcGIS Pro để trực quan hóa dữ liệu lên bản đồ phục vụ cho các nhu cầu phân tích thực tế.\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.3-knowledge-base/","title":"Tạo và Cấu hình Knowledge Base","tags":[],"description":"","content":"Mục tiêu Sau khi hoàn thành việc chuẩn bị môi trường và dữ liệu, bước tiếp theo là thiết lập thành phần cốt lõi của kiến trúc RAG. Trong phần này, chúng ta sẽ khởi tạo Knowledge Base, đóng vai trò là cơ chế trung gian thông minh kết nối các nguồn dữ liệu phi cấu trúc với khả năng suy luận của các foundation models.\nChúng ta sẽ thực hiện 3 mục tiêu kỹ thuật chính:\nThiết lập Pipeline Tự động: Cấu hình Knowledge Base để tự động hóa toàn bộ quy trình xử lý dữ liệu RAG (bao gồm trích xuất, phân đoạn văn bản và tạo vector) nhằm loại bỏ các tác vụ xử lý thủ công. Khởi tạo Vector Store: Triển khai một collection trên Amazon OpenSearch Serverless để lưu trữ các vector ngữ nghĩa, phục vụ việc truy xuất thông tin chính xác và hiệu quả. Đồng bộ hóa Dữ liệu (Data Ingestion): Thực hiện quy trình nhập dữ liệu ban đầu, chuyển đổi các tài liệu tĩnh từ S3 thành các vector có thể tìm kiếm trong hệ thống. Các Thành phần Chính Trong quá trình cấu hình này, chúng ta sẽ tương tác và kết nối các dịch vụ sau:\nKnowledge Bases for Amazon Bedrock: Dịch vụ được quản lý đóng vai trò là bộ điều phối luồng dữ liệu, kết nối các nguồn thông tin và thực thi các truy vấn ngữ nghĩa. Amazon Titan Embeddings G1 - Text v2: Mô hình chuyên dụng để chuyển đổi dữ liệu văn bản thành các vector số (Embeddings) với độ chính xác cao và hỗ trợ đa ngôn ngữ. Amazon OpenSearch Serverless: Cơ sở dữ liệu vector được quản lý hoàn toàn, chịu trách nhiệm lưu trữ và thực thi các thuật toán tìm kiếm tương đồng (k-NN). Các Bước Thực hiện Khởi tạo Knowledge Base Kiểm tra Vector Store và Đồng bộ Dữ liệu "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/4-eventparticipated/4.4-event4/","title":"Event 4","tags":[],"description":"","content":"AWS Cloud Mastery Series #1: GENERATIVE AI, RAG \u0026amp; AWS AGENTIC AI Mục Đích Của Sự Kiện Làm chủ kỹ thuật Prompt Engineering để tối ưu hóa đầu vào, giúp mô hình hiểu và thực hiện chính xác ý định của người dùng. Tận dụng sức mạnh của các Pretrained AI Services trên AWS để tích hợp tính năng thông minh nhanh chóng mà không cần xây dựng mô hình từ đầu. Hiểu sâu về kiến trúc RAG (Retrieval-Augmented Generation) để giải quyết vấn đề ảo giác và cập nhật dữ liệu riêng cho AI. Nắm bắt làn sóng công nghệ tiếp theo: Agentic AI và cách sử dụng Amazon Bedrock AgentCore để chuyển đổi AI Agent từ bản thử nghiệm (POC) sang môi trường thực tế (Production). Tiếp cận Pipecat Framework để xây dựng các trợ lý ảo giao tiếp bằng giọng nói với độ trễ thấp (Real-time). Danh Sách Diễn Giả Anh Lâm Tuấn Kiệt - Sr DevOps Engineer (FPT Software) - Chuyên gia về vận hành và triển khai hệ thống. Bạn Danh Hoàng Hiếu Nghị - AI Engineer (Renova Cloud) - Chuyên gia về các giải pháp trí tuệ nhân tạo. Anh Đinh Lê Hoàng Anh - Cloud Engineer Trainee (First Cloud AI Journey) - Chia sẻ góc nhìn từ người mới bắt đầu hành trình Cloud AI. Nội Dung Nổi Bật 1. Prompt Engineering \u0026amp; Foundation Models (Nền Tảng Cốt Lõi) Trước khi đi sâu vào các hệ thống phức tạp, sự kiện khẳng định rằng \u0026ldquo;chất lượng đầu vào quyết định chất lượng đầu ra\u0026rdquo;. Việc giao tiếp hiệu quả với các mô hình nền tảng (Foundation Models) trên Amazon Bedrock là bước đầu tiên:\nZero-shot / Few-shot Prompting: Kỹ thuật điều hướng mô hình bằng cách ra lệnh trực tiếp hoặc cung cấp một vài ví dụ mẫu (context) để AI học theo mẫu đó và trả về kết quả mong muốn. Chain of Thought (CoT): Một kỹ thuật nâng cao giúp AI xử lý các tác vụ suy luận phức tạp bằng cách yêu cầu nó \u0026ldquo;giải trình từng bước\u0026rdquo;. Điều này giúp giảm sai sót logic trong câu trả lời. 2. Các Dịch Vụ AI Được Huấn Luyện Trước (AWS AI Services) Đây là tầng ứng dụng giúp các lập trình viên không chuyên về Machine Learning vẫn có thể tích hợp AI vào sản phẩm thông qua API:\nThị giác máy tính: Amazon Rekognition giúp phân tích hình ảnh/video, nhận diện vật thể và kiểm duyệt nội dung. Xử lý ngôn ngữ tự nhiên: Bộ ba Amazon Translate (dịch thuật), Comprehend (phân tích cảm xúc/ngữ nghĩa), và Textract (OCR thông minh - trích xuất văn bản từ tài liệu). Xử lý âm thanh: Amazon Polly (chuyển văn bản thành giọng nói tự nhiên) và Transcribe (chuyển giọng nói thành văn bản). 3. RAG - Retrieval Augmented Generation RAG là giải pháp cầu nối giúp AI \u0026ldquo;học\u0026rdquo; được dữ liệu riêng của doanh nghiệp mà không cần huấn luyện lại (fine-tuning), giải quyết vấn đề mô hình bị lỗi thời hoặc \u0026ldquo;bịa\u0026rdquo; thông tin (hallucination):\nEmbeddings (Vector hóa): Sử dụng model như Amazon Titan Text Embeddings V2 để chuyển đổi văn bản thành các vector số học, giúp hệ thống hiểu và tìm kiếm dựa trên ngữ nghĩa (semantic search) thay vì chỉ khớp từ khóa. Knowledge Bases for Amazon Bedrock: Dịch vụ quản lý toàn trình (end-to-end), tự động hóa các khâu phức tạp: Cắt nhỏ tài liệu (Chunking) -\u0026gt; Lưu vào Vector Store -\u0026gt; Truy xuất dữ liệu liên quan (Retrieval) -\u0026gt; Tổng hợp câu trả lời (Generation). 4. Sự Tiến Hóa Lên Agentic AI (Kỷ Nguyên AI Tác Vụ) GenAI đang chuyển dịch từ việc chỉ \u0026ldquo;trả lời câu hỏi\u0026rdquo; sang \u0026ldquo;thực hiện hành động\u0026rdquo;. Sự kiện phân loại rõ lộ trình phát triển:\nGenAI Assistants: Trợ lý ảo thực hiện các tác vụ đơn lẻ, lặp lại dựa trên quy tắc có sẵn. GenAI Agents: AI hướng mục tiêu (Goal-oriented), có khả năng suy luận để chọn công cụ phù hợp nhằm hoàn thành một chuỗi công việc. Agentic AI Systems: Hệ sinh thái đa tác nhân (Multi-agent), hoạt động tự chủ cao (Autonomous), có thể tự phối hợp với nhau dưới sự giám sát tối thiểu của con người. Thách thức \u0026ldquo;Hố sâu ngăn cách\u0026rdquo; (The Prototype to Production Chasm): Tại sao nhiều bản demo Agent rất hay nhưng thất bại khi đưa ra thực tế?\nHiệu năng \u0026amp; Mở rộng: Agent hoạt động chậm khi xử lý luồng suy luận dài. An toàn \u0026amp; Quản trị: Rủi ro khi Agent tự ý thực hiện hành động sai (ví dụ: xóa nhầm database) hoặc truy cập dữ liệu nhạy cảm. Độ phức tạp: Khó khăn trong việc duy trì bộ nhớ ngữ cảnh (Memory) qua các phiên làm việc dài. 5. Amazon Bedrock AgentCore: Giải Pháp Đưa Agent Ra Thị Trường AgentCore được giới thiệu như một nền tảng hạ tầng hoàn chỉnh để giải quyết các bài toán trên, giúp doanh nghiệp an tâm triển khai Agent:\nCác thành phần cốt lõi: Runtime \u0026amp; Memory: Cung cấp môi trường thực thi ổn định và khả năng \u0026ldquo;ghi nhớ\u0026rdquo; dài hạn các tương tác quá khứ. Identity \u0026amp; Gateway: Quản lý định danh chặt chẽ, đảm bảo Agent chỉ thực hiện đúng quyền hạn được cấp. Code Interpreter: Một \u0026ldquo;sandbox\u0026rdquo; an toàn cho phép Agent tự viết và chạy code Python để xử lý tính toán số liệu hoặc vẽ biểu đồ chính xác (thay vì tự đoán số liệu). Observability: Công cụ giám sát giúp con người theo dõi từng bước suy luận (Trace) của Agent để debug và tối ưu. Lợi ích: Giúp Developer tập trung vào logic nghiệp vụ, giảm gánh nặng xây dựng hạ tầng phụ trợ. 6. Pipecat: Framework Cho AI Voice Thời Gian Thực Giới thiệu một Framework mã nguồn mở giúp xây dựng các ứng dụng giao tiếp người-máy tự nhiên (Multimodal):\nĐặc điểm: Tối ưu hóa độ trễ (Latency) cực thấp, yếu tố sống còn trong giao tiếp thoại. Cơ chế Pipeline: WebRTC Input: Nhận luồng âm thanh trực tiếp từ trình duyệt/app. STT (Speech-to-Text): Dịch giọng nói sang văn bản tức thì. LLM Processing: AI suy nghĩ và sinh câu trả lời dưới dạng text. TTS (Text-to-Speech): Chuyển câu trả lời thành giọng nói. Output: Phát lại cho người dùng. Điểm mấu chốt là các bước này diễn ra gần như song song (streaming) để tạo cảm giác hội thoại liền mạch. Trải nghiệm chi tiết trong Event Buổi workshop đã giúp tôi hệ thống hóa lại kiến thức và nhìn thấy bức tranh lớn hơn về tương lai của AI.\n1. Sự chuyển dịch từ \u0026ldquo;Hỏi - Đáp\u0026rdquo; sang \u0026ldquo;Hành động\u0026rdquo; (Agentic AI) Điều làm tôi ấn tượng nhất là tư duy về Agentic AI. Trước đây, tôi chỉ xem AI như một công cụ tra cứu thông minh. Nhưng với AgentCore, AI trở thành một \u0026ldquo;nhân viên kỹ thuật số\u0026rdquo; có khả năng tự lập kế hoạch và sử dụng công cụ (API, Code, Search) để giải quyết vấn đề trọn vẹn. Đây là bước nhảy vọt về giá trị sử dụng.\n2. Giải quyết bài toán \u0026ldquo;Production\u0026rdquo; Phần chia sẻ về \u0026ldquo;Hố sâu ngăn cách\u0026rdquo; rất thực tế. Nó giải thích tại sao nhiều dự án AI chết yểu. Việc AWS cung cấp các lớp bảo mật (Identity) và giám sát (Observability) trong Bedrock Agent là chìa khóa để doanh nghiệp dám tin tưởng giao quyền cho AI tác động vào hệ thống thực.\n3. Tiềm năng của Voice AI với Pipecat Demo về Pipecat cho thấy tương lai của giao tiếp không chạm. Việc kết hợp WebRTC và LLM để tạo ra hội thoại thời gian thực mở ra vô vàn ứng dụng: từ Tổng đài CSKH tự động, Luyện thi IELTS ảo, đến Trợ lý phỏng vấn.\nKết Luận Workshop “Generative AI \u0026amp; Agentic AI on AWS” đã phác thảo rõ lộ trình phát triển năng lực AI:\nHiện tại: Chúng ta dùng RAG và Prompt Engineering để khai thác dữ liệu hiệu quả. Tương lai gần: Chúng ta chuyển sang Agentic AI, nơi các hệ thống tự chủ (Autonomous Agents) sẽ thay con người vận hành các quy trình phức tạp. Công cụ: Với hệ sinh thái toàn diện của AWS (Bedrock, AgentCore) và cộng đồng Open Source (Pipecat, LangChain), rào cản kỹ thuật đã giảm đi đáng kể, nhường chỗ cho sự sáng tạo về giải pháp nghiệp vụ. Một số hình ảnh khi tham gia sự kiện Hình ảnh hơn 400 bạn tham dự buổi Event AWS Cloud Mastery Series #1\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4","tags":[],"description":"","content":"Mục tiêu tuần 4: Tìm hiểu kiến thức toàn diện về các dịch vụ lưu trữ đa dạng trên AWS. Tập trung sâu vào dịch vụ cốt lõi là Amazon S3 (Simple Storage Service), một dịch vụ lưu trữ đối tượng, bao gồm các đặc tính (như độ bền 11 số 9, nhân bản 3 AZ), các lớp lưu trữ (Storage Classes). Học về các tính năng quan trọng như quản lý vòng đời (Lifecycle Management), Versioning (lập phiên bản), và Static Website Hosting. Các giải pháp di dời dữ liệu quy mô lớn (dòng Snow Family), giải pháp lưu trữ hybrid kết nối on-premise với cloud (Storage Gateway), dịch vụ quản lý sao lưu tập trung (AWS Backup), và các khái niệm, chiến lược cơ bản về Disaster Recovery (DR). Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 Amazon S3:\n- Kiến trúc (Object storage, 3 AZ, durability).\n- Các lớp lưu trữ (Storage Classes) \u0026amp; Quản lý vòng đời (Lifecycle).\n- Tính năng: Static Website, CORS, Versioning.\n- Bảo mật: Bucket Policy, ACL, S3 Endpoint.\n- Tối ưu hiệu năng \u0026amp; S3 Glacier. 29/09/2025 29/09/2025 Module 04 3 Snow Family: Di chuyển dữ liệu quy mô lớn (Snowball, Snowmobile) \u0026amp; xử lý tại biên (Edge).\nAWS Storage Gateway: Giải pháp lưu trữ Hybrid (File, Volume, Tape Gateway) kết nối On-premise với AWS. 30/09/2025 30/09/2025 Module 04 4 Disaster Recovery (DR): Các chỉ số RTO/RPO và 4 chiến lược DR trên AWS.\nAWS Backup: Quản lý sao lưu tập trung, lập lịch và chính sách lưu giữ cho nhiều dịch vụ AWS. 01/10/2025 01/10/2025 Module 04 5 Lab 000057: S3 cơ bản (Bucket, Upload, Static Website).\nLab 000013: Cấu hình AWS Backup Plan \u0026amp; Notification.\nLab 000014: VM Import/Export (Chuyển máy ảo lên AWS và ngược lại). 02/10/2025 02/10/2025 Module 04 6 Lab 000024: Cấu hình Storage Gateway \u0026amp; File Sharing.\nLab 000025: Triển khai Amazon FSx với Managed AD.\nNghiên cứu thêm: AWS Skill Builder (Block \u0026amp; Object Storage Plans). 03/10/2025 03/10/2025 Module 04 Kết quả đạt được tuần 4: Dịch vụ S3 (Cơ bản): Hiểu rõ Amazon S3 là dịch vụ lưu trữ đối tượng (object storage), không phải lưu trữ khối, hoạt động theo mô hình WORM (Ghi 1 lần, đọc nhiều lần). Bài học về Độ bền (Durability): Nắm được S3 được thiết kế cho độ bền 11 số 9 (99.999999999%) bằng cách tự động nhân bản dữ liệu trên 3 Availability Zone (AZ). Kĩ thuật Tối ưu chi phí S3: Phân biệt được các lớp lưu trữ (Storage Classes) như S3 Standard (truy cập thường xuyên), S3 Standard IA (không thường xuyên), và S3 Glacier (lưu trữ dài hạn, chi phí thấp, phải retrieve). Kĩ thuật Tự động hóa S3: Biết cách dùng Object Life Cycle Management để tự động chuyển dữ liệu xuống các lớp rẻ hơn (ví dụ: từ Standard sang Glacier) theo thời gian. Hiểu về Trigger Event (ví dụ: kích hoạt serverless function khi upload file). Kĩ thuật Bảo mật S3: Phân biệt hai cơ chế kiểm soát truy cập: S3 ACL (cơ chế cũ) và S3 Bucket Policy (dễ dàng xác định quyền truy cập hơn). Bài học về Bảo vệ Dữ liệu (S3): Hiểu rõ tính năng Versioning (lập phiên bản) cho phép khôi phục lại các phiên bản cũ của file, giúp chống xóa nhầm hoặc tấn công ransomware. Kĩ thuật Mạng S3: Nắm được cách dùng S3 Endpoint để truy cập S3 từ trong VPC qua mạng riêng của AWS mà không cần Internet. Biết cách host Static Website trên S3 và cấu hình CORS. Dịch vụ Di dời Dữ liệu (Migration): Nhận biết dòng Snow Family (Snowball, Snowmobile) là giải pháp di dời dữ liệu vật lý quy mô lớn (Petabyte, Exabyte) từ on-premise. Dịch vụ Lưu trữ Hybrid: Hiểu Storage Gateway là giải pháp lưu trữ lai, cho phép các ứng dụng on-premise sử dụng các giao thức (NFS, SMB, iSCSI) để lưu trữ dữ liệu lên S3/Glacier. Bài học về Disaster Recovery (DR): Nắm được 2 khái niệm cơ bản để thiết kế DR là RTO (thời gian phục hồi) và RPO (lượng dữ liệu chấp nhận mất). Dịch vụ Sao lưu (Backup): Biết AWS Backup là dịch vụ quản lý tập trung, giúp tự động hóa việc sao lưu (schedule, retention) cho nhiều tài nguyên AWS (EBS, RDS, EFS\u0026hellip;). Thực hành: Nắm được các bước thực hành tạo S3 bucket, host website tĩnh, và cấu hình AWS Backup. "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":"Trong suốt kỳ thực tập, em đã có cơ hội tham dự 6 sự kiện chuyên ngành khác nhau. Mỗi sự kiện không chỉ là một cơ hội quý báu để trau dồi những kiến thức mới mẻ và thiết thực, mà còn để lại những dấu ấn khó quên với những phần quà ý nghĩa cùng nhiều khoảnh khắc trải nghiệm tuyệt vời.\nEvent 1 Tên sự kiện: Vietnam Cloud Day 2025 - Ho Chi Minh City Connect Edition for Builders\nThời gian: 09:00 ngày 18/09/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: Vòng đời phát triển theo hướng AI: Tái định hình kỹ thuật phần mềm\nThời gian: 14:00 ngày 03/10/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 3 Tên sự kiện: WORKSHOP KHOA HỌC DỮ LIỆU TRÊN AWS\nThời gian: 09:30 ngày 16/10/2025\nĐịa điểm: Đại học FPT, Đường D1, Khu Công nghệ cao, Phường Tăng Nhơn Phú, TP. Hồ Chí Minh.\nVai trò trong sự kiện: Người tham dự\nEvent 4 Tên sự kiện: AWS Cloud Mastery Series #1\nThời gian: 08:30 ngày 15/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 5 Tên sự kiện: AWS Cloud Mastery Series #2\nThời gian: 08:30 ngày 17/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 6 Tên sự kiện: AWS Cloud Mastery Series #3\nThời gian: 08:30 ngày 29/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.4-test-chatbox/","title":"Kiểm thử Chatbot (RAG)","tags":[],"description":"","content":"Mục tiêu Sau khi đã nhập dữ liệu thành công vào Vector Store, đã đến lúc xác minh kết quả. Trong phần này, bạn sẽ đóng vai trò là người dùng cuối, đặt câu hỏi cho Chatbot trực tiếp trong giao diện AWS Console để quan sát cách hệ thống RAG hoạt động.\nChúng ta sẽ tập trung vào 2 yếu tố:\nĐộ chính xác: AI có trả lời đúng dựa trên tài liệu không? Tính minh bạch: AI có thể trích dẫn nguồn (Citation) của thông tin không? Các Bước Thực hiện Bước 1: Cấu hình cửa sổ kiểm thử\nĐể bắt đầu trò chuyện, chúng ta cần chọn một Foundation Model sẽ đóng vai trò là \u0026ldquo;người trả lời\u0026rdquo;.\nTrong giao diện chi tiết Knowledge Base của bạn, hãy xem bảng điều khiển bên phải có tiêu đề Test knowledge base. Nhấp vào nút Select model.\nTrong bảng điều khiển lựa chọn xuất hiện: Category: Chọn Anthropic. Model: Chọn Claude 3 Sonnet (hoặc Claude 3.5 Sonnet / Haiku tùy thuộc vào model bạn đã kích hoạt). Throughput: Giữ nguyên On-demand. Nhấp Apply. Bước 2: Tiến hành hội thoại (Chat)\nBây giờ, hãy thử đặt một câu hỏi liên quan đến nội dung tài liệu bạn đã tải lên.\nTrong ô nhập liệu (Message input), gõ câu hỏi của bạn. Ví dụ: Nếu bạn đã tải lên tài liệu \u0026ldquo;Tổng quan về AWS\u0026rdquo;, hãy hỏi: \u0026ldquo;Bạn có thể giải thích cho tôi EC2 là gì không?\u0026rdquo;. Nhấp Run. Quan sát kết quả: AI sẽ suy nghĩ trong vài giây (truy vấn Vector Store). Sau đó, nó sẽ trả lời bằng ngôn ngữ tự nhiên, tóm tắt thông tin tìm được. Bước 3: Xác minh nguồn dữ liệu\nĐây là tính năng quan trọng nhất của RAG giúp phân biệt với ChatGPT thông thường: khả năng chứng minh nguồn thông tin.\nTrong câu trả lời của AI, hãy chú ý đến các số nhỏ (chú thích) hoặc văn bản Show source details. Nhấp vào các số đó hoặc nút chi tiết. Một cửa sổ Source details sẽ xuất hiện, hiển thị: Source chunk: Đoạn văn bản gốc chính xác mà AI tìm thấy trong tài liệu. Score: Điểm tương đồng (mức độ liên quan). S3 Location: Đường dẫn đến file gốc. Việc nhìn thấy đoạn văn bản gốc này chứng minh rằng AI không \u0026ldquo;ảo tưởng\u0026rdquo; mà đang thực sự đọc tài liệu của bạn.\nBước 4: Kiểm thử với câu hỏi không liên quan (Tùy chọn)\nĐể xem hệ thống phản ứng như thế nào khi không tìm thấy thông tin.\nĐặt một câu hỏi hoàn toàn không liên quan đến tài liệu. Ví dụ: \u0026ldquo;Hãy giải thích cho tôi một số kiến thức về tài chính cá nhân?\u0026rdquo; (Trong khi tài liệu của bạn là về Điện toán đám mây). Kết quả mong đợi: AI có thể trả lời dựa trên kiến thức tổng quát của nó (nếu không bị hạn chế). HOẶC AI sẽ trả lời \u0026ldquo;Xin lỗi, tôi không thể trả lời câu hỏi của bạn dựa trên dữ liệu truy xuất được\u0026rdquo; - Đây là hành vi lý tưởng cho một ứng dụng RAG doanh nghiệp. "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/4-eventparticipated/4.5-event5/","title":"Event 5","tags":[],"description":"","content":"AWS Cloud Mastery Series #2: Từ DevOps, IaC đến Container \u0026amp; Observability Mục Đích Của Sự Kiện Tái định hình tư duy (Mindset Transformation): Hiểu sâu sắc về Vòng đời Giá trị (Value Cycle) và cách văn hóa DevOps giúp doanh nghiệp cân bằng giữa tốc độ phát triển và sự ổn định của hệ thống. Cách mạng hóa hạ tầng (Modern Infrastructure): Chuyển đổi từ phương thức quản trị thủ công rủi ro (ClickOps) sang quản trị bằng mã nguồn (Infrastructure as Code - IaC) với bộ ba công cụ: CloudFormation, Terraform và CDK. Chiến lược Container hóa (Container Strategy): Phân tích kiến trúc và đưa ra quyết định lựa chọn nền tảng điều phối phù hợp nhất với nhu cầu: Từ đơn giản (App Runner), tích hợp sâu (ECS) đến mở rộng linh hoạt (EKS). Giám sát và Thấu hiểu (Deep Observability): Thiết lập hệ thống giám sát chủ động, không chỉ để báo lỗi mà còn để thấu hiểu hành vi hệ thống và tối ưu trải nghiệm người dùng bằng CloudWatch và X-Ray. Danh Sách Diễn Giả Đội ngũ chuyên gia AWS \u0026amp; Cloud Engineers: Mang đến góc nhìn kiến trúc tổng thể, chiến lược Platform Engineering và các bài demo thực chiến. Anh Trần Vĩ: FCJer 2024 - Chia sẻ kinh nghiệm thực tế từ cộng đồng. Anh Long Quy Nghiêm: FCJer 2024 - Chia sẻ góc nhìn từ người mới tiếp cận và phát triển kỹ năng Cloud. Nội Dung Chi Tiết 1. DevOps Mindset \u0026amp; CI/CD Pipeline (Nền Tảng Tư Duy) Sự kiện nhấn mạnh rằng DevOps không phải là một chức danh hay công cụ, mà là triết lý tập trung vào việc tối ưu hóa dòng chảy giá trị từ ý tưởng đến người dùng cuối.\nThe Value Cycle (Vòng Đời Giá Trị):\nLà một chu trình khép kín gồm 5 giai đoạn: Insights \u0026amp; Analysis (Phân tích nhu cầu) -\u0026gt; Portfolio \u0026amp; Backlog (Lập kế hoạch) -\u0026gt; Continuous Integration (Tích hợp) -\u0026gt; Continuous Testing (Kiểm thử) -\u0026gt; Continuous Delivery (Chuyển giao). Mục tiêu cốt lõi: Giải quyết bài toán kinh điển \u0026ldquo;Speed vs. Stability\u0026rdquo;. DevOps chứng minh rằng chúng ta có thể tăng tốc độ ra mắt tính năng mới (Speed) mà không cần đánh đổi sự an toàn của hệ thống (Stability) nhờ vào tự động hóa. Định nghĩa lại các khái niệm CI/CD:\nContinuous Integration (CI): Là văn hóa cam kết code thường xuyên (hàng ngày). Mọi thay đổi code đều kích hoạt quy trình Build và Test tự động nhằm phát hiện lỗi ngay lập tức (Fail fast), tránh tích tụ nợ kỹ thuật. Continuous Delivery (Chuyển giao liên tục): Code sau khi qua CI sẽ tự động được deploy lên môi trường Staging. Tuy nhiên, bước deploy ra Production là một quyết định kinh doanh, cần một cái \u0026ldquo;gật đầu\u0026rdquo; xác nhận từ con người (Manual Approval). Continuous Deployment (Triển khai liên tục): Mức độ tự động hóa cao nhất. Nếu code vượt qua mọi bài test, nó sẽ đi thẳng ra Production mà không có bất kỳ sự can thiệp nào của con người. Chiến lược Pipeline hiệu quả:\nCentralized CI: Đội ngũ Platform xây dựng các pipeline chuẩn, đảm bảo tính bảo mật và tuân thủ (Compliance), nhưng trao quyền cho Developer tự sử dụng (Self-service) để không tạo ra nút thắt cổ chai. Artifact Management (Quản lý thành phẩm): Tuân thủ nguyên tắc bất biến \u0026ldquo;Build Once, Deploy Anywhere\u0026rdquo;. Mã nguồn chỉ được đóng gói một lần duy nhất thành Binary/Docker Image (Artifact). Các môi trường Test, Staging hay Prod đều dùng chung Artifact này để đảm bảo những gì đã test chính là những gì sẽ chạy thật. Cơ chế phản hồi nhanh (Fail Fast): Pipeline phải được thiết kế để dừng ngay lập tức khi có vấn đề (Lỗi biên dịch, Code xấu, Lỗ hổng bảo mật, Test chậm). Thà dừng quy trình sớm còn hơn để lỗi lọt xuống các bước sau tốn kém hơn. Đo lường hiệu quả (Metrics):\nSử dụng Heatmap để trực quan hóa hiệu suất của toàn bộ tổ chức. Tập trung vào 4 chỉ số vàng (DORA Metrics): Tần suất triển khai, Thời gian thay đổi (Lead time), Tỷ lệ lỗi khi thay đổi (Change Failure Rate), và Thời gian khôi phục dịch vụ (MTTR). 2. Infrastructure as Code (IaC) - Từ ClickOps Đến Code Phần này phân tích sự dịch chuyển bắt buộc từ quản trị thủ công sang tự động hóa hạ tầng.\nVấn đề của \u0026ldquo;ClickOps\u0026rdquo;: Việc click chuột trên AWS Console tuy trực quan nhưng tiềm ẩn rủi ro lớn: Sai sót do con người (quên cấu hình), không thể tái tạo lại môi trường y hệt (Inconsistent), và cực kỳ khó khăn khi cần mở rộng quy mô. Giải pháp IaC: Biến hạ tầng thành Code để hưởng các lợi ích của phát triển phần mềm: Có Version Control (Git), có Code Review, có thể Test và Tái sử dụng. Phân tích chi tiết 3 công cụ IaC hàng đầu:\n1. AWS CloudFormation (Native Tool):\nCông cụ \u0026ldquo;chính chủ\u0026rdquo; của AWS, sử dụng YAML/JSON để khai báo trạng thái mong muốn (Declarative). Template Anatomy: Cấu trúc gồm Parameters (Đầu vào linh hoạt), Mappings (Ánh xạ giá trị theo vùng/môi trường), và Resources (Tài nguyên AWS cụ thể). Stack Management: Quản lý tài nguyên theo nhóm (Stack). Khi xóa Stack, mọi tài nguyên liên quan sẽ được dọn dẹp sạch sẽ, tránh rác tài nguyên. 2. Terraform (Multi-Cloud Powerhouse):\nCông cụ mã nguồn mở, sử dụng ngôn ngữ HCL. Là lựa chọn số 1 cho chiến lược Đa đám mây (Multi-cloud). Quy trình an toàn: Write -\u0026gt; Plan -\u0026gt; Apply. Bước Plan cho phép xem trước các thay đổi sẽ tác động thế nào đến hạ tầng thực tế trước khi áp dụng, giúp tránh các sai lầm tai hại. State File: Là \u0026ldquo;bộ nhớ\u0026rdquo; của Terraform, lưu giữ trạng thái thực của hạ tầng để so sánh và đồng bộ hóa. 3. AWS CDK (Cloud Development Kit):\nTiếp cận hạ tầng bằng ngôn ngữ lập trình hiện đại (Python, TS, Java\u0026hellip;), tận dụng được sức mạnh của vòng lặp, điều kiện, và hướng đối tượng. Sức mạnh của Abstraction (Constructs): L1: Cấu hình thô (tương đương CloudFormation). L2: Các Class có sẵn cấu hình mặc định an toàn (Best practices). L3: Các mẫu thiết kế (Patterns) dựng sẵn cả một hệ thống phức tạp (VPC + Cluster + LB) chỉ với vài dòng code. Drift Detection: Tính năng giúp phát hiện \u0026ldquo;sự trôi dạt\u0026rdquo; cấu hình - tức là sự khác biệt giữa Code (IaC) và thực tế (do ai đó sửa tay). Đây là công cụ quan trọng để duy trì kỷ luật vận hành.\n3. Containerization - Chiến Lược Chạy Ứng Dụng Đi sâu vào các mô hình điều phối (Orchestration) để chọn giải pháp tối ưu:\nKubernetes (K8s):\nHệ thống tiêu chuẩn của thế giới Container. Kiến trúc phức tạp gồm Control Plane (não bộ) và Worker Nodes (cơ bắp). Phù hợp cho các hệ thống cực lớn, cần tùy chỉnh sâu, nhưng đòi hỏi đội ngũ vận hành có kỹ năng cao. So sánh Amazon ECS vs. Amazon EKS:\nAmazon ECS: \u0026ldquo;Đơn giản hóa\u0026rdquo;. Được AWS thiết kế để tích hợp liền mạch với các dịch vụ khác (ALB, IAM). Phù hợp cho team muốn tập trung vào ứng dụng, bớt lo về vận hành cụm cluster. Amazon EKS: \u0026ldquo;Chuẩn mở\u0026rdquo;. Là phiên bản Managed Kubernetes của AWS. Phù hợp cho doanh nghiệp cần hệ sinh thái công cụ của K8s hoặc chạy Hybrid-cloud. Mô hình tính toán (Compute Options):\nEC2 Launch Type: Bạn quản lý máy ảo (Servers). Kiểm soát tối đa nhưng phải lo việc vá lỗi OS, update agent. AWS Fargate (Serverless): Bạn chỉ quản lý Container. AWS lo toàn bộ hạ tầng máy chủ bên dưới. Loại bỏ gánh nặng bảo trì OS. AWS App Runner:\nGiải pháp \u0026ldquo;Zero-ops\u0026rdquo;. Dành cho Developer muốn deploy Web App/API nhanh nhất có thể. Tự động hóa toàn bộ từ Source Code -\u0026gt; Build -\u0026gt; Deploy -\u0026gt; Load Balancer -\u0026gt; HTTPS URL. 4. Observability - Giám Sát \u0026amp; Tối Ưu Hóa Chuyển từ \u0026ldquo;Monitoring\u0026rdquo; (Hệ thống có sống không?) sang \u0026ldquo;Observability\u0026rdquo; (Tại sao hệ thống chạy chậm?).\nAmazon CloudWatch (Trung tâm giám sát):\nMetrics: Các chỉ số đo lường định lượng (CPU cao, RAM đầy). Logs: Nhật ký hoạt động chi tiết. Logs Insights giúp truy vấn và phân tích hàng triệu dòng log trong vài giây. Alarms: Cơ chế phản ứng tự động. Khi chỉ số vượt ngưỡng -\u0026gt; Gửi cảnh báo hoặc Tự động scale hệ thống. AWS X-Ray (Truy vết phân tán):\nGiải quyết bài toán \u0026ldquo;hộp đen\u0026rdquo; trong Microservices. Distributed Tracing: Vẽ lại bản đồ đường đi của một request qua hàng chục service khác nhau. Giúp xác định chính xác service nào đang gây chậm (Latency) hoặc gây lỗi (Error) để xử lý tận gốc. AWS Observability Best Practices:\nTham khảo AWS Observability Recipes để áp dụng các mẫu giám sát chuẩn. Phân biệt rõ vai trò: Logs cho biết chi tiết sự kiện, Traces cho biết ngữ cảnh và luồng đi của sự kiện đó. Trải nghiệm chi tiết trong Event Buổi chuyên đề đã giúp tôi thay đổi hoàn toàn cách nhìn nhận về việc vận hành hệ thống phần mềm:\n1. Sự chuyển dịch từ \u0026ldquo;Ops\u0026rdquo; sang \u0026ldquo;Platform Engineering\u0026rdquo; Tôi nhận ra vai trò của người làm DevOps hiện đại không phải là \u0026ldquo;người trực server\u0026rdquo; hay \u0026ldquo;người deploy thuê\u0026rdquo;. DevOps là người xây dựng nền tảng (Platform Builders). Nhiệm vụ là tạo ra một \u0026ldquo;đường cao tốc\u0026rdquo; (Pipeline \u0026amp; Infrastructure) an toàn và tự động, giúp Developer có thể tự mình đưa code ra thị trường (Self-service) mà không cần chờ đợi, nhưng vẫn đảm bảo các quy tắc an toàn.\n2. Kỷ luật trong vận hành (Operational Discipline) Khái niệm Immutability (Bất biến) trong quản lý Artifact và Drift Detection trong IaC thực sự đắt giá. Trong môi trường doanh nghiệp, \u0026ldquo;chạy được\u0026rdquo; là chưa đủ, mà phải là \u0026ldquo;chạy ổn định và nhất quán\u0026rdquo;. Việc cấm sửa tay (ClickOps) và tuân thủ quy trình \u0026ldquo;Code -\u0026gt; Build -\u0026gt; Deploy\u0026rdquo; là yếu tố sống còn để tránh những lỗi ngớ ngẩn do con người gây ra.\n3. Chiến lược lựa chọn công cụ thông minh Bài học lớn nhất là không có công cụ \u0026ldquo;xịn nhất\u0026rdquo;, chỉ có công cụ \u0026ldquo;phù hợp nhất với ngữ cảnh\u0026rdquo;:\nCần sự ổn định tuyệt đối và hỗ trợ tính năng AWS mới nhất? Chọn CloudFormation. Doanh nghiệp dùng nhiều Cloud (Multicloud)? Chọn Terraform. Team mạnh về lập trình, muốn viết ít code mà được hạ tầng lớn? Chọn AWS CDK. Muốn chạy Web App đơn giản mà không muốn tốn người quản trị K8s? App Runner là chân ái. Kết Luận Chuyên đề \u0026ldquo;DevOps \u0026amp; IaC Mastery\u0026rdquo; đã vẽ nên một lộ trình trưởng thành về công nghệ:\nVề Tư duy: Chuyển từ làm việc cảm tính, thủ công sang tư duy hệ thống, tự động hóa và đo lường bằng dữ liệu. Về Hạ tầng: Kiểm soát hạ tầng bằng Code (IaC) để đạt được sự linh hoạt và khả năng mở rộng vô hạn. Về Vận hành: Kết hợp sức mạnh của Container với khả năng thấu hiểu hệ thống (Observability) để đảm bảo dịch vụ luôn sẵn sàng và tối ưu. Đây chính là nền tảng kiến thức vững chắc để tôi tự tin bước vào xây dựng các hệ thống quy mô lớn trên AWS.\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5: Tìm hiểu kiến thức nền tảng và các dịch vụ cốt lõi về bảo mật trên AWS, xoay quanh triết lý \u0026ldquo;Security is job zero\u0026rdquo;. Bắt đầu với khái niệm cơ bản nhất là Mô hình chia sẻ trách nhiệm (Share Responsibility Model). Tập trung sâu vào việc quản lý định danh và quyền truy cập (Identify and Access Management - IAM), bao gồm các thành phần: User, Group, Policy, và Role. Mở rộng tìm hiểu thêm các dịch vụ quản lý định danh ở quy mô lớn hơn như AWS Organizations (quản lý nhiều tài khoản), AWS Identity Center (SSO) (đăng nhập một lần), và Amazon Cognito (quản lý người dùng cho ứng dụng web/di động). Nắm rõ kiến thức về bảo vệ dữ liệu thông qua mã hóa với AWS KMS và giám sát, kiểm tra tuân thủ với AWS Security Hub. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 Shared Responsibility Model: AWS bảo mật của Cloud, Khách hàng bảo mật trong Cloud.\nIAM:\n- Root Account (Best practices).\n- IAM User, Group, Policy (Identity \u0026amp; Resource-based).\n- IAM Role, Assume Role (AWS STS). 06/10/2025 06/10/2025 Module 05 3 Amazon Cognito: User Pool (Xác thực người dùng cuối) \u0026amp; Identity Pool (Cấp quyền).\nAWS Organizations: Quản lý đa tài khoản, OU, SCP, Consolidated Billing.\nAWS Identity Center (SSO): Quản lý truy cập tập trung, Permission Sets. 07/10/2025 07/10/2025 Module 05 4 AWS KMS: Quản lý khóa mã hóa (CMK, Data Key).\nAWS Security Hub: Kiểm tra bảo mật tự động theo tiêu chuẩn.\nLab 000002: IAM cơ bản \u0026amp; Assume Role.\nLab 000044: IAM Role Condition \u0026amp; Giới hạn quyền (IP, Time). 08/10/2025 08/10/2025 Module 05 5 Lab 000048: IAM Role cho Application (EC2).\nLab 000030: IAM Permission Boundary.\nLab 000027 \u0026amp; 000028: Quản lý Tag, Resource Groups và kiểm soát EC2 qua Tag. 09/10/2025 09/10/2025 Module 05 6 Lab 000018: Cấu hình \u0026amp; đánh giá với AWS Security Hub.\nLab 000012: Thiết lập AWS SSO \u0026amp; Organizations.\nLab 000033: KMS Workshop (Mã hóa, Key Policy).\nNghiên cứu thêm: AWS Security Specialty Guide (SCS-C01). 10/10/2025 10/10/2025 Module 05 Research Link Kết quả đạt được tuần 5: Bài học Nền tảng: Nắm vững Mô hình chia sẻ trách nhiệm (Share Responsibility Model), hiểu rõ đâu là trách nhiệm của AWS và đâu là của khách hàng. Dịch vụ IAM (Cốt lõi): Phân biệt rõ ràng Root Account (toàn quyền, cần khóa lại) và IAM User (dùng hàng ngày, mặc định không có quyền). Nắm vững 3 thành phần chính để cấp quyền: IAM User (đối tượng), IAM Policy (giấy phép - viết bằng JSON), và IAM Group (nhóm các đối tượng). Hiểu rõ IAM Role: một cơ chế cấp quyền tạm thời (không có credentials vĩnh viễn) cho cả User và Service (như EC2). Kĩ thuật IAM (Quan trọng): Biết cách một User/Service \u0026ldquo;nhận\u0026rdquo; quyền của Role thông qua kĩ thuật Assume Role (sử dụng dịch vụ STS). Hiểu quy tắc đánh giá quyền: Explicit Deny (Deny tường minh) luôn thắng mọi quyền Allow. Dịch vụ Quản lý Định danh (Identity Services): Phân biệt rõ IAM (quản lý người quản trị AWS) và Amazon Cognito (quản lý người dùng cuối của ứng dụng web/mobile). Biết Cognito User Pool là thư mục người dùng (có thể login bằng Facebook, Google) và Identity Pool là nơi cấp quyền cho user đó truy cập tài nguyên AWS. Dịch vụ Quản lý Đa tài khoản (Multi-Account): Hiểu AWS Organizations dùng để quản lý tập trung nhiều tài khoản, cho phép Consolidated Billing (thanh toán gộp). Biết dùng Service Control Policies (SCP) trong Organization để giới hạn quyền tối đa của các tài khoản con. Nắm được AWS Identity Center (SSO) là giải pháp đăng nhập một lần, sử dụng Permission Set để cấp quyền vào các tài khoản trong Organization. Dịch vụ Mã hóa (Encryption): Biết AWS KMS là dịch vụ để tạo và quản lý khóa mã hóa. Hiểu cơ chế mã hóa Encryption at rest và phân biệt được CMK (khóa chính trong KMS) với Data Key (khóa dùng để mã hóa dữ liệu thực tế). Dịch vụ Giám sát Bảo mật (Monitoring): Biết AWS Security Hub là dịch vụ quét và chấm điểm bảo mật, giúp kiểm tra tuân thủ (compliance) theo các tiêu chuẩn (như PCIDSS). Thực hành: Thực hành tạo và quản lý User, Group, Policy, Role. Thực hành triển khai SSO và KMS. Thực hành sử dụng các tính năng nâng cao của IAM như Conditions và Permission Boundary. "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.5-client-integration/","title":"Tích hợp ứng dụng Client (Tùy chọn)","tags":[],"description":"","content":"Mục tiêu Bạn sẽ biến dòng code Python thành một Giao diện Web Chatbot (GUI) chuyên nghiệp, thân thiện với người dùng cuối (tương tự như giao diện ChatGPT) chỉ trong vài phút.\nChúng ta sử dụng:\nBackend: Python. Frontend: Streamlit. AI Model: Claude 3.5 Sonnet. Các Bước Thực hiện Phần I: Cấu hình AWS Credentials\nBước 1: Cài đặt AWS CLI\nMở Terminal trên máy tính của bạn.\n# macOS brew install awscli # Linux curl \u0026#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026#34; -o \u0026#34;awscliv2.zip\u0026#34; unzip awscliv2.zip sudo ./aws/install Bước 2: Cấu hình credentials\naws configure Nhập thông tin khi được hỏi:\nAWS Access Key ID: YOUR_ACCESS_KEY AWS Secret Access Key: YOUR_SECRET_KEY Default region name: us-east-1 Default output format: json Bước 3: Kiểm tra cấu hình\n# Kiểm tra credentials aws sts get-caller-identity # Kiểm tra kết nối Bedrock aws bedrock-agent-runtime list-knowledge-bases --region ap-southeast-1 Lưu ý bảo mật:\nKHÔNG commit credentials vào Git KHÔNG share credentials với người khác Sử dụng IAM roles khi có thể Rotate credentials định kỳ Permissions cần thiết:\nIAM User cần có các quyền sau:\nbedrock:InvokeModel bedrock:RetrieveAndGenerate bedrock:Retrieve s3:GetObject (cho Knowledge Base) Troubleshooting:\nLỗi \u0026ldquo;Unable to locate credentials\u0026rdquo;:\nKiểm tra file ~/.aws/credentials tồn tại Kiểm tra format file đúng Thử chạy aws configure lại Lỗi \u0026ldquo;AccessDeniedException\u0026rdquo;:\nKiểm tra IAM permissions Đảm bảo region đúng (ap-southeast-1) Kiểm tra Knowledge Base ID đúng Lỗi \u0026ldquo;ExpiredToken\u0026rdquo;:\nCredentials đã hết hạn Cần tạo credentials mới từ AWS Console Phần II: Clone Project từ GitHub đã tạo sẵn\nBước 1: Truy cập vào link GitHub sau\nBạn hãy tải về và mở folder trên bằng Visual Studio Code:\nhttps://github.com/DazielNguyen/chatbot_with_bedrock.git\nBước 2: Tải các thư viện và môi trường Python\nTải môi trường:\nMacOS: python3 -m venv .venv Win: python -m venv .venv Kích hoạt môi trường:\nMacOS: source .venv/bin/activate Win: .venv\\Scripts\\activate Tải thư viện:\nMacOS/ Win: pip install -r requirements.txt Bước 3: Lấy ID của Knowledge Base đã tạo\nTruy cập Amazon Bedrock -\u0026gt; Knowledge Base -\u0026gt; knowledge-base-demo Cập nhật \u0026ldquo;KB_ID=\u0026ldquo;YOUR_KNOWLEDGE_BASE_ID\u0026rdquo;\u0026rdquo; Bước 4: Chạy Streamlit - UI của Chatbot và Trải nghiệm\nRun Terminal: streamlit run start.py Khi chạy xong lệnh sẽ xuất hiện trang sau: Hãy thử hỏi một số câu hỏi bạn đã upload lên Knowledge Base trước đó. Kết quả Chabot đã trả về kết quả dựa trên file dữ liệu mà bạn đã cung cấp, có trích nguồn của dữ liệu của bạn. Kết luận Chúc mừng bạn đã xây dựng thành công một Web Chatbot được xây dựng từ Amazon Bedrock\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Xây dựng ứng dụng RAG sử dụng Knowledge Bases cho Amazon Bedrock Tổng quan Knowledge Bases for Amazon Bedrock là một tính năng được quản lý hoàn toàn giúp bạn triển khai kỹ thuật RAG (Retrieval-Augmented Generation) bằng cách kết nối các Foundation Models với nguồn dữ liệu nội bộ của bạn để cung cấp các phản hồi chính xác, có trích dẫn và phù hợp với ngữ cảnh.\nRAG là một kỹ thuật để tối ưu hóa đầu ra của Large Language Model (LLM) bằng cách truy xuất thông tin từ cơ sở dữ liệu bên ngoài đáng tin cậy (Retrieval) và thêm nó vào ngữ cảnh (Augmentation) trước khi tạo ra câu trả lời (Generation). Phương pháp này giúp khắc phục những hạn chế về dữ liệu huấn luyện lỗi thời và đảm bảo AI trả lời dựa trên thông tin thực tế được cung cấp.\nTrong bài lab này, chúng ta sẽ học cách xây dựng một trợ lý AI có khả năng \u0026ldquo;đọc và hiểu\u0026rdquo; các tài liệu doanh nghiệp độc quyền. Bạn sẽ thực hiện quy trình từ việc nhập dữ liệu và tạo chỉ mục vector đến cấu hình mô hình để trả lời câu hỏi dựa trên những tài liệu đó mà không cần quản lý bất kỳ máy chủ nào.\nChúng ta sẽ sử dụng ba thành phần chính để thiết lập quy trình xử lý RAG hoàn chỉnh:\nNguồn dữ liệu (Amazon S3) - Đóng vai trò là kho lưu trữ \u0026ldquo;sự thật\u0026rdquo;. Bạn sẽ tải các tài liệu (PDF, Word, Text) lên một S3 bucket. Knowledge Base sẽ sử dụng nguồn này để đồng bộ hóa dữ liệu. Vector Store (OpenSearch Serverless) - Nơi lưu trữ các embeddings vector (dữ liệu được mã hóa bằng số). Khi người dùng đặt câu hỏi, hệ thống sẽ thực hiện tìm kiếm ngữ nghĩa tại đây để trích xuất các đoạn văn bản liên quan nhất thay vì tìm kiếm từ khóa tiêu chuẩn. Foundation Model (Claude 3) - Large Language Model đóng vai trò là bộ não xử lý. Nó nhận câu hỏi của người dùng cùng với thông tin tìm thấy từ Vector Store, sau đó tổng hợp và tạo ra câu trả lời tự nhiên, chính xác kèm theo trích dẫn nguồn. Kết quả đạt được Khi kết thúc workshop, bạn sẽ có một hệ thống Chatbot thực tế, hoạt động với các tính năng sau:\nTrò chuyện hỏi đáp về nội dung tài liệu độc quyền. Câu trả lời chính xác, không có ảo giác (hallucinations). Trích dẫn nguồn (biết chính xác câu trả lời đến từ trang nào). Triển khai nhanh chóng mà không cần viết mã xử lý dữ liệu phức tạp. Nội dung Tổng quan về Workshop Chuẩn bị môi trường Tạo và cấu hình Knowledge Base Kiểm tra Chatbot (RAG) Tích hợp ứng dụng Client (Tùy chọn) Cập nhật dữ liệu Dọn dẹp tài nguyên "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/4-eventparticipated/4.6-event6/","title":"Event 6","tags":[],"description":"","content":"AWS Cloud Mastery Series #3 Mục Đích Của Chuỗi Chuyên Đề Sự kiện không dừng lại ở việc hướng dẫn sử dụng công cụ, mà tập trung vào việc hình thành Tư duy Hệ thống (System Thinking). Mục tiêu là giúp người tham dự chuyển đổi từ tư duy bảo mật thụ động sang mô hình Cloud-Native Security chủ động và toàn diện:\nXây dựng cộng đồng (Community): Tạo môi trường kết nối bền vững, lan tỏa tri thức thông qua mạng lưới AWS Cloud Clubs. Quản trị định hướng (Governance): Thiết lập nền tảng quản lý cho tổ chức quy mô lớn (hàng trăm tài khoản) đảm bảo sự đồng bộ và tuân thủ tuyệt đối. Phòng thủ chiều sâu (Defense in Depth): Chiến lược bảo mật đa lớp (Identity - Network - Data), đảm bảo nếu một lớp bị xuyên thủng, hệ thống vẫn an toàn. Phản ứng tự động (Automated Response): Chuyển từ việc xử lý sự cố thủ công (tốn thời gian) sang các quy trình tự động hóa (tức thì) để giảm thiểu thiệt hại. Danh Sách Diễn Giả Chương trình quy tụ đội ngũ chuyên gia dày dặn kinh nghiệm, là những gương mặt tiêu biểu trong cộng đồng kỹ thuật AWS tại Việt Nam:\nĐại diện AWS Cloud Clubs: Các thủ lĩnh (Captains) đến từ các trường đại học lớn: HCMUTE, SGU, PTIT, HUFLIT (Lê Vũ Xuân An, Trần Đức Anh, Trần Đoàn Công Lý, Danh Hoàng Hiếu Nghị). Chuyên gia Identity \u0026amp; Governance: Anh Huỳnh Hoàng Long, Đinh Lê Hoàng Anh (AWS Community Builders) - Chia sẻ về quản lý định danh. Chuyên gia Detection \u0026amp; Monitoring: Anh Trần Đức Anh, Nguyễn Tuấn Thịnh, Nguyễn Đỗ Thành Đạt - Tập trung vào giám sát và phát hiện mối đe dọa. Chuyên gia Network Security: Anh Kha Văn (Cloud Security Engineer | AWS Community Builder) - Chuyên sâu về an ninh mạng lưới. Chuyên gia Data Protection: Anh Thịnh Lâm, Việt Nguyễn - Chia sẻ chiến lược bảo vệ dữ liệu. Chuyên gia Incident Response: Anh Mendel Grabski (Long) - cựu Head of Security \u0026amp; DevOps, và anh Tinh Truong - Platform Engineer - Chia sẻ kinh nghiệm ứng phó sự cố thực chiến. Nội Dung Chi Tiết PHẦN 1: KHỞI ĐỘNG - AWS CLOUD CLUBS \u0026amp; CƠ HỘI PHÁT TRIỂN Phần mở đầu giới thiệu về hệ sinh thái AWS Cloud Clubs - bệ phóng cho nhân lực Cloud tương lai.\n1. Tầm nhìn (Vision):\nKhông chỉ là nơi học tập, đây là môi trường để sinh viên thực hành vai trò lãnh đạo và kết nối với mạng lưới nhân sự Cloud toàn cầu. 2. Lợi ích cốt lõi (Benefits):\nBuild Skills: Học đi đôi với hành qua các dự án thực tế, tài trợ chi phí thi chứng chỉ và tài khoản học tập chuyên sâu. Build Community: Rút ngắn khoảng cách giữa sinh viên và chuyên gia đầu ngành. Build Opportunities: Cơ hội làm đẹp CV, nhận tài trợ AWS Credits để thử nghiệm ý tưởng và kết nối việc làm. 3. The Badging Journey:\nLộ trình thăng tiến được thiết kế dạng Game hóa (Gamification) để thúc đẩy động lực. Các cấp bậc danh hiệu: Bronze \u0026gt; Silver \u0026gt; Gold \u0026gt; Platinum \u0026gt; Diamond. Giá trị nhận được: Không chỉ là swag (quà tặng) hay Credits ($200+), mà là sự công nhận năng lực để ưu tiên tham gia các sự kiện lớn như Student Community Day. PHẦN 2: NỀN TẢNG ĐỊNH DANH VÀ QUẢN TRỊ (IDENTITY \u0026amp; GOVERNANCE) Khẳng định nguyên lý: Trên Cloud, biên giới mạng không còn là tường lửa duy nhất, mà chính là Định danh (Identity).\n1. Tư duy IAM hiện đại:\nIdentity First: Coi định danh là tuyến phòng thủ đầu tiên và quan trọng nhất. Credential Spectrum (Phổ thông tin xác thực): Loại bỏ thói quen dùng Long-term Credentials (Access Key cố định - rủi ro lộ lọt cao) và chuyển sang Short-term Credentials (STS tokens - tự động hết hạn sau phiên làm việc). Least Privilege (Quyền tối thiểu): Nguyên tắc \u0026ldquo;chỉ cấp những gì thực sự cần\u0026rdquo;. Tuyệt đối tránh thói quen cấp quyền admin (*) cho tiện, vì đây là lỗ hổng chết người. 2. Quản trị quy mô lớn với AWS Organizations:\nKiến trúc phân tầng: Tổ chức tài khoản theo chức năng (OUs) như Security (chứa log, audit), Shared Services (hạ tầng chung), Workloads (chạy ứng dụng) để cô lập rủi ro. Nếu một OU bị tấn công, các OU khác vẫn an toàn. Service Control Policies (SCPs): Được ví như \u0026ldquo;Hiến pháp\u0026rdquo; của hệ thống. SCP tạo ra các vành đai bảo vệ cứng (Guardrails) - ví dụ: cấm user xóa log CloudTrail, cấm tạo server ở region lạ - mà ngay cả tài khoản Root của từng account con cũng không thể vi phạm. PHẦN 3: KHẢ NĂNG QUAN SÁT VÀ PHÁT HIỆN (VISIBILITY \u0026amp; DETECTION) Chiến lược: \u0026ldquo;Bạn không thể bảo vệ những gì bạn không nhìn thấy\u0026rdquo;.\n1. Amazon GuardDuty - Trinh sát thông minh:\nHệ thống phát hiện xâm nhập thông minh sử dụng AI/ML để phân tích 3 luồng dữ liệu gốc: CloudTrail (Ai làm gì?), VPC Flow Logs (Traffic đi đâu?), và DNS Logs (Truy cập web nào?). Runtime Monitoring: Tính năng nâng cao, cài agent nhẹ vào máy chủ để giám sát sâu bên trong hệ điều hành (OS Level), phát hiện các tiến trình lạ (malware processes) hoặc hành vi leo thang đặc quyền mà log mạng bên ngoài không thấy được. 2. AWS Security Hub - Trung tâm chỉ huy:\nGiải quyết vấn đề phân mảnh thông tin bằng chuẩn ASFF (AWS Security Finding Format). Mọi cảnh báo từ GuardDuty, Inspector, Macie đều được quy về một định dạng chung. Đóng vai trò CSPM (Cloud Security Posture Management): Tự động rà soát hệ thống 24/7 để chấm điểm tuân thủ theo các tiêu chuẩn quốc tế (CIS, PCI-DSS) và báo cáo các cấu hình sai lệch. PHẦN 4: BẢO MẬT MẠNG LƯỚI (NETWORK SECURITY) Xây dựng \u0026ldquo;Pháo đài số\u0026rdquo; với tư duy Zero Trust (Không tin ai cả, kể cả mạng nội bộ).\n1. Kiểm soát cơ bản (VPC Fundamentals):\nSecurity Groups (Stateful): Áp dụng Micro-segmentation. Thay vì whitelist IP (vốn hay thay đổi trên Cloud), ta dùng cơ chế Reference ID (Server App chỉ được nhận traffic từ Server Web). Vì là Stateful, nó tự động cho phép traffic phản hồi đi ra. NACLs (Stateless): Lớp bảo vệ thô ở cấp độ Subnet. Dùng để chặn cứng (Deny) các dải IP đen hoặc các subnet không tin cậy. 2. Phòng thủ nâng cao (Advanced Filtering):\nDNS Firewall (Route 53 Resolver): Ngăn chặn malware kết nối về máy chủ điều khiển (C2) của hacker. Ngay cả khi máy bị nhiễm, nó cũng không thể \u0026ldquo;gọi điện về nhà\u0026rdquo; để nhận lệnh. AWS Network Firewall: Tường lửa thế hệ mới với khả năng kiểm tra sâu gói tin (Deep Packet Inspection): Stateless Engine: Xử lý cực nhanh dựa trên IP/Port. Stateful Engine: Sử dụng bộ luật Suricata (Open Source IPS) để phân tích nội dung gói tin, chặn các cuộc tấn công phức tạp hoặc lọc tên miền (FQDN) cho traffic đi ra Internet. 3. Kiến trúc mạng hiện đại:\nSử dụng AWS Transit Gateway để đơn giản hóa việc kết nối nhiều VPC, tích hợp sẵn Network Firewall để kiểm tra traffic tập trung (Centralized Inspection). Active Threat Defense: Tự động hóa quy trình phòng thủ: GuardDuty phát hiện IP độc hại -\u0026gt; Tự động cập nhật luật cho Network Firewall để chặn IP đó trên toàn hệ thống. PHẦN 5: BẢO VỆ DỮ LIỆU (DATA PROTECTION) Bảo vệ tài sản cốt lõi bằng các lớp mã hóa thông minh.\n1. Mã hóa bao thư (Envelope Encryption):\nCơ chế tối ưu hiệu năng của AWS KMS: Thay vì dùng khóa chính để mã hóa cục dữ liệu lớn (rất chậm), KMS dùng khóa chính (Master Key) để mã hóa một khóa dữ liệu nhỏ (Data Key). Khóa dữ liệu này mới dùng để mã hóa file. Vừa an toàn, vừa nhanh. 2. Quản lý bí mật (Secrets Management):\nVấn đề: Hardcode user/pass DB trong code là tử huyệt bảo mật. Giải pháp: Dùng AWS Secrets Manager. Điểm mạnh nhất không chỉ là lưu trữ, mà là khả năng Automatic Rotation. Nó tự động đổi pass DB định kỳ và cập nhật cho ứng dụng, khiến hacker dù có trộm được pass cũ cũng vô dụng. 3. Hạ tầng mã hóa phần cứng:\nAWS Nitro System: Các tác vụ mã hóa/giải mã nặng nhọc được chuyển xuống chip phần cứng chuyên biệt (Nitro Cards). Điều này đảm bảo Server được mã hóa toàn diện nhưng không hề bị chậm đi (Zero Performance Impact). PHẦN 6: ỨNG PHÓ SỰ CỐ (INCIDENT RESPONSE) Khi phòng thủ thất bại, tốc độ phản ứng là yếu tố sinh tồn.\n1. Chiến lược phòng ngừa (Prevention - Sleep Better):\nNguyên tắc: \u0026ldquo;Phòng bệnh hơn chữa bệnh\u0026rdquo;. Loại bỏ SSH key vĩnh viễn, chặn S3 Public Access ở mức Account, dùng Private Subnet mặc định. Infrastructure as Code (IaC): Bảo mật bắt đầu từ Code. Dùng Terraform/CDK giúp kiểm soát thay đổi, review được cấu hình trước khi deploy, loại bỏ hoàn toàn lỗi cấu hình do sửa tay (ClickOps). 2. Quy trình 5 bước chuẩn mực:\nChuẩn bị (Preparation): \u0026ldquo;Thao trường đổ mồ hôi, chiến trường bớt đổ máu\u0026rdquo;. Phải có sẵn công cụ, log và kịch bản (Playbook). Phát hiện (Detection): Dựa vào tín hiệu từ CloudTrail, GuardDuty. Cô lập (Containment): Bước quan trọng nhất để ngăn lây lan. Ví dụ: Dùng Lambda tự động gắn Security Group \u0026ldquo;cách ly\u0026rdquo; vào EC2 bị nhiễm. Diệt trừ \u0026amp; Phục hồi (Eradication \u0026amp; Recovery): Xóa bỏ nguyên nhân, khôi phục từ bản backup sạch gần nhất. Hậu sự cố (Post-Incident): Phân tích nguyên nhân gốc rễ (RCA) để cải tiến quy trình. 3. Tự động hóa (Automation is King):\nHacker dùng tool tự động, ta không thể chống lại bằng tay. Sử dụng EventBridge bắt sự kiện rủi ro và kích hoạt Lambda để xử lý ngay lập tức (ví dụ: tự động đóng S3 bucket bị public trong tích tắc). Kết Luận Chuỗi chuyên đề \u0026ldquo;Cloud Security \u0026amp; Operations Mastery\u0026rdquo; là cẩm nang toàn diện để kiến tạo một hệ thống Cloud vững chắc:\nIdentity \u0026amp; Governance: Là nền móng. Quản lý chặt ai được vào nhà và họ được làm gì. Network \u0026amp; Detection: Là hệ thống báo động và tường rào. Quan sát mọi ngóc ngách và phát hiện kẻ gian ngay khi chúng xuất hiện. Data \u0026amp; Response: Là két sắt và đội bảo vệ. Mã hóa dữ liệu nhiều lớp và sẵn sàng phản ứng tự động để dập tắt nguy cơ ngay lập tức. Một số hình ảnh khi tham gia sự kiện Hình ảnh hơn 400 bạn tham dự buổi Event AWS Cloud Mastery Series #3\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6: Ôn tập các khái niệm cơ sở dữ liệu (CSDL) nền tảng, bao gồm RDBMS (khóa chính, khóa ngoại), các kỹ thuật tối ưu (Index, Partition), và các khái niệm về vận hành (Database Log, Buffer). Phân biệt rõ hai loại hệ thống CSDL chính: OLTP (Online Transaction Processing - xử lý giao dịch) và OLAP (Online Analytical Processing - xử lý phân tích hay Kho dữ liệu). Hiểu rõ dịch vụ CSDL quan hệ được quản lý Amazon RDS, bao gồm các tính năng cốt lõi như Multi-AZ (cho tính sẵn sàng cao) và Read Replicas (cho hiệu năng đọc). Tìm hiểu về Amazon Aurora, dịch vụ CSDL cloud-native của AWS, với kiến trúc lưu trữ chia sẻ độc đáo, hiệu năng cao và các tính năng vượt trội như Zero Replication Lag. Tìm hiểu về Amazon Redshift, dịch vụ kho dữ liệu (Data Warehouse) quy mô petabyte, được thiết kế cho OLAP, và hiểu rõ kiến trúc MPP cùng kỹ thuật Columnar Storage. Hiểu về vai trò của Amazon ElastiCache (Redis, Memcached) như một lớp bộ nhớ đệm (caching) tốc độ cao để giảm tải cho CSDL chính. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 Database Concepts:\n- Kiến trúc RDBMS (PK, FK, Normalization) \u0026amp; Tối ưu hóa (Index, Partition, Execution Plan).\n- Phân biệt RDBMS (ACID) vs NoSQL (BASE).\n- Phân loại hệ thống: OLTP (Giao dịch) vs OLAP (Phân tích). 13/10/2025 13/10/2025 Module 06 3 Amazon RDS:\n- Dịch vụ quản lý, Automated Backups (Point-in-Time Recovery).\n- Multi-AZ: Đồng bộ, High Availability, Auto Failover.\n- Read Replicas: Bất đồng bộ, Tối ưu hiệu năng đọc. 14/10/2025 14/10/2025 Module 06 4 Amazon Aurora:\n- Kiến trúc lưu trữ: Shared Volume, 6 bản sao/3 AZ, Zero Replication Lag.\n- Cấu trúc Cluster: 1 Writer + tối đa 15 Readers.\n- Tính năng nâng cao: Backtrack, Global Database. 15/10/2025 15/10/2025 Module 06 5 Amazon Redshift: Data Warehouse, kiến trúc MPP, lưu trữ dạng Cột (Columnar) tối ưu cho OLAP, Redshift Spectrum.\nAmazon ElastiCache: Caching in-memory (Redis/Memcached), giảm tải cho DB chính. 16/10/2025 16/10/2025 Module 06 6 Lab 000005: Amazon RDS cơ bản (Tạo DB, Kết nối, Backup/Restore).\nLab 000043: Migration CSDL dùng DMS và SCT (Oracle sang Aurora).\nNghiên cứu thêm: Sách Database Internals \u0026amp; The Data Warehouse Toolkit. 17/10/2025 17/10/2025 Module 06 Kết quả đạt được tuần 6: Bài học (Nền tảng): Phân biệt rõ ràng hai mô hình hệ thống: OLTP (Online Transaction Processing - xử lý giao dịch) và OLAP (Online Analytical Processing - xử lý phân tích, kho dữ liệu). Nắm vững các kỹ thuật tối ưu CSDL cơ bản: Index (tăng tốc độ đọc) và Partition (chia nhỏ bảng). Hiểu vai trò của Database Log (để khôi phục/đồng bộ) và Buffer (dùng RAM để tăng tốc). Dịch vụ (RDS): Biết Amazon RDS là dịch vụ CSDL quan hệ (OLTP) được quản lý. Phân biệt rõ 2 tính năng chính của RDS: Multi-AZ (dùng cho tính Sẵn sàng cao - HA) và Read Replicas (dùng để tăng hiệu năng đọc). Kĩ thuật (Replication): Phân biệt Synchronous Replication (Sao chép đồng bộ - dùng cho RDS Multi-AZ) và Asynchronous Replication (Sao chép bất đồng bộ - dùng cho RDS Read Replicas, có thể bị trễ). Dịch vụ (Aurora): Biết Amazon Aurora là CSDL hiệu năng cao, cloud-native. Hiểu kiến trúc lưu trữ chia sẻ (Cluster Volume) của Aurora và lợi ích vượt trội là Zero Replication Lag (không có độ trễ). Nắm được các tính năng cao cấp như Backtrack và Global Database. Dịch vụ (Redshift): Biết Amazon Redshift là dịch vụ kho dữ liệu (OLAP). Hiểu kiến trúc MPP (Massively Parallel Processing) (gồm Leader Node và Compute Nodes). Nắm vững kỹ thuật cốt lõi của OLAP: Columnar Storage (Lưu trữ dạng Cột), giúp tăng tốc các truy vấn phân tích. Dịch vụ (ElastiCache): Biết Amazon ElastiCache (Redis/Memcached) là dịch vụ caching trong RAM. Hiểu vai trò của caching là giảm tải cho CSDL chính. Nhận thức được trách nhiệm phải tự viết Caching Logic trong ứng dụng. Thực hành: Biết cách tạo và vận hành (backup/restore) một CSDL RDS. Biết cách sử dụng dịch vụ DMS và SCT để dịch chuyển (migrate) CSDL từ Oracle sang Aurora. "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.6-update-data/","title":"Cập nhật dữ liệu","tags":[],"description":"","content":"Mục tiêu Một trong những lợi thế lớn nhất của RAG so với Fine-tuning (huấn luyện lại) mô hình là khả năng cập nhật dữ liệu nhanh chóng. Khi doanh nghiệp có quy định mới, bạn chỉ cần nhập chúng vào Knowledge Base, và AI sẽ \u0026ldquo;học\u0026rdquo; chúng ngay lập tức.\nTrong phần này, chúng ta sẽ mô phỏng kịch bản sau:\nHỏi AI về một thông tin không tồn tại (AI sẽ trả lời là không biết). Cung cấp thông tin đó cho hệ thống bằng cách tải lên file mới. Hỏi lại câu hỏi tương tự để chứng kiến AI trả lời đúng ngay lập tức. Các Bước Thực hiện Bước 1: Xác minh \u0026ldquo;thiếu kiến thức\u0026rdquo; ban đầu\nChúng ta cần xác nhận rằng AI hiện tại không biết gì về thông tin bí mật mà chúng ta sắp tạo.\nQuay lại giao diện Streamlit Chatbot (được tạo trong Phần 5) hoặc sử dụng cửa sổ Test Knowledge Base trên Console. Đặt một câu hỏi về thông tin giả định không có thật. Ví dụ: \u0026ldquo;Mã kích hoạt cho Dự án Omega là gì?\u0026rdquo; Quan sát kết quả: AI sẽ trả lời rằng không thể tìm thấy thông tin trong các tài liệu được cung cấp hoặc sẽ cố gắng đưa ra câu trả lời chung chung (nếu không bị hạn chế). Bước 2: Tạo dữ liệu mới\nChúng ta sẽ tạo một file văn bản chứa \u0026ldquo;bí mật\u0026rdquo; này để nhập vào hệ thống.\nTrên máy tính của bạn, mở Notepad (Windows) hoặc TextEdit (Mac). Sao chép và dán nội dung sau vào file: THÔNG BÁO MẬT: Dự án Omega bí mật chính thức khởi động vào ngày 01/12/2025. Mã kích hoạt là: \u0026#34;AWS-ROCKS-2025-SINGAPORE\u0026#34;. Người Quản lý Dự án là Ông Robot. Vui lòng giữ thông tin này tuyệt đối bí mật. Lưu file với tên: secret-project.txt. Bạn có thể tải file tại đây: Tệp định dạng TXT\nBước 3: Tải lên và Đồng bộ\nBây giờ, chúng ta sẽ cung cấp kiến thức mới này vào \u0026ldquo;bộ não\u0026rdquo; của AI.\nTruy cập S3 Console, điều hướng đến bucket cũ của bạn (rag-workshop-demo).\nNhấp Upload -\u0026gt; Add files -\u0026gt; Chọn file secret-project.txt -\u0026gt; Upload.\nChuyển sang Amazon Bedrock Console -\u0026gt; Chọn Knowledge bases từ menu bên trái. Nhấp vào tên Knowledge Base của bạn. Cuộn xuống phần Data source, chọn nguồn dữ liệu (s3-datasource). Nhấp vào nút Sync (Màu cam). Chờ đợi: Chờ khoảng 30 giây đến 1 phút cho đến khi cột Status chuyển từ Syncing sang Available. Bước 4: Xác minh lại (Khoảnh khắc \u0026ldquo;Wow\u0026rdquo;)\nHệ thống hiện đã có kiến thức mới. Hãy thách thức AI một lần nữa.\nQuay lại giao diện Streamlit Chatbot (Không cần tải lại trang hoặc khởi động lại server). Hỏi chính xác câu hỏi tương tự như trước: \u0026ldquo;Mã kích hoạt cho Dự án Omega là gì?\u0026rdquo; Kết quả mong đợi: AI trả lời chính xác: \u0026ldquo;Mã kích hoạt là AWS-ROCKS-2025-SINGAPORE\u0026rdquo;. AI trích dẫn nguồn là file secret-project.txt. Kết luận Bạn vừa chứng kiến sức mạnh thực sự của RAG!\nKhông cần chỉnh sửa code. Không cần huấn luyện lại mô hình. Chỉ cần Sync dữ liệu. Chatbot của bạn đã trở nên thông minh hơn và cập nhật với thông tin mới nhất chỉ trong vài bước đơn giản. Đây chính là lý do tại sao các doanh nghiệp chọn giải pháp này để xây dựng trợ lý ảo nội bộ.\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại AWS/First Cloud Journey từ 12/08/2025 đến 12/12/2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia việc học các dịch vụ AWS và áp dụng kiến thức vào một dự án nhóm chủ đề FinTech, qua đó cải thiện kỹ năng thu thập dữ liệu, phân tích dữ liệu, báo cáo và giao tiếp.\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ☐ ✅ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ☐ ✅ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ☐ ✅ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ✅ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ☐ ✅ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ☐ ✅ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ☐ ✅ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ☐ ✅ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7: Học và nghiên cứu thêm những kiến thức về Cloud Hoàn thành các Mooc trong Skil Builder ôn chứng chỉ Certificate Cloud Practicioner Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 Domain 1: Cloud Concepts\n- 5 tiêu chí Cloud Computing.\n- Phân biệt Availability, Reliability, Resiliency.\n- Scaling vs. Elasticity.\n- AWS Well-Architected Framework (6 trụ cột). 20/10/2025 20/10/2025 3 Domain 1: Cloud Adoption \u0026amp; Economics\n- AWS Cloud Adoption Framework (CAF) \u0026amp; các giai đoạn.\n- Chiến lược di chuyển (7 R\u0026rsquo;s) \u0026amp; Migration Services.\n- Cloud Economics, Pricing Models \u0026amp; TCO. 21/10/2025 21/10/2025 4 Domain 2: Security \u0026amp; Compliance\n- Shared Responsibility Model (Mô hình trách nhiệm chung).\n- Quản lý truy cập: Root, IAM, Cognito, Policies.\n- Bảo mật mạng \u0026amp; tài nguyên: Security Group, NACL, WAF. 22/10/2025 22/10/2025 5 Domain 3: Technology \u0026amp; Services (Part 1)\n- Global Infra: Regions, AZs, Edge Locations (CloudFront, Global Accelerator).\n- Compute: EC2 (Types, Config), Containers, Serverless.\n- Database: RDS, Aurora, DynamoDB, ElastiCache, Redshift \u0026amp; Migration tools. 23/10/2025 23/10/2025 6 Domain 3: Technology \u0026amp; Services (Part 2)\n- Networking: VPC (Core components, Security, Connectivity), DNS.\n- Storage: S3, EBS, EFS, Storage Gateway, Backup.\n- Advanced Services: AI/ML, Analytics, Monitoring (CloudWatch), Integration (SQS/SNS), DevOps tools, IoT. 24/10/2025 24/10/2025 Kết quả đạt được tuần 7: 1. Domain 1: Cloud Concepts - Lợi ích của AWS Cloud Điện toán đám mây cơ bản:\nNắm vững 5 tiêu chí của điện toán đám mây (On-demand self-service, Broad network access, Resource pooling, Rapid elasticity, Measured service) Hiểu rõ về hạ tầng đám mây AWS Phân biệt rõ các khái niệm: Availability (Khả năng sẵn có): Hệ thống luôn hoạt động và có thể truy cập được Durability (Khả năng chịu đựng): Dữ liệu được bảo vệ khỏi mất mát Resilience (Khả năng phục hồi): Hệ thống có thể phục hồi nhanh sau sự cố Hiểu khác biệt giữa Scaling (Mở rộng quy mô) và Elasticity (Tính đàn hồi) AWS Well-Architected Framework:\nNắm vững các nguyên tắc thiết kế chung (General Design Principles) Hiểu rõ 6 trụ cột chính: Operational Excellence (Xuất sắc hoạt động) Security (Bảo mật) Reliability (Độ tin cậy) Performance Efficiency (Hiệu suất) Cost Optimization (Tối ưu chi phí) Sustainability (Tính bền vững) Di chuyển lên AWS Cloud:\nHiểu về AWS Cloud Adoption Framework (CAF) với 6 perspectives Nắm vững các giai đoạn chấp nhận đám mây (Cloud Adoption Stages) Học thuộc 7 chiến lược di chuyển (7 R\u0026rsquo;s): Rehost (Lift and Shift) Replatform (Lift, Tinker, and Shift) Repurchase (Drop and Shop) Refactor/Re-architect Retire Retain Relocate Hiểu về các dịch vụ và kịch bản di chuyển Cloud Economics:\nHiểu về Total Cost of Ownership (TCO) Các phương pháp giảm chi phí trên AWS Mô hình thanh toán và giá cả của AWS 2. Domain 2: Security and Compliance AWS Shared Responsibility Model:\nTrách nhiệm của AWS (Security OF the Cloud) Trách nhiệm của khách hàng (Security IN the Cloud) Trách nhiệm thay đổi dựa trên loại dịch vụ (IaaS, PaaS, SaaS) Security, Governance \u0026amp; Compliance:\nCác khái niệm bảo mật cơ bản của AWS Quản trị và tuân thủ trên AWS Cloud Các dịch vụ và công cụ bảo mật Access Management:\nAWS Root User và best practices AWS IAM (Identity and Access Management) Amazon Cognito IAM Policies và cách hoạt động Least Privilege Principle Security Components:\nSecurity Groups: Firewall ở tầng instance Network ACLs (NACLs): Firewall ở tầng subnet AWS WAF (Web Application Firewall): Bảo vệ ứng dụng web 3. Domain 3: Cloud Technology and Services (Phần 1) 3.1 Deployment và Operating Methods:\nCác phương pháp triển khai và vận hành Các loại Cloud: Public, Private, Hybrid So sánh dịch vụ Public vs Private Các tùy chọn kết nối 3.2 AWS Global Infrastructure:\nCấu trúc hạ tầng toàn cầu AWS (Regions, Availability Zones) Tiện ích mở rộng khu vực (Local Zones, Wavelength Zones) Edge Services: CloudFront vs Global Accelerator Khái niệm về Availability Zones và Disaster Recovery 3.3 AWS Compute Resources:\nAmazon EC2: Các loại instance, AMI, cấu hình EC2 Storage: EBS, Instance Store Containers: ECS, EKS, Fargate Serverless Computing: AWS Lambda So sánh High Availability vs Scalability 3.4 AWS Database Resources:\nAmazon RDS: Managed relational database Amazon Aurora: MySQL/PostgreSQL compatible Amazon DynamoDB: NoSQL database In-Memory Databases: ElastiCache, DynamoDB Accelerator (DAX) Amazon Redshift: Data warehouse Migration Services: AWS Snow Family, AWS DMS, AWS DataSync 4. Domain 3: Cloud Technology and Services (Phần 2) 3.5 AWS Network Resources:\nAmazon VPC và các thành phần cốt lõi: Subnets (Public/Private) Route Tables Internet Gateway NAT Gateway VPC Security: Security Groups, NACLs VPC Gateways: Internet Gateway, NAT Gateway, Virtual Private Gateway VPC \u0026amp; Hybrid Connectivity: VPN, Direct Connect DNS \u0026amp; Routing: Route 53 3.6 AWS Storage Resources:\nCác loại lưu trữ đám mây: Object, Block, File Amazon S3: Object storage, storage classes File Storage: EFS vs FSx Block Storage: EBS vs Instance Store EBS Volume Types: gp2, gp3, io1, io2, st1, sc1 AWS Storage Gateway: Hybrid storage Backup Solutions: AWS Backup 3.7 AI/ML và Analytics Services:\nCơ bản về AI/ML 3 cấp độ AWS ML: AI Services (Rekognition, Comprehend, etc.) ML Services (SageMaker) ML Frameworks \u0026amp; Infrastructure Analytics Services: Amazon Athena: Query S3 data Amazon Macie: Data security Amazon Redshift: Data warehouse Amazon Kinesis: Real-time data streaming Amazon Glue: ETL service Amazon QuickSight: BI tool Amazon EMR: Big data processing 3.8 Các Dịch Vụ AWS Khác:\nMonitoring \u0026amp; Observability: CloudWatch, X-Ray, EventBridge Application Integration: SQS, SNS Business \u0026amp; Customer Services: Amazon Connect, SES, AWS Activate, AWS IQ Developer \u0026amp; DevOps Tools: CodeCommit, CodeBuild, CodeDeploy, CodePipeline End-User Computing: AppStream 2.0, WorkSpaces, WorkSpaces Web Frontend \u0026amp; Mobile: AWS Amplify, AWS AppSync IoT Services: AWS IoT Core, AWS IoT Greengrass Tổng kết: Tuần 7 đã hoàn thành việc học tập toàn diện về 3 domains chính cho chứng chỉ AWS Cloud Practitioner. Nắm vững các khái niệm cloud computing cơ bản, hiểu rõ về bảo mật và tuân thủ trên AWS, cũng như làm quen với hầu hết các dịch vụ AWS quan trọng. Đã có nền tảng kiến thức vững chắc để chuẩn bị cho kỳ thi chứng chỉ.\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":" Tại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Đó là được lên công ty ngồi máy lạnh và làm việc. Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Khi mình đi ra đi vệ sinh thì rất dễ, còn lúc vào thì lại khó khăn hay bị khoá cửa ở ngoài. Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Chắc chắn mình sẽ giới thiệu với bạn bè của mình, vì ở đây không chỉ môi trường làm việc rất chuyên nghiệp mà còn tiện cho việc đi chơi ở quận 1. Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Em chưa có ý tưởng gì ạ. Bạn có muốn tiếp tục chương trình này trong tương lai? Có chứ, mình vẫn muốn tiếp tục thử sức với chương trình này. Góp ý khác (tự do chia sẻ): "},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/5-workshop/5.7-cleanup/","title":"Dọn dẹp Tài nguyên","tags":[],"description":"","content":"Mục tiêu Để tránh phát sinh chi phí không mong muốn sau khi hoàn thành bài thực hành, chúng ta cần xóa các tài nguyên đã tạo.\n⚠️ CẢNH BÁO: Xóa Knowledge Base KHÔNG tự động xóa Vector Store (OpenSearch Serverless). Bạn phải xóa thủ công OpenSearch Serverless Collection vì đây là dịch vụ tốn chi phí nhất trong Lab này.\nCác Bước Thực hiện Bước 1: Xóa Knowledge Base\nTruy cập Amazon Bedrock Console -\u0026gt; Knowledge bases.\nChọn nút radio bên cạnh tên Knowledge Base của bạn.\nNhấp vào nút Delete.\nHộp thoại xuất hiện, nhập tên Knowledge Base để xác nhận (hoặc gõ delete).\nNhấp Delete. Quá trình này mất 10-15 phút mới xóa thành công. Nên bạn thư giản nhé\nBước 2: Xóa Vector Store\nTruy cập Amazon OpenSearch Service. Trong menu bên trái, ở phần Serverless, chọn Collections. Bạn sẽ thấy một Collection có tên dạng bedrock-knowledge-base-.... Chọn nút radio bên cạnh tên Collection đó. Nhấp vào nút Delete. Gõ confirm hoặc tên collection để xác nhận xóa. Nhấp Delete. Bước 3: Xóa Dữ liệu trên S3\nTruy cập dịch vụ Amazon S3. Chọn bucket rag-workshop-demo. Nhấp vào nút Empty trước tiên. Gõ permanently delete để xác nhận xóa tất cả các file bên trong. Sau khi bucket rỗng, quay lại danh sách Buckets. Chọn lại bucket đó và nhấp vào nút Delete. Nhập tên bucket để xác nhận. Hoàn thành Chúc mừng bạn đã hoàn thành đầy đủ Workshop \u0026ldquo;Xây dựng Ứng dụng RAG với Amazon Bedrock\u0026rdquo;. Hệ thống của bạn đã được dọn dẹp và an toàn!\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8: Hoàn thành các khóa học về NLP (Natural Language Processing) Tìm hiểu thêm về FastAPI để chuẩn bị cho dự án sắp tới. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 Module 01: NLP cơ bản \u0026amp; Vector Spaces\n- Phân tích cảm xúc (Logistic Regression, Naive Bayes).\n- Mô hình không gian Vector, Dịch máy \u0026amp; Tìm kiếm tài liệu. 27/10/2025 27/10/2025 3 Module 02: Mô hình Xác suất (Probabilistic Models)\n- Autocorrect, Gắn thẻ từ loại (POS Tagging - HMMs).\n- Language Models \u0026amp; Word Embeddings. 28/10/2025 28/10/2025 4 Module 03: Mô hình Chuỗi (Sequence Models)\n- Mạng RNNs, LSTMs và nhận dạng thực thể tên (NER).\n- Mạng Siamese Networks. 29/10/2025 29/10/2025 5 Module 04: Mô hình Attention (Attention Models)\n- Dịch máy Neural (NMT).\n- Tóm tắt văn bản (Text Summarization) \u0026amp; Hỏi đáp (QA). 30/10/2025 30/10/2025 6 Deployment \u0026amp; API:\n- Triển khai mô hình ML thành API.\n- Xây dựng ứng dụng CRUD hoàn chỉnh với FastAPI. 31/10/2025 31/10/2025 Kết quả đạt được tuần 8: 1. Module 01 - Xử Lý Ngôn Ngữ Tự Nhiên với Phân Loại và Không Gian Vectơ Week 01: Phân Tích Tình Cảm với Hồi Quy Logistic\nHiểu về binary classification cho sentiment analysis Xây dựng model logistic regression từ đầu Feature extraction với Bag of Words Preprocessing: tokenization, stemming, stop words removal Đánh giá model với accuracy, precision, recall Week 02: Phân Tích Tình Cảm với Naive Bayes\nHiểu về Bayes\u0026rsquo; Theorem và conditional probability Xây dựng Naive Bayes classifier So sánh performance với Logistic Regression Hiểu về independence assumption Laplacian smoothing để xử lý zero probability Week 03: Mô Hình Không Gian Vector\nVector space models và word representations Cosine similarity để đo độ tương đồng PCA (Principal Component Analysis) để giảm chiều Visualize word embeddings Euclidean distance vs Cosine similarity Week 04: Dịch Máy và Tìm Kiếm Tài Liệu\nWord alignment cho machine translation Hash tables và locality sensitive hashing Document search và information retrieval K-nearest neighbors trong NLP Transformation matrices cho word translation 2. Module 02 - Xử Lý Ngôn Ngữ Tự Nhiên với Mô Hình Xác Suất Week 01: Tự Động Sửa Lỗi và Khoảng Cách Chỉnh Sửa Tối Thiểu\nEdit distance (Levenshtein distance) Dynamic programming cho minimum edit distance Spelling correction algorithms Probability-based error correction N-gram models cho spell checking Week 02: Gắn Thẻ Từ Loại và Mô Hình Markov Ẩn\nPart-of-Speech (POS) tagging Hidden Markov Models (HMMs) Viterbi algorithm cho sequence labeling Transition và emission probabilities Training HMMs với tagged corpus Week 03: Autocomplete và Language Models\nN-gram language models (unigram, bigram, trigram) Perplexity để đánh giá language models Smoothing techniques (Laplace, Add-k) Backoff và interpolation Building autocomplete systems Week 04: Word Embeddings với Neural Networks\nContinuous Bag of Words (CBOW) Skip-gram model Word2Vec architecture Training word embeddings Negative sampling Evaluating word embeddings 3. Module 03 - Xử Lý Ngôn Ngữ Tự Nhiên với Mô Hình Chuỗi Week 01: Recurrent Neural Networks cho Language Modeling\nRNN architecture và forward propagation Backpropagation through time (BPTT) Vanishing và exploding gradient problems Language modeling với RNNs Text generation với RNNs GRU (Gated Recurrent Units) Week 02: LSTMs và Named Entity Recognition\nLong Short-Term Memory (LSTM) architecture Cell state, forget gate, input gate, output gate Named Entity Recognition (NER) task Bidirectional LSTMs Training LSTMs cho sequence labeling Evaluating NER systems Week 03: Siamese Networks\nSiamese network architecture Triplet loss function One-shot learning Similarity learning Applications: question duplicate detection, semantic similarity Cosine similarity trong neural networks 4. Module 04 - Xử Lý Ngôn Ngữ Tự Nhiên với Các Mô Hình Chú Ý Week 01: Neural Machine Translation\nSequence-to-sequence (Seq2Seq) models Encoder-decoder architecture Attention mechanism Teacher forcing BLEU score cho machine translation Beam search decoding Week 02: Tóm Tắt Văn Bản\nExtractive vs Abstractive summarization Seq2Seq với attention cho summarization ROUGE scores (ROUGE-1, ROUGE-2, ROUGE-L) Coverage mechanism Pointer-generator networks Handling long documents Week 03: Question Answering\nQuestion answering systems Context-based QA Attention mechanisms cho QA SQuAD dataset Extractive QA models End-to-end trainable QA systems 5. FastAPI và Triển Khai Machine Learning Models Machine Learning Model as API:\nSetup FastAPI project structure Load và serve ML models Request/Response schemas với Pydantic Input validation và error handling Preprocessing pipelines trong API Testing API endpoints Dockerize ML API FastAPI CRUD Application:\nRESTful API design principles CRUD operations (Create, Read, Update, Delete) Database integration (SQLAlchemy) Async/await operations Authentication và authorization API documentation với Swagger/OpenAPI Dependency injection trong FastAPI File structure best practices: app/main.py: Entry point app/routers/: API routes app/models/: Database models app/schemas/: Pydantic schemas app/crud/: Database operations app/db/: Database configuration FastAPI Key Features Mastered:\nPath parameters và query parameters Request body validation Response models Background tasks Middleware CORS configuration Environment variables Testing với pytest Tổng kết: Tuần 8 đã hoàn thành toàn bộ chương trình học về NLP từ cơ bản đến nâng cao, bao gồm 4 modules với các chủ đề từ classification, probabilistic models, sequence models đến attention mechanisms. Nắm vững các kỹ thuật từ traditional methods (Naive Bayes, HMM) đến modern deep learning approaches (RNN, LSTM, Attention). Đồng thời thành thạo FastAPI framework để triển khai ML models thành production-ready APIs với đầy đủ CRUD operations, validation, và best practices. Đã sẵn sàng áp dụng kiến thức NLP và FastAPI vào dự án thực tế.\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9: Dự án FastAPI với MongoDB Thư viện STT tiếng Việt được lựa chọn và tích hợp Thư viện OCR tiếng Việt được lựa chọn và thử nghiệm Trích xuất NLP: số lượng, danh mục, ngày tháng, phát hiện jar (REQ-027) Phát hiện nhiều giao dịch (REQ-027) Xuất bản sự kiện lên RabbitMQ Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 Thiết lập dự án: Cấu trúc FastAPI, Docker, MongoDB (ai_service_db).\nNghiên cứu công nghệ: Tìm kiếm mô hình OCR (Bill) và STT (Voice) tối ưu cho tiếng Việt. 03/11/2025 03/11/2025 3 Xây dựng Core API:\n- Thiết lập Endpoints, Pydantic models.\n- Cấu hình Middleware (CORS, Error handling) \u0026amp; Logging (structlog). 04/11/2025 04/11/2025 4 Triển khai Voice \u0026amp; OCR:\n- Voice: Cài đặt thư viện STT, tiền xử lý âm thanh.\n- OCR: Cài đặt thư viện, nghiên cứu kỹ thuật tiền xử lý ảnh hóa đơn. 05/11/2025 05/11/2025 5 Tối ưu hóa:\n- Voice: Ứng dụng mô hình PhoWhisper (VinAI), detect giao dịch/thời gian.\n- OCR: Tối ưu hóa chất lượng ảnh đầu vào, thu thập dataset hóa đơn Việt Nam. 06/11/2025 06/11/2025 6 Tích hợp \u0026amp; Kiểm thử (Integration \u0026amp; Testing):\n- Xử lý Background tasks.\n- Test luồng E2E cho Voice (Ghi âm -\u0026gt; Text).\n- Đánh giá hiệu quả các model OCR (Tesseract, EasyOCR\u0026hellip;). 07/11/2025 07/11/2025 Kết quả đạt được tuần 9: 1. Thiết lập Dự án và Hạ tầng Hoàn thành cấu trúc dự án FastAPI với các thư mục chuẩn (/app, /models, /services, /utils, /routers, /schemas, /ai-models) Thiết lập môi trường Python 3.11+ với môi trường ảo Cài đặt và cấu hình MongoDB cục bộ sử dụng Docker Tạo cơ sở dữ liệu ai_service_db và thu thập bộ dữ liệu Bills và Voices Thiết lập kết nối MongoDB với MongoEngine và quản lý vòng đời kết nối 2. Cấu trúc API và Middleware Thiết lập các API endpoint cho Voice và Bill processing Tạo mô hình Pydantic cho request/response validation Cấu hình CORS middleware và error handling middleware Triển khai health check endpoint (GET /health) Tích hợp structlog cho logging system 3. Xử lý Giọng nói (Speech-to-Text) Nghiên cứu và lựa chọn mô hình PhoWhisper của VinAI cho STT tiếng Việt Triển khai tiền xử lý âm thanh và tích hợp Voice-to-Text Kiểm tra độ chính xác của mô hình và khả năng detect giọng nói Cấu hình endpoint trả về đúng các category đã định nghĩa Thử nghiệm xử lý nhiều giao dịch cùng lúc Thiết lập phát hiện thời gian giao dịch từ giọng nói Tạo đối tượng giao dịch từ dữ liệu voice 4. Xử lý Hóa đơn (OCR) Nghiên cứu và lựa chọn thư viện OCR phù hợp (Tesseract, EasyOCR) Triển khai tiền xử lý ảnh để tối ưu chất lượng trước khi OCR Thu thập bộ dữ liệu hóa đơn Việt Nam đa dạng (điện, siêu thị, quán ăn, cửa hàng tiện lợi, cà phê) Thử nghiệm các mô hình OCR với hóa đơn thực tế 5. Trích xuất NLP và Xử lý Dữ liệu Triển khai trích xuất thông tin: số lượng, danh mục, ngày tháng (REQ-027) Phát hiện jar detection Xử lý phát hiện nhiều giao dịch trong một request 6. Tích hợp RabbitMQ Thiết lập xuất bản sự kiện lên RabbitMQ Xử lý các công việc nền (background tasks) cho Voice và Bill 7. Testing và Quality Assurance Kiểm thử end-to-end cho Voice processing pipeline (Ghi âm → Xử lý → Trả Endpoint) Đánh giá và cải thiện độ chính xác của xử lý Voice Kiểm thử các mô hình OCR với dataset thực tế Tổng kết: Tuần 9 đã hoàn thành đầy đủ các mục tiêu đề ra, bao gồm thiết lập hạ tầng dự án FastAPI-MongoDB, tích hợp mô hình PhoWhisper cho STT tiếng Việt, triển khai OCR cho xử lý hóa đơn, và thiết lập hệ thống event publishing với RabbitMQ. Các chức năng NLP cho trích xuất thông tin giao dịch đã được triển khai và kiểm thử thành công.\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10: Cải tiến và tối ưu hóa mô hình OCR cho nhiều loại hóa đơn Nâng cao chất lượng xử lý Voice với số tiếng Việt và cụm từ ghép Triển khai hệ thống Confidence Scoring cho cả Voice và Bill Phát hiện danh mục thông minh và nhận dạng ngữ cảnh Xử lý lỗi toàn diện và tối ưu hiệu suất Kiểm thử đa chiều với các trường hợp edge cases Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 Cloud Mastery Series #2.\nCải tiến OCR: Trích xuất chi tiết mục hàng (line items) ra JSON, đếm số lượng.\nCải tiến Voice: Chuẩn hóa số tiếng Việt (text normalization), xử lý nhiễu và lỗi chính tả. 10/11/2025 10/11/2025 3 Đánh giá độ tin cậy (Confidence Scoring):\n- OCR: Tính điểm cho từng trường (giá, ngày), ngưỡng tin cậy thấp.\n- Voice: Điểm tin cậy đa lớp, kiểm tra hiệu suất (\u0026lt;4s).\n- Kiểm thử hệ thống diện rộng. 11/11/2025 11/11/2025 4 Tính năng nâng cao \u0026amp; Tích hợp:\n- Voice: Phát hiện danh mục thông minh \u0026amp; ngữ cảnh.\n- OCR: Mở rộng hỗ trợ các loại hóa đơn (siêu thị, nhà hàng, cafe).\n- Backend: Tích hợp giao dịch, chuẩn hóa JSON output. 12/11/2025 12/11/2025 5 Xử lý lỗi \u0026amp; Tối ưu hóa (Error Handling):\n- Xử lý file hỏng, timeout, logic thử lại (Retry logic).\n- Quản lý ngoại lệ (Edge cases): Âm thanh tĩnh, sai ngôn ngữ, file quá lớn.\n- Cơ chế Graceful Degradation (trả về kết quả một phần thay vì lỗi hoàn toàn). 13/11/2025 13/11/2025 6 Kiểm thử toàn diện \u0026amp; Tài liệu:\n- Kiểm tra API Voice/Bill.\n- Test các trường hợp khó: Voice (nhiễu, tốc độ nói), Bill (ảnh xoay, mờ, phức tạp).\n- Hoàn thiện tài liệu dự án. 14/11/2025 14/11/2025 Kết quả đạt được tuần 10: 1. Cải Tiến Mô Hình OCR Phát hiện và trích xuất mục hàng đúng định dạng JSON Trích xuất đa mục hàng hóa trong một hóa đơn Tính toán số lượng các thành phần trong hóa đơn tự động Kiểm thử thành công với nhiều loại hóa đơn: siêu thị, nhà hàng, cà phê, quán nước Xây dựng quy tắc trích xuất theo từng loại hóa đơn cụ thể Cải thiện format JSON response cho endpoint Bill 2. Nâng Cao Chất Lượng Voice Processing Xử lý số tiếng Việt (chuyển \u0026ldquo;hai mươi hai\u0026rdquo; → \u0026ldquo;22\u0026rdquo;) Nhận dạng các cụm từ ghép tiếng Việt Sửa lỗi chính tả và xử lý nhiễu âm thanh Cải tiến định dạng phản hồi JSON Tối ưu hóa hiệu suất xử lý Voice 3. Hệ Thống Confidence Scoring OCR Confidence:\nTính toán độ tin cậy cấp trường (Field-level Confidence) Độ tin cậy cho Số tiền/Tổng Độ tin cậy cho Ngày tháng Đánh giá độ rõ nét văn bản và phân tách dòng Phát hiện căn chỉnh giá và số lượng Xây dựng thuật toán độ tin cậy tổng thể Thiết lập Low Confidence Threshold Kiểm thử trên hơn 30 hóa đơn thực tế Voice Confidence:\nTriển khai điểm số tin cậy nhiều lớp (Multi-layer Confidence Scoring) Thuật toán độ tin cậy tổng thể cho Voice Thiết lập Low Confidence Thresholds Kiểm tra hiệu suất trên hơn 50 mẫu (thời gian xử lý \u0026lt;4 giây) 4. Phát Hiện Danh Mục Thông Minh Phân tích tên người bán/merchant Trích xuất keyword dựa vào danh mục Xác định ngữ cảnh giao dịch Phát hiện danh mục nâng cao (Advanced Category Detection) 5. Error Handling \u0026amp; Resilience Xử lý Lỗi Âm Thanh:\nXác thực định dạng âm thanh (WAV, MP3, M4A) Kiểm tra thời lượng (min: 0.5s, max: 30s) Phát hiện tệp bị hỏng/không đầy đủ Xử lý timeout STT (max: 30s) Logic retry với exponential backoff (3 lần, 1s-2s-4s) Xử lý Trường Hợp Ngoại Lệ:\nÂm thanh trống/im lặng → Error: \u0026ldquo;Không phát hiện giọng nói\u0026rdquo; Giọng nói không phải tiếng Việt → Cảnh báo độ tin cậy thấp Nhiều người nói → Cảnh báo + trích xuất nỗ lực tốt nhất Âm thanh quá dài (\u0026gt;30s) → Error: \u0026ldquo;Âm thanh quá dài\u0026rdquo; Graceful Degradation:\nDanh mục không phát hiện được → Trả về \u0026ldquo;Chưa phân loại\u0026rdquo; Số lượng không trích xuất được → Trả về null + cảnh báo Ngày không phát hiện → Sử dụng ngày hiện tại + cảnh báo Luôn trả về kết quả partial khi có thể 6. Kiểm Thử Toàn Diện Voice Testing:\nKiểm tra với tiếng ồn xung quanh Kiểm tra tốc độ nói (nhanh/chậm) Kiểm tra đầu vào không hợp lệ (nói tàm phào) Kiểm tra đa giao dịch trong một lần ghi âm Kiểm tra đầu vào mơ hồ Bill OCR Testing:\nKiểm tra ảnh xoay nhiều hướng Kiểm tra chất lượng ảnh đa dạng Kiểm tra input không đúng định dạng hóa đơn Kiểm tra hóa đơn có độ phức tạp cao Kiểm tra hóa đơn nhiều mặt hàng 7. Tích Hợp Backend Tích hợp các chức năng giao dịch với Backend Xử lý lỗi toàn diện Trả về giá trị JSON chuẩn hóa Tổng kết: Tuần 10 tập trung vào việc nâng cao chất lượng và độ tin cậy của cả hai mô hình Voice và OCR. Đã triển khai thành công hệ thống confidence scoring, xử lý lỗi toàn diện, và kiểm thử đa chiều với nhiều edge cases. Hệ thống đã sẵn sàng tích hợp với Backend và xử lý các tình huống thực tế phức tạp.\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Phát hiện và xử lý nhiều giao dịch phức tạp Tích hợp hỗ trợ file PDF cho Bill OCR Triển khai hệ thống feedback và fine-tuning models Nâng cao chất lượng xử lý hình ảnh và âm thanh Tích hợp Backend và lưu trữ MongoDB Automated testing và deployment Docker Làm quen với AWS và các công cụ quản lý Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 Nâng cao tính năng:\n- Phát hiện đa giao dịch (Multi-transaction) \u0026amp; phân loại hũ (jar) thông minh.\n- Hỗ trợ xử lý và kiểm thử file PDF cho hóa đơn. 17/11/2025 17/11/2025 3 Cơ chế học tập (Feedback Loop):\n- Xây dựng hệ thống thu thập phản hồi người dùng cho Voice/OCR.\n- Fine-tune lại mô hình dựa trên dữ liệu feedback để cải thiện độ chính xác. 18/11/2025 18/11/2025 4 Xử lý nâng cao (Advanced Processing):\n- Bill: Tự động xoay, khử nghiêng, phát hiện vùng quan tâm (ROI), nâng cao chất lượng ảnh.\n- Voice: Giảm nhiễu nền, phát hiện giọng nói (VAD), cắt khoảng lặng. 19/11/2025 19/11/2025 5 Tích hợp hệ thống:\n- Kết nối Backend API, kiểm thử luồng tạo giao dịch tự động.\n- Thiết lập lưu trữ MongoDB và chuẩn bị tích hợp AWS S3. 20/11/2025 20/11/2025 6 Kiểm thử \u0026amp; Triển khai:\n- Thiết lập Automated Testing và kiểm thử hồi quy (Regression test).\n- Đóng gói và triển khai ứng dụng lên Docker. 21/11/2025 21/11/2025 Kết quả đạt được tuần 11: 1. Phát Hiện Nhiều Giao Dịch và Hỗ Trợ PDF Phân tích cú pháp đa giao dịch phức tạp Tinh chỉnh thuật toán phát hiện đa giao dịch Phát hiện phân công jar trong cụm từ Xử lý các loại giao dịch hỗn hợp Kiểm Tra Cụm Từ Phức Tạp:\nKiểm tra 1 giao dịch với 1 hủ Kiểm tra nhiều giao dịch Kiểm thử chuyển đổi giữa các hủ Kiểm thử các ngữ cảnh hỗn hợp Hỗ Trợ PDF:\nCài đặt các thư viện xử lý PDF Kiểm thử giao dịch với file PDF Tích hợp PDF vào OCR Pipeline 2. Hệ Thống Phản Hồi và Học Tập Xử lý hệ thống feedback từ user của phần Voice Xử lý hệ thống feedback từ user của phần Bill Fine-tuning các model dựa trên feedback Cải thiện xử lý các cú pháp nhập vào sai Kiểm tra độ cải thiện của 2 mô hình Voice và Bill 3. Xử Lý Hình Ảnh/Âm Thanh Nâng Cao Nâng Cao Chất Lượng Bill:\nPhát hiện và đánh giá chất lượng ảnh Tự động xoay và nghiêng ảnh Phát hiện ROI (Region of Interest/Vùng quan tâm) Tích hợp với OCR Pipeline Kiểm thử với nhiều điều kiện ảnh khác nhau Xử Lý Tiếng Ồn Nền Voice:\nTriển khai giảm noise (Noise Reduction) Phát hiện hoạt động giọng nói (Voice Activity Detection) Cắt phần im lặng (Silence Trimming) Giảm thời gian xử lý Tích hợp với Voice Pipeline Kiểm thử với nhiều môi trường âm thanh 4. Tích Hợp Backend \u0026amp; Lưu Trữ Tích Hợp Backend:\nReview Backend API endpoints Test AI và Backend workflow Xác minh mức tiêu thụ sự kiện (Event Consumption) Kiểm tra việc tạo giao dịch tự động Khắc phục sự cố tích hợp Tích Hợp MongoDB:\nThiết lập Database cho Voice và Bill Chuẩn bị schema cho tích hợp với S3 của Amazon Triển khai storage strategy 5. Testing Tự Động và Deployment Tạo automated tests cho Voice và Bill Nghiệm thu và kiểm tra tất cả test cases Sửa lỗi phát hiện từ testing Kiểm tra hồi quy đầy đủ (Full Regression Testing) Setup Docker environment Deploy lên Docker container 6. AWS Learning Hiểu AWS và các nhóm dịch vụ cơ bản (Compute, Storage, Networking, Database) Tạo và cấu hình AWS Free Tier account Làm quen với AWS Management Console Cài đặt và cấu hình AWS CLI (Access Key, Secret Key, Region) Thực hiện các thao tác cơ bản với AWS CLI Kết nối và làm quen với cộng đồng First Cloud Journey Tổng kết: Tuần 11 đã hoàn thành việc nâng cao khả năng xử lý đa giao dịch, tích hợp hỗ trợ PDF, triển khai hệ thống feedback và fine-tuning models. Đã cải thiện đáng kể chất lượng xử lý ảnh/âm thanh với các kỹ thuật nâng cao (ROI detection, noise reduction, VAD), tích hợp thành công với Backend và MongoDB, đồng thời hoàn tất automated testing và deployment lên Docker. Bên cạnh đó, đã làm quen với AWS ecosystem và các công cụ quản lý cơ bản, chuẩn bị cho việc triển khai cloud infrastructure.\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Mục tiêu tuần 12: Kiểm tra tải và tối ưu hóa hiệu suất hệ thống Cải thiện độ chính xác của Voice và OCR models Tăng cường bảo mật và xử lý lỗi toàn diện Triển khai logging và metrics collection nâng cao Chuẩn bị deployment và kiểm tra cuối cùng Nâng cao chất lượng code và documentation Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày kết thúc Nguồn tài liệu và ghi chú học tập 2 Kiểm tra tải (Load Testing): Thiết lập kịch bản \u0026amp; chạy test (Voice/Bill/Đồng thời).\nTối ưu hóa: Cải thiện hiệu năng Database, Caching và quản lý bộ nhớ. 24/11/2025 24/11/2025 3 Cải thiện độ chính xác:\n- Voice/OCR: Phân tích lỗi, tinh chỉnh NLP và nhận dạng ký tự.\n- Xử lý ngoại lệ: Giải quyết các trường hợp số lượng mơ hồ, xác thực tổng tiền. 25/11/2025 25/11/2025 4 Bảo mật \u0026amp; Ổn định:\n- Security: Rate limiting, Input validation, JWT, bảo mật MongoDB.\n- Robustness: Xử lý lỗi toàn diện (Error Handling) và kiểm thử với file hỏng. 26/11/2025 26/11/2025 5 Giám sát (Observability):\n- Cấu hình Logging (JSON cấu trúc, Stack traces).\n- Thu thập Metrics (Thời gian xử lý, tỷ lệ lỗi).\n- Chuẩn bị gói triển khai (Deployment Prep). 27/11/2025 27/11/2025 6 Kiểm thử cuối cùng (Final QA): Regression Test \u0026amp; Integration Test (UI/Backend).\nChất lượng mã nguồn: Thêm Docstrings, Type hints, chạy Linter và viết Unit Tests. 28/11/2025 28/11/2025 Kết quả đạt được tuần 12: 1. Kiểm Tra Tải và Tối Ưu Hóa Thiết Lập Load Testing:\nCài đặt công cụ kiểm tra tải (JMeter/Locust) Tạo các kịch bản kiểm tra tải (Voice, Bill, đồng thời) Thiết lập giám sát tài nguyên (CPU, RAM, Disk I/O) Chuẩn bị dữ liệu thử nghiệm Chạy Thử Nghiệm Tải:\nKiểm tra tải Voice (10 files đồng thời) Kiểm tra tải Bill OCR (10 files đồng thời) Kiểm tra tải đồng thời cả Voice và Bill Phân tích bottlenecks và điểm nghẽn Tối Ưu Hóa:\nTối ưu hóa Database queries và indexing Triển khai bộ nhớ đệm (caching) cho kết quả Tối ưu hóa bộ nhớ và garbage collection Cải thiện thời gian phản hồi API 2. Cải Thiện Độ Chính Xác Voice Accuracy:\nPhân tích các trường hợp thất bại (failure cases) Cải thiện quy tắc NLP cho tiếng Việt Kiểm tra lại và lặp lại (testing \u0026amp; iteration) Nâng cao độ chính xác nhận dạng số và danh mục OCR Accuracy:\nPhân tích các trường hợp OCR thất bại Cải tiến theo định dạng hóa đơn cụ thể Cải tiến nhận dạng ký tự đặc biệt Xử lý các trường hợp font chữ khó Xử Lý Số Lượng:\nXử lý các trường hợp mơ hồ Logic xác thực số lượng Trích xuất tổng số lượng Logic xác thực tổng tiền 3. Tăng Cường An Ninh File Security:\nXác thực tải lên tệp (file type, size validation) Giới hạn tỷ lệ (rate limiting) cho API Vệ sinh đầu vào (input sanitization) Xác thực JWT tokens Bảo mật MongoDB (authentication, authorization) Hoàn thành danh sách kiểm tra bảo mật Error Handling:\nTry-Catch toàn diện cho tất cả các hàm Mã trạng thái HTTP thích hợp Thông báo lỗi hữu ích và rõ ràng Ghi nhật ký với ngữ cảnh đầy đủ Robustness Testing:\nKiểm tra Voice với files bị hỏng/không hợp lệ Kiểm tra OCR với hình ảnh bị hỏng/không hợp lệ Xử lý graceful degradation 4. Logging và Metrics Enhanced Logging:\nGhi nhật ký JSON có cấu trúc (structured logging) Logging cho mỗi HTTP request Các bước xử lý nhật ký với timestamp Ghi lại lỗi với stack traces Correlation ID để theo dõi request flow Metrics Collection:\nTheo dõi thời gian xử lý (processing time) Độ chính xác và tỷ lệ lỗi (accuracy \u0026amp; error rates) Lưu trữ metrics trong MongoDB Tạo API endpoints cho metrics Dashboard cho monitoring 5. Deployment Preparation Chuẩn bị triển khai Voice service Chuẩn bị triển khai OCR service Docker configuration và optimization Environment variables và secrets management Health check endpoints 6. Kiểm Tra Toàn Diện và Code Quality Comprehensive Testing:\nKiểm tra hồi quy đầy đủ (full regression testing) Kiểm tra tất cả các tình huống lỗi (error scenarios) Kiểm tra tích hợp UI (frontend integration) Kiểm tra tích hợp Backend (backend integration) End-to-end testing Code Quality:\nThêm Docstrings cho tất cả functions/classes Thêm type hints (Python typing) Chạy Linter (Pylint/Flake8) và sửa lỗi Thêm unit tests cho các chức năng quan trọng Code review và refactoring Tổng kết: Tuần 12 tập trung vào hoàn thiện và production-ready hóa hệ thống AI. Đã thực hiện thành công load testing và tối ưu hóa hiệu suất, cải thiện đáng kể độ chính xác của cả Voice và OCR models. Tăng cường bảo mật toàn diện với file validation, rate limiting, JWT authentication và MongoDB security. Triển khai structured logging và metrics collection để monitoring. Nâng cao chất lượng code với docstrings, type hints, linting và unit tests. Hệ thống đã sẵn sàng cho production deployment với error handling mạnh mẽ và testing toàn diện.\n"},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://pgmdes.github.io/fcj2025-workshop-minhtran/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]